# BruV Enterprise Server — 企業級地端化伺服器規劃

> **版本**：v3.0 Anytype Edition  
> **最後更新**：2026-02-10  
> **定位**：企業級、完全地端部署的 AI 知識管理伺服器  
> **本文件為唯一規劃主文件，所有架構討論的變動皆在此更新。**

---

## 目錄

1. [系統總覽](#1-系統總覽)
2. [四層架構概述](#2-四層架構概述)
3. [核心引擎整合](#3-核心引擎整合)
4. [前端架構](#4-前端架構)
5. [後端架構](#5-後端架構)
6. [API 端點一覽](#6-api-端點一覽)
7. [資料庫與儲存](#7-資料庫與儲存)
8. [Docker 容器服務](#8-docker-容器服務)
9. [安全縱深防禦](#9-安全縱深防禦)
10. [配置管理](#10-配置管理)
11. [任務佇列與持久化](#11-任務佇列與持久化)
12. [檔案監控與自動匯入](#12-檔案監控與自動匯入)
13. [Nginx 反向代理](#13-nginx-反向代理)
14. [依賴清單](#14-依賴清單)
15. [部署與啟動方式](#15-部署與啟動方式)
16. [硬體建議規格](#16-硬體建議規格)
17. [未來擴展路線圖](#17-未來擴展路線圖)
18. [架構深度審查 — 紅隊測試報告](#18-架構深度審查--紅隊測試報告-2026-02-10)
19. [變更紀錄](#19-變更紀錄)

---

## 1. 系統總覽

BruV Enterprise Server 是一套企業級、完全地端部署的 AI 知識管理平台。  
它整合了三大核心引擎：

| # | 引擎 | 用途 |
|---|------|------|
| 1 | **Dify** | 大語言模型 (LLM) 對話平台 — AI 聊天、自動化工作流 |
| 2 | **RAGFlow** | 檢索增強生成 (RAG) 知識檢索引擎 — 文件解析與語義搜尋 |
| 3 | **KuzuDB** | 圖資料庫 — 知識圖譜的節點與關係管理 |

前端提供 **2D (AntV G6)** 與 **3D (Three.js + 3D-Force-Graph)** 雙模式的知識圖譜視覺化介面，支援拖放操作、跨圖譜關聯、智能推薦連結等功能。

**所有資料與模型完全執行在本地環境，不依賴任何外部雲端服務，滿足企業對資料隱私與合規性的嚴格要求。**

### 主要技術棧

| 分類 | 技術 |
|------|------|
| 前端 | Vue 3 + Vite 5 + Pinia + Element Plus + Tailwind CSS |
| 後端 | Python FastAPI + Uvicorn (ASGI) |
| 圖資料庫 | KuzuDB |
| AI 引擎 | Dify (LLM) + RAGFlow (RAG) |
| 容器化 | Docker Compose (9 個微服務) |
| 反向代理 | Nginx (SSL/TLS + 安全標頭 + 速率限制) |
| 物件儲存 | MinIO (S3 相容) |
| 搜尋引擎 | Elasticsearch 8.11 |
| 關聯式資料庫 | PostgreSQL 15 (Dify) / MySQL 8.0 (RAGFlow) |
| 快取 | Redis 7 (兩組獨立實例) |

---

## 2. 四層架構概述

| 層級 | 技術組件 | 職責 |
|------|---------|------|
| **展示層** | Vue 3 + Vite 5 + Element Plus + AntV G6 / Three.js | 知識圖譜 2D/3D 視覺化、AI 對話、系統管理 UI |
| **接入層** | Nginx (SSL/TLS + 速率限制 + 安全標頭) | HTTPS 終端、反向代理、WAF 防護 |
| **業務層** | FastAPI + Uvicorn (ASGI) | API 路由、認證、意圖路由、任務佇列、檔案監控 |
| **資料層** | KuzuDB + PostgreSQL + MySQL + ES + Redis×2 + MinIO + SQLite | 圖資料庫、全文搜尋、快取、物件儲存、任務持久化 |

### 系統架構圖

```
使用者瀏覽器
     │
     ▼
┌─────────────────────────────────────────────────────────────┐
│  Nginx 反向代理 (HTTPS 443 / HTTP 80)                        │
│  SSL/TLS 終端 · WAF · 速率限制 (API 30r/s · Upload 5r/s)     │
└─────────────────────────┬───────────────────────────────────┘
                          │
     ┌────────────────────┴────────────────────┐
     ▼                                         ▼
┌──────────────────────┐      ┌────────────────────────────────────────────┐
│  Vue 3 前端 (SPA)     │      │  FastAPI 後端 (Port 8765)                  │
│  Port 5173 (dev)     │      │                                            │
│  ├── AntV G6 (2D)    │      │  ├── Auth Middleware (Bearer Token)        │
│  ├── Three.js (3D)   │      │  ├── CORS Middleware                       │
│  ├── Pinia Store     │      │  ├── /api/graph/*     → KuzuDB             │
│  ├── Element Plus    │      │  ├── /api/dify/*      → Dify LLM 代理      │
│  └── authFetch       │─────▶│  ├── /api/ragflow/*   → RAGFlow 檢索代理   │
│      (Token 自動附加) │      │  ├── /api/system/*    → 系統配置           │
└──────────────────────┘      │  ├── /api/media/*     → 媒體庫 (MinIO)     │
                              │  ├── /api/tasks/*     → 任務管理           │
                              │  ├── /api/auth/*      → 認證               │
                              │  └── Lifespan 管理                         │
                              │       ├── httpx 連線池 (max 50)            │
                              │       ├── TaskQueue Worker (SQLite)        │
                              │       ├── WatcherService 檔案監控          │
                              │       └── KuzuDBManager 圖資料庫連線       │
                              └───────────┬────────────────────────────────┘
                                          │
          ┌───────────────────────────────┼───────────────────────────────┐
          ▼                               ▼                               ▼
┌──────────────────┐  ┌──────────────────────────────────┐  ┌─────────────────┐
│  Dify 堆疊 (4)    │  │  RAGFlow 堆疊 (5)                 │  │  本地儲存         │
│  ├── Web :82     │  │  ├── RAGFlow :81/:9380/:9381     │  │  ~/BruV_Data/    │
│  ├── API :5001   │  │  ├── Elasticsearch :9200         │  │  ├── kuzu_db/    │
│  ├── PostgreSQL  │  │  ├── MySQL 8.0                   │  │  ├── Auto_Import/│
│  └── Redis       │  │  ├── MinIO :9000/:9001           │  │  ├── media_lib/  │
└──────────────────┘  │  └── Redis                       │  │  ├── auth_token  │
                      └──────────────────────────────────┘  │  └── task_queue  │
                                                            └─────────────────┘
```

---

## 3. 核心引擎整合

```
┌─────────────────────────────────────────────────────────────┐
│                     FastAPI 後端閘道                          │
│                                                              │
│   ┌──────────────┐  ┌────────────────┐  ┌──────────────┐    │
│   │  Dify        │  │  RAGFlow       │  │  KuzuDB      │    │
│   │  LLM 對話     │  │  RAG 知識檢索   │  │  知識圖譜     │    │
│   │  Port 5001   │  │  Port 9380     │  │  嵌入式       │    │
│   └──────┬───────┘  └───────┬────────┘  └──────┬───────┘    │
│          │                  │                   │            │
│   ┌──────▼──────────────────▼───────────────────▼───────┐    │
│   │            AgentService 意圖路由器                    │    │
│   │                                                      │    │
│   │  RAG 意圖 → RAGFlow 檢索 → Dify 生成回應             │    │
│   │  CHAT 意圖 → 直接 Dify 對話                          │    │
│   │  AUTOMATION 意圖 → 系統自動化                        │    │
│   └──────────────────────────────────────────────────────┘    │
└──────────────────────────────────────────────────────────────┘
```

### 資料流序列

```
使用者 ──► Nginx(HTTPS) ──► FastAPI ──► AuthMiddleware
                                           │
                                    AgentService 意圖路由
                                     ┌──────┼──────┐
                                     ▼      ▼      ▼
                                   RAG    CHAT  AUTOMATION
                                     │      │      │
                                RAGFlow  Dify    系統API
                                     │      │
                                     ▼      ▼
                                  Dify (結合知識生成回應)
                                     │
                                     ▼
                                  JSON Response ──► 使用者
```

---

## 4. 前端架構

### 4.1 技術選型

| 分類 | 技術 | 版本 |
|------|------|------|
| 框架 | Vue 3 (Composition API + `<script setup>`) | 3.4.15+ |
| 建構工具 | Vite | 5.4.21 |
| 狀態管理 | Pinia (defineStore Composition 風格) | 3.x |
| UI 組件庫 | Element Plus | 2.5 |
| CSS 框架 | Tailwind CSS | 3.4 |
| 2D 圖譜渲染 | AntV G6 | 5.0 |
| 3D 圖譜渲染 | 3D-Force-Graph + Three.js | 1.79 / 0.182 |
| HTTP 客戶端 | Axios + 原生 fetch (authFetch 封裝) | 1.13 |
| 路由 | Vue Router (History Mode) | 4.2 |
| 其他 | markdown-it · xlsx · splitpanes · vuedraggable | — |

### 4.2 路由表 (全部 Lazy Loading)

| 路徑 | 名稱 | 組件 | 說明 |
|------|------|------|------|
| `/` | — | redirect → /nexus | 首頁重定向 |
| `/nexus` | Nexus | NexusPage | 知識中樞主頁面 |
| `/graph-page` | GraphPage | GraphPage | 知識圖譜頁面 |
| `/graph` | Graph | GraphView | 舊版 2D 圖譜 |
| `/graph-3d` | Graph3D | Graph3D | 3D 圖譜視覺化 |
| `/cross-graph` | CrossGraph | CrossGraphPage | 跨圖譜關聯 |
| `/import` | Import | ImportPage | 資料匯入 |
| `/file-import` | FileImport | FileImport | 檔案匯入 |
| `/batch-repair` | BatchRepair | BatchRepair | 批量修復 |
| `/create` | Create | KnowledgeForm | 建立知識節點 |
| `/settings` | Settings | Settings | 系統設定 |
| `/monitor` | SystemMonitor | SystemMonitorPage | 系統監控 |
| `/timeline` | Timeline | TimelinePage | 時間線 |
| `/login` | Login | LoginPage | 公開登入頁面 |

**認證守衛** (router.beforeEach)：
- 首次載入時呼叫 `/api/auth/status` 檢查認證是否啟用
- 未帶 Token 時重定向至 `/login`
- 標記 `meta.public: true` 的路由免認證

### 4.3 狀態管理 (Pinia Stores)

**graphStore.js** (1270 行)：
- 管理知識圖譜的所有狀態：nodes、links、選中節點、2D/3D 模式切換、跨圖譜 AI Link
- `executeCypherQuery()` — 含前端安全驗證 (CYPHER_BLOCKED regex)
- 呼叫 GraphDataManager 取得資料

### 4.4 核心服務層

**GraphDataManager.js** (393 行)：
- 設計模式：單例 (Singleton)
- LRU 快取 (Map, 上限 10 個圖譜, TTL 5 分鐘)
- 請求去重 (pendingRequests Map) — 同一 graphId 的並發請求只發送一次
- 使用 authFetch 自動附加認證 Token

**apiClient.js** (102 行)：
- `authFetch(url, options)` 封裝原生 fetch
- 自動附加 `Authorization: Bearer <token>` header
- Token 存於 `localStorage('bruv_api_token')`
- 超時控制：30 秒 (AbortController)
- 401 回應時自動清除 Token 並重定向至 `/login`

### 4.5 前端安全措施

- Cypher 查詢雙重防護：前端 regex 攔截 + 後端白/黑名單驗證
- 查詢長度限制：2000 字元
- 黑名單關鍵字：`CREATE, DELETE, DETACH, SET, REMOVE, MERGE, DROP, ALTER, CALL, COPY, LOAD`

### 4.6 建構配置 (vite.config.js)

- Dev Server：Port 5173
- API Proxy：`/api` → `http://127.0.0.1:8000`
- 手動分塊策略：vue-vendor、element-plus、g6、xlsx、markdown
- 路徑別名：`@` → `./src`
- Terser 壓縮、sourcemap 關閉、chunk 上限 1500KB

---

## 5. 後端架構

### 5.1 主程式進入點 (app_anytype.py, 646 行)

- **框架**：FastAPI + Uvicorn (ASGI)
- **應用模式**：Lifespan Context Manager (取代已棄用的 on_event)

**初始化流程 (lifespan)**：

| 階段 | 啟動時 | 關閉時 |
|------|--------|--------|
| 1 | 啟動 TaskQueue 背景 Worker (asyncio) | 停止 TaskQueue Worker |
| 2 | 建立共享 httpx.AsyncClient 連線池 (max=50) | 關閉 httpx 連線池 |
| 3 | 初始化 KuzuDBManager (fallback → MockKuzuManager) | 關閉 KuzuDB 連線 |
| 4 | 初始化 WatcherService (監控 AUTO_IMPORT_DIR) | 停止 WatcherService |
| 5 | 將所有服務存於 app.state | — |

**中間件**：CORSMiddleware (白名單式 origin 控制) + APIAuthMiddleware (Bearer Token)

**掛載的 Router**：

| 路徑前綴 | Router | 模組 |
|---------|--------|------|
| `/api/tasks` | tasks_router | 任務管理 |
| `/api/dify` | dify_router | Dify LLM 代理 |
| `/api/ragflow` | ragflow_router | RAGFlow 知識檢索代理 |
| `/api/graph` | graph_router | 知識圖譜 CRUD |
| `/api/graph` | graph_import_router | Excel/CSV 匯入 |
| `/api/system` | system_router | 系統配置與上傳 |
| `/api/media` | media_library_router | 媒體庫管理 |

### 5.2 核心模組 (backend/core/)

**config.py** (168 行)：
- `Settings` 類別 (Pydantic BaseSettings)
- 配置優先級：`config.json` > 環境變數 (`.env`) > 程式碼預設值
- 執行緒安全：`threading.Lock` 保護 config.json 讀寫
- 原子寫入：先寫 `.tmp` 再 `rename`
- API Key 快取：`@lru_cache(maxsize=1)`，save 時自動清除

**auth.py** (189 行)：
- Bearer Token 認證 — Token 首次啟動時自動生成 (`secrets.token_urlsafe(32)`)
- Token 以 **SHA-256 雜湊**存於 `auth_token.json` (不存明文)
- 白名單免認證路徑：`/docs`, `/redoc`, `/openapi.json`, `/api/health`, `/api/auth/login`, `/api/auth/status`, `/`
- 白名單前綴：`/assets/`, `/favicon`

**kuzu_manager.py** (566 行)：
- KuzuDBManager — Schema 初始化、實體 CRUD、關係操作、Cypher 查詢
- 路徑處理：非 ASCII 路徑 fallback 到 `C:/BruV_Data/kuzu_db`
- MockKuzuManager 用於開發/測試環境 fallback

### 5.3 API 路由模組 (backend/api/)

| 模組 | 行數 | 功能描述 |
|------|------|---------|
| **graph.py** | 395 | 知識圖譜核心 API — 實體建立、關係管理、鄰居查詢、Cypher 安全驗證、圖譜元資料 CRUD |
| **graph_import.py** | 421 | Excel/CSV 智能解析匯入、LLM Prompt v2.0 自動標題/描述/關係推薦、多語言+領域特化 |
| **dify.py** | 208 | Dify LLM 平台代理、動態 API Key、整合 agent_service 意圖路由 |
| **ragflow.py** | 148 | RAGFlow 知識檢索代理、支援 `question, dataset_ids, top_k` 參數 |
| **system.py** | 547 | 系統配置讀寫、連線測試 (Dify/RAGFlow)、通用檔案上傳 |
| **media_library.py** | 438 | 媒體檔案 CRUD、MinIO 物件儲存 (本地 fallback)、標籤分類、OCR |
| **tasks.py** | 64 | 任務狀態查詢 (列表/單一)、封裝 TaskQueue |

### 5.4 服務層 (backend/services/)

**agent_service.py** (338 行)：
- 智能代理核心 — 意圖路由 (Intent Router)
- 意圖類型：`RAG` (知識檢索) / `AUTOMATION` (系統自動化) / `CHAT` (閒聊)
- 中文關鍵字匹配進行意圖識別
- httpx 非同步呼叫，超時由 `settings.REQUEST_TIMEOUT` 控制

**task_queue.py** (443 行)：
- asyncio 背景 Worker + SQLite 持久化 (`~/BruV_Data/task_queue.db`)
- 任務狀態：`PENDING → PROCESSING → COMPLETED | FAILED`
- 追蹤：進度百分比、total/processed/failed items、current stage
- 最大歷史 500 條，自動清理過期任務

**watcher.py** (573 行)：
- watchdog 庫 (Observer + FileSystemEventHandler)
- 監控 AUTO_IMPORT_DIR，支援 `.pdf, .txt, .md, .docx, .xlsx`
- 偵測新檔案 → 自動上傳至 RAGFlow + 同步至 KuzuDB
- 整合 TaskQueue 追蹤進度，背景執行緒不阻塞 asyncio

### 5.5 RAG 客戶端 (backend/rag_client.py, 119 行)

- 非同步 HTTP 客戶端 (httpx.AsyncClient)
- 連接 RAGFlow Server API (`http://localhost:81`)
- `async_upload_file()` — 上傳文件到指定知識庫
- 支援 MIME 類型檢測、chunk method 配置
- 同時提供同步方法供 WatcherService 背景執行緒使用

---

## 6. API 端點一覽

### 認證 API

| 方法 | 路徑 | 說明 |
|------|------|------|
| POST | `/api/auth/login` | Token 驗證登入 |
| GET | `/api/auth/status` | 認證狀態查詢 (是否啟用) |

### 系統 API

| 方法 | 路徑 | 說明 |
|------|------|------|
| GET | `/api/health` | 健康檢查 |
| GET | `/api/system/config` | 讀取目前配置 |
| POST | `/api/system/config` | 更新配置 (寫入 config.json) |
| GET | `/api/system/env-file` | 讀取 .env 檔案 |
| POST | `/api/system/test-connection` | 測試 Dify/RAGFlow 連線 |
| POST | `/api/system/upload` | 通用檔案上傳 |

### 知識圖譜 API

| 方法 | 路徑 | 說明 |
|------|------|------|
| POST | `/api/graph/entities` | 建立實體節點 |
| POST | `/api/graph/relations` | 建立關係邊 |
| GET | `/api/graph/entities/{id}` | 取得單一實體 |
| GET | `/api/graph/entities` | 搜尋/列出實體 |
| GET | `/api/graph/entities/{id}/neighbors` | 取得鄰居節點 |
| GET | `/api/graph/list` | 列出圖譜 |
| POST | `/api/graph/query` | 執行 Cypher 查詢 (僅讀取) |
| POST | `/api/graph/metadata` | 建立圖譜元資料 |
| GET | `/api/graph/metadata` | 列出所有圖譜元資料 |
| GET | `/api/graph/metadata/{id}` | 取得單一圖譜元資料 |
| PUT | `/api/graph/metadata/{id}` | 更新圖譜元資料 |
| DELETE | `/api/graph/metadata/{id}` | 刪除圖譜元資料 |
| POST | `/api/graph/import` | Excel/CSV 智能匯入 |

### AI 代理 API

| 方法 | 路徑 | 說明 |
|------|------|------|
| POST | `/api/dify/chat` | Dify LLM 對話 |
| POST | `/api/ragflow/query` | RAGFlow 知識檢索 |

### 媒體庫 API

| 方法 | 路徑 | 說明 |
|------|------|------|
| POST | `/api/media/upload` | 上傳媒體檔案 |
| GET | `/api/media/list` | 列出媒體庫 |
| GET | `/api/media/files/{path}` | 取得檔案 |
| DELETE | `/api/media/{file_id}` | 刪除檔案 |
| GET | `/api/media/stats` | 媒體庫統計 |

### 任務 API

| 方法 | 路徑 | 說明 |
|------|------|------|
| GET | `/api/tasks` | 取得所有任務列表 |
| GET | `/api/tasks/{task_id}` | 取得單一任務狀態 |

---

## 7. 資料庫與儲存

| # | 引擎 | 用途 | 位置/Port | 備份策略 |
|---|------|------|-----------|---------|
| 1 | **KuzuDB** | 知識圖譜 (節點+關係) | `~/BruV_Data/kuzu_db` | 目錄快照 |
| 2 | **PostgreSQL 15** | Dify 平台資料 | 容器 `dify-db` (無外部 Port) | Docker Volume `dify_db_data` |
| 3 | **MySQL 8.0** | RAGFlow 平台資料 | 容器 `ragflow-mysql` (無外部) | Docker Volume `ragflow_mysql_data` |
| 4 | **Elasticsearch 8.11.3** | 全文搜尋與語義索引 | `127.0.0.1:9200` | Docker Volume `es01_data` |
| 5 | **Redis 7 (Dify)** | Dify 快取與佇列 | 容器 `dify-redis` (無外部) | Docker Volume (可重建) |
| 6 | **Redis 7 (RAGFlow)** | RAGFlow 快取 | 容器 `ragflow-redis` (無外部) | Docker Volume (可重建) |
| 7 | **MinIO** | S3 相容物件儲存 | `127.0.0.1:9000` (API) / `:9001` (Console) | Docker Volume `ragflow_minio_data` |
| 8 | **SQLite** | 任務佇列持久化 | `~/BruV_Data/task_queue.db` | 500 條上限，自動清理 |
| 9 | **本地檔案系統** | config/token/媒體/自動匯入 | `~/BruV_Data/` | 整目錄備份 |

---

## 8. Docker 容器服務

使用 Docker Compose 編排 **9 個微服務**，所有服務在 `bruv_network` (bridge) 網路中通訊。

| 服務名稱 | 映像 | 外部 Port (bind 127.0.0.1) | 資源限制 |
|---------|------|---------------------------|---------|
| dify | langgenius/dify-web:0.6.16 | 82 → 3000 | 2 CPU + 4GB |
| dify-api | langgenius/dify-api:0.6.16 | 5001 → 5001 | 2 CPU + 4GB |
| dify-db | postgres:15-alpine | (無外部) | — |
| dify-redis | redis:7-alpine | (無外部) | — |
| ragflow | infiniflow/ragflow:v0.16.0 | 81→80, 9380, 9381 | — |
| es01 | elasticsearch:8.11.3 | 9200 → 9200 | — |
| ragflow-mysql | mysql:8.0 | (無外部) | — |
| ragflow-minio | minio/minio:latest | 9000, 9001 | — |
| ragflow-redis | redis:7-alpine | (無外部) | — |

**Docker Volumes (9 個)**：  
`dify_db_data`, `dify_redis_data`, `dify_storage`, `ragflow_data`, `ragflow_logs`, `ragflow_mysql_data`, `ragflow_minio_data`, `ragflow_redis_data`, `es01_data`

---

## 9. 安全縱深防禦

### 五層防護架構

```
第1層 ─ 網路邊界
│  ├── Port 綁定 127.0.0.1 (僅本地存取)
│  ├── SSL/TLS 1.2-1.3 (HTTPS 加密)
│  └── HSTS 1 年 (強制 HTTPS)
│
第2層 ─ Nginx WAF
│  ├── 速率限制 (API 30r/s burst 50 · Upload 5r/s burst 10)
│  ├── 安全標頭 (CSP · X-Frame-Options · HSTS · Permissions-Policy)
│  ├── 隱藏 Nginx 版本 (server_tokens off)
│  └── 路徑封鎖 (.env · .git · .sql · .log · 隱藏檔)
│
第3層 ─ 應用認證
│  ├── Bearer Token + SHA-256 雜湊儲存 (不存明文)
│  ├── CORS 白名單式 Origin 控制
│  ├── 免認證白名單 (/docs · /health · /login)
│  └── 401 自動清除 Token + 重定向
│
第4層 ─ 業務邏輯
│  ├── Cypher 前後端雙重驗證 (前端 regex + 後端黑名單)
│  ├── 查詢長度限制 2000 字元
│  ├── 上傳大小限制 100MB + Nginx 128M
│  └── config.json 原子寫入 + threading.Lock 防競爭
│
第5層 ─ 資料隔離
   ├── 完全地端部署 (零外部雲端依賴)
   ├── 密碼/金鑰透過 .env 注入 (不寫死在程式碼)
   ├── Docker Compose 使用 ${VAR:?message} 強制必填
   └── 進程優雅停止 (先 terminate → 5秒超時 → force kill)
```

---

## 10. 配置管理

### 10.1 配置優先級（高 → 低）

1. `config.json` (使用者透過 UI 設定頁面修改)
2. 環境變數 (`.env` 檔案)
3. 程式碼預設值 (`Settings` 類別)

### 10.2 Settings 類別欄位

| 欄位名稱 | 預設值 | 說明 |
|---------|--------|------|
| HOST | 127.0.0.1 | 伺服器監聽位址 |
| PORT | 8765 | 伺服器監聽埠號 |
| ENVIRONMENT | development | 執行環境 |
| DIFY_API_URL | http://localhost:80/v1 | Dify API 位址 |
| RAGFLOW_API_URL | http://localhost:81/api/v1 | RAGFlow API 位址 |
| KUZU_DB_PATH | ~/BruV_Data/kuzu_db | 圖資料庫路徑 |
| AUTO_IMPORT_DIR | ~/BruV_Data/Auto_Import | 自動匯入監控目錄 |
| MEDIA_LIBRARY_PATH | ~/BruV_Data/media_library | 媒體庫路徑 |
| MINIO_ENDPOINT | localhost:9000 | MinIO 端點 |
| MINIO_ROOT_USER | minioadmin | MinIO 使用者 |
| MINIO_ROOT_PASSWORD | (空) | MinIO 密碼 |
| REQUEST_TIMEOUT | 30 | HTTP 請求超時 (秒) |
| BRUV_AUTH_ENABLED | true | 啟用 API 認證 |
| BRUV_API_TOKEN | (空) | 自訂 Token |
| MAX_UPLOAD_SIZE | 104857600 | 上傳大小限制 (100MB) |

### 10.3 環境變數 (.env.example)

```
DIFY_API_URL, DIFY_API_KEY, DIFY_SECRET_KEY,
RAGFLOW_API_URL, RAGFLOW_API_KEY,
KUZU_DB_PATH, DEBUG, LOG_LEVEL,
BRUV_AUTH_ENABLED, BRUV_API_TOKEN,
DIFY_DB_PASSWORD, RAGFLOW_MYSQL_PASSWORD,
MINIO_ROOT_USER, MINIO_ROOT_PASSWORD,
RAGFLOW_REDIS_PASSWORD, ELASTIC_PASSWORD
```

---

## 11. 任務佇列與持久化

TaskQueue 是基於 asyncio 的背景任務系統，搭配 SQLite 持久化。

**任務生命週期**：`PENDING → PROCESSING → COMPLETED | FAILED`

**任務類型**：
- `file_upload` — 檔案上傳至 RAGFlow
- `excel_parse` — Excel 智能解析匯入

**每個任務追蹤**：
- 進度百分比 (0-100%)
- 總項目數 / 已處理 / 失敗項目數
- 當前階段描述
- 結果 (JSON) 或錯誤訊息
- 建立/開始/完成時間

**持久化機制**：
- 儲存路徑：`~/BruV_Data/task_queue.db` (SQLite)
- 每次 create/update 即時寫入
- 啟動時自動載入未完成的任務
- 歷史記錄上限 500 條，自動清理

---

## 12. 檔案監控與自動匯入

WatcherService 使用 watchdog 庫監控 AUTO_IMPORT_DIR 目錄。

**監控流程**：

```
1. 使用者將檔案放入 ~/BruV_Data/Auto_Import/
2. WatcherService 偵測到新檔案事件
3. 檢查副檔名 (.pdf, .txt, .md, .docx, .xlsx)
4. 建立 TaskQueue 任務，開始追蹤進度
5. 上傳檔案至 RAGFlow 知識庫
6. 同步文件元資料至 KuzuDB 知識圖譜
```

> watchdog callback 在獨立的背景執行緒中執行，不會阻塞 FastAPI 的 asyncio 事件迴圈。

---

## 13. Nginx 反向代理

配置檔案：`nginx/ragflow.conf` (200 行)

| 功能 | 配置 |
|------|------|
| SSL/TLS 終端 | TLS 1.2 + TLS 1.3 |
| 上游代理 | 127.0.0.1:9380 (RAGFlow API) |
| WebSocket | `/ws` 路徑 (read_timeout 86400) |
| Gzip 壓縮 | Level 6 |
| 靜態資源快取 | 30 天 (immutable) |
| HTTP → HTTPS | 301 重定向 |
| API 速率限制 | 30r/s (burst 50, nodelay) |
| 上傳速率限制 | 5r/s (burst 10, nodelay) |
| 上傳超時 | 600 秒 |

---

## 14. 依賴清單

### 14.1 Python 後端 (requirements.txt) — 全部版本鎖定

| 套件 | 版本 | 用途 |
|------|------|------|
| fastapi | 0.104.1 | Web 框架 |
| uvicorn[standard] | 0.24.0 | ASGI 伺服器 |
| pydantic | 2.5.0 | 資料驗證 |
| pydantic-settings | 2.1.0 | 設定管理 |
| httpx | 0.25.1 | 非同步 HTTP 客戶端 |
| requests | 2.32.5 | 同步 HTTP 客戶端 |
| kuzu | 0.1.0 | 圖資料庫 |
| python-multipart | 0.0.6 | 檔案上傳 |
| pandas | 3.0.0 | 資料處理 |
| openpyxl | 3.1.5 | Excel 讀寫 |
| python-dotenv | 1.0.0 | 環境變數載入 |
| watchdog | 6.0.0 | 檔案系統監控 |
| minio | 7.2.20 | MinIO 物件儲存客戶端 |

### 14.2 GUI 啟動器 (requirements-gui.txt)

| 套件 | 版本 | 用途 |
|------|------|------|
| PySide6 | 6.6.1 | Qt GUI 框架 (僅啟動器) |

### 14.3 前端依賴 (package.json 摘要)

| 套件 | 版本 | 用途 |
|------|------|------|
| vue | ^3.4.15 | UI 框架 |
| vue-router | ^4.2.5 | 路由 |
| pinia | ^3.0.4 | 狀態管理 |
| element-plus | ^2.5.4 | UI 組件庫 |
| @antv/g6 | ^5.0.0 | 2D 圖譜渲染 |
| 3d-force-graph | ^1.79 | 3D 圖譜渲染 |
| three | ^0.182 | 3D 引擎 |
| axios | ^1.13.4 | HTTP 客戶端 |
| markdown-it | ^14.0.0 | Markdown 渲染 |
| xlsx | ^0.18.5 | Excel 解析 |
| splitpanes | ^4.0.4 | 面板分割 |
| vuedraggable | ^4.1.0 | 拖放功能 |
| vite | ^5.0 | 建構工具 |
| tailwindcss | ^3.4 | CSS 框架 |

---

## 15. 部署與啟動方式

### 15.1 開發環境啟動

| 步驟 | 指令 | 說明 |
|------|------|------|
| 1 | `docker-compose up -d` | 啟動 Docker 容器群組 |
| 2 | `.\start_backend.ps1` 或 `uvicorn app_anytype:app --host 127.0.0.1 --port 8765` | 啟動 FastAPI 後端 |
| 3 | `cd frontend && npm run dev` | 啟動前端開發伺服器 |
| 4 (選用) | `python launcher_gui.py` | 啟動 GUI 啟動器 |

### 15.2 一鍵啟動

- `START.bat` — Windows 批次檔
- `START.ps1` — PowerShell 腳本
- `start_gui_launcher.bat` — GUI 啟動器

### 15.3 GUI 啟動器 (launcher_gui.py, 1454 行)

PySide6 桌面應用程式，功能包括：
- 一鍵啟動/停止所有服務
- 即時日誌輸出
- 服務健康狀態指示燈 (後端/前端/Dify/RAGFlow)
- 快速連結 (開啟 BruV AI / Dify / RAGFlow)
- 多語言支援 (繁體中文/英文)
- 系統設定頁面 (API 配置/認證管理)
- 優雅停止機制 (先 terminate → 5 秒超時 → force kill)

### 15.4 資料目錄

```
~/BruV_Data/    (可透過 BRUV_DATA_DIR 環境變數覆蓋)
├── kuzu_db/          KuzuDB 圖資料庫
├── Auto_Import/      自動匯入監控目錄
├── media_library/    本地媒體儲存
├── auth_token.json   認證 Token 雜湊
└── task_queue.db     SQLite 任務持久化
```

---

## 16. 硬體建議規格

| 等級 | CPU | RAM | 儲存 | GPU | 適用場景 |
|------|-----|-----|------|-----|---------|
| **入門** | 4C/8T | 16 GB | 256 GB SSD | — | 個人/小團隊，使用外部 LLM API |
| **標準** | 8C/16T | 32 GB | 512 GB NVMe | — | 中型團隊，Dify + RAGFlow 完整運行 |
| **進階** | 16C/32T | 64 GB | 1 TB NVMe | RTX 4060+ | 本地 LLM (Ollama)，大規模知識庫 |
| **企業** | 32C+ | 128 GB+ | 2 TB+ NVMe RAID | A4000+ | 多人同時推論，TB 級文件庫 |

---

## 17. 未來擴展路線圖

| 階段 | 目標 | 具體做法 |
|------|------|---------|
| **Phase 1** (現階段) | 單機地端部署 | Port 127.0.0.1 綁定，GUI 啟動器管理 |
| **Phase 2** | 區網多人存取 | Nginx HTTPS :443 開放區網 IP，多使用者 Token |
| **Phase 3** | 本地 LLM 整合 | Ollama (Llama 3.1 / Qwen2) 取代外部 API，完全離線 |
| **Phase 4** | 高可用部署 | Docker Swarm / K3s，PostgreSQL 主從複製 |
| **Phase 5** | 多節點聯邦 | 多台主機跨圖譜同步，分散式知識圖譜 |

---

## 18. 架構深度審查 — 紅隊測試報告 (2026-02-10)

### 18.1 執行摘要

**整體評分：7.2 / 10**

作為一套地端化單機部署的 AI 知識管理平台，BruV v3.0 在功能完整度與安全縱深防禦上已達到相當成熟的水準。前端雙模式圖譜視覺化、後端三引擎整合、五層安全模型——這些都是扎實的架構決策。然而，從「可靠性工程 (Reliability Engineering)」的角度深度審查後，發現以下 **三個 P0 級架構風險**：

| 風險排名 | 維度 | 問題 | 影響 |
|---------|------|------|------|
| **P0-1** | 資料一致性 | RAGFlow ↔ KuzuDB 跨系統寫入無補償機制 | 「幽靈文件」── 檔案存在 RAGFlow 但知識圖譜無對應節點，導致搜得到但圖譜看不到 |
| **P0-2** | 併發安全 | KuzuDB 單一 `Connection` 物件在 async 環境中無任何鎖保護 | 高併發寫入時可能觸發 Segfault 或資料庫檔案毀損 |
| **P0-3** | 可觀測性 | 9 個 Docker 容器 + 2 個原生進程，無 Correlation ID，無集中式日誌 | 跨服務除錯如同大海撈針，MTTR (平均恢復時間) 極高 |

---

### 18.2 深度分析

#### 18.2.1 資料一致性與分散式事務 (Data Consistency)

**現狀問題**

檢視 [watcher.py](backend/services/watcher.py) 的 `_process_file()` 方法，目前的寫入流程是：

```
動作 A: self.rag_client.upload_file()    → 寫入 RAGFlow (MySQL + ES + MinIO)
動作 B: self._add_to_graph()            → 寫入 KuzuDB
動作 C: self._parse_excel_and_link()     → 寫入 KuzuDB (Excel 深度解析)
```

**失敗情境分析**：

| 情境 | A (RAGFlow) | B (KuzuDB) | 結果 | 目前處理方式 |
|------|-------------|------------|------|-------------|
| 正常 | ✅ | ✅ | 一致 | — |
| 情境 1 | ✅ | ❌ | **不一致** — 幽靈文件 | `except` 印 Log，無補償 |
| 情境 2 | ❌ | — | 一致 (都未寫入) | 正確中斷 |
| 情境 3 | ✅ | ✅ (節點) | ❌ (關係) — **不一致** — 孤立節點 | 部分成功無回滾 |

**架構級解決方案：Saga Pattern (Orchestration 模式)**

引入 **Saga Orchestrator** 搭配 **補償操作 (Compensating Transaction)**：

```python
# === Pseudocode: SagaOrchestrator for File Import ===

class FileImportSaga:
    """
    Saga 編排器：協調 RAGFlow 上傳 + KuzuDB 寫入的跨系統事務。
    每個步驟都有對應的補償操作，確保最終一致性。
    """

    def __init__(self, rag_client, kuzu_manager, task_queue):
        self.rag_client = rag_client
        self.kuzu_manager = kuzu_manager
        self.task_queue = task_queue

    async def execute(self, file_path: Path, graph_id: str, dataset_id: str):
        saga_log = SagaLog()  # 持久化到 SQLite，記錄每一步的執行狀態
        ragflow_doc_id = None
        kuzu_entity_id = None

        try:
            # ── Step 1: 上傳至 RAGFlow ──
            saga_log.record_step("ragflow_upload", status="STARTED")
            upload_result = await self.rag_client.async_upload_file(dataset_id, str(file_path))
            ragflow_doc_id = extract_doc_id(upload_result)
            saga_log.record_step("ragflow_upload", status="COMPLETED", doc_id=ragflow_doc_id)

            # ── Step 2: 寫入 KuzuDB ──
            saga_log.record_step("kuzu_write", status="STARTED")
            kuzu_entity_id = generate_entity_id(file_path, upload_result)
            success = self.kuzu_manager.add_entity(
                entity_id=kuzu_entity_id,
                name=file_path.name,
                entity_type='document',
                graph_id=graph_id
            )
            if not success:
                raise KuzuWriteError(f"KuzuDB 寫入失敗: {kuzu_entity_id}")
            saga_log.record_step("kuzu_write", status="COMPLETED", entity_id=kuzu_entity_id)

            # ── Step 3: Excel 深度解析 (可選) ──
            if file_path.suffix.lower() == '.xlsx':
                saga_log.record_step("excel_parse", status="STARTED")
                parse_excel_and_link(file_path, kuzu_entity_id, graph_id)
                saga_log.record_step("excel_parse", status="COMPLETED")

            saga_log.mark_saga_completed()

        except Exception as e:
            # ── 補償流程 (Compensation) ──
            logger.error(f"Saga 失敗，啟動補償: {e}")
            await self._compensate(saga_log, ragflow_doc_id, kuzu_entity_id)
            saga_log.mark_saga_failed(str(e))
            raise

    async def _compensate(self, saga_log, ragflow_doc_id, kuzu_entity_id):
        """反向補償：按照 saga_log 反向撤銷已完成的步驟"""
        completed_steps = saga_log.get_completed_steps()

        if "kuzu_write" in completed_steps and kuzu_entity_id:
            try:
                self.kuzu_manager.delete_entity(kuzu_entity_id)
                logger.info(f"補償完成: 已刪除 KuzuDB 實體 {kuzu_entity_id}")
            except Exception as comp_err:
                logger.error(f"補償失敗 (KuzuDB): {comp_err}")
                # 寫入 Dead Letter Queue，等待人工介入

        if "ragflow_upload" in completed_steps and ragflow_doc_id:
            try:
                await self.rag_client.async_delete_document(ragflow_doc_id)
                logger.info(f"補償完成: 已刪除 RAGFlow 文件 {ragflow_doc_id}")
            except Exception as comp_err:
                logger.error(f"補償失敗 (RAGFlow): {comp_err}")
                # 寫入 Dead Letter Queue
```

**額外建議**：

- **Dead Letter Queue (DLQ)**：補償也失敗的操作寫入 `saga_dlq` SQLite 表，提供 `/api/system/saga-dlq` 端點讓管理員手動重試或確認
- **冪等性設計 (Idempotency)**：KuzuDB 的 `add_entity()` 已使用 `MERGE` (upsert) ✅，RAGFlow 上傳需增加基於檔案雜湊的去重檢查
- **定時調和任務 (Reconciliation Job)**：每小時比對 RAGFlow 文件清單與 KuzuDB Entity 清單，自動修復不一致

---

#### 18.2.2 KuzuDB 的併發處理 (Concurrency in Embedded DB)

**現狀問題**

檢視 [kuzu_manager.py](backend/core/kuzu_manager.py)：

```python
# 第 49-50 行 — 整個生命週期只建立一個 Connection
self.db = kuzu.Database(db_path_str)
self.conn = kuzu.Connection(self.db)
```

**風險鏈**：

```
FastAPI (async) → 多個並發 API Handler
                  ├── Handler A: self.conn.execute("MERGE ...")  ← 寫入
                  ├── Handler B: self.conn.execute("MATCH ...")  ← 讀取
                  └── Handler C: self.conn.execute("CREATE ...")  ← 寫入
                  
問題：kuzu.Connection 不是 thread-safe 的。
      在 async 環境中，雖然 GIL 提供了一定保護，
      但 KuzuDB 的 C++ 底層操作可能在 GIL 釋放期間並發執行。
```

此外，`conn.execute()` 是 **同步阻塞呼叫**，會阻塞整個事件迴圈，在高併發時造成所有 API 回應延遲。

**架構級解決方案：Write Serialization Queue + Read Connection Pool**

```python
# === Pseudocode: KuzuDBManager v2 with Concurrency Control ===

import asyncio
import threading
from contextlib import contextmanager

class KuzuDBManagerV2:
    """
    併發安全的 KuzuDB 管理器
    
    設計原則：
    1. 寫入操作序列化 — 所有寫入排進 asyncio.Queue，由單一 Writer 執行
    2. 讀取操作並行  — 使用 Connection Pool (讀取鎖不衝突)
    3. 同步呼叫隔離  — 使用 run_in_executor 避免阻塞事件迴圈
    """

    def __init__(self, db_path: str, read_pool_size: int = 3):
        self.db = kuzu.Database(db_path)
        
        # 寫入專用連線 (單一，序列化)
        self._write_conn = kuzu.Connection(self.db)
        self._write_lock = asyncio.Lock()
        
        # 讀取連線池
        self._read_pool = [kuzu.Connection(self.db) for _ in range(read_pool_size)]
        self._read_semaphore = asyncio.Semaphore(read_pool_size)
        self._read_index = 0
        
        # 後台執行緒池 (避免阻塞 asyncio 事件迴圈)
        self._executor = ThreadPoolExecutor(max_workers=read_pool_size + 1, 
                                             thread_name_prefix="kuzu")

    async def write(self, cypher: str, parameters: dict = None) -> bool:
        """序列化寫入 — 所有寫入操作排隊等待"""
        async with self._write_lock:  # ← 確保同一時間只有一個寫入
            loop = asyncio.get_event_loop()
            return await loop.run_in_executor(
                self._executor,
                self._sync_execute,      # 同步呼叫
                self._write_conn, 
                cypher, 
                parameters
            )

    async def read(self, cypher: str, parameters: dict = None) -> list:
        """並行讀取 — 從連線池取得連線"""
        async with self._read_semaphore:  # ← 限制並發讀取數
            conn = self._get_read_conn()
            loop = asyncio.get_event_loop()
            return await loop.run_in_executor(
                self._executor,
                self._sync_query,
                conn,
                cypher,
                parameters
            )

    def _sync_execute(self, conn, cypher, parameters):
        """在執行緒池中執行的同步寫入"""
        conn.execute(cypher, parameters=parameters or {})
        return True

    def _sync_query(self, conn, cypher, parameters):
        """在執行緒池中執行的同步查詢"""
        result = conn.execute(cypher, parameters=parameters or {})
        return [dict(row) for row in result.get_as_df().to_dict('records')]

    def _get_read_conn(self):
        """輪詢 (Round-Robin) 取得讀取連線"""
        conn = self._read_pool[self._read_index % len(self._read_pool)]
        self._read_index += 1
        return conn
```

**關鍵改進點**：

| 改進 | 說明 |
|------|------|
| `asyncio.Lock` 寫入序列化 | 避免並發寫入導致的資料毀損 |
| `run_in_executor` | 將同步阻塞呼叫移至 ThreadPoolExecutor，不阻塞事件迴圈 |
| Read Connection Pool | KuzuDB 支援多讀取連線並行，提升查詢吞吐量 |
| Write-Ahead 考量 | 未來可在寫入前先記錄 WAL (Write-Ahead Log) 到 SQLite，崩潰時可重播 |

---

#### 18.2.3 系統擴展性與解耦 (Scalability & Decoupling)

**現狀問題**

檢視 [task_queue.py](backend/services/task_queue.py)：

```python
# 模組層級全域單例 — 硬綁定到 asyncio + SQLite
task_queue = TaskQueue()
```

耦合鏈分析：

```
watcher.py  ──import──► task_queue (module-level singleton)
app_anytype.py ──import──► task_queue
tasks.py    ──import──► task_queue

問題：
1. 所有模組直接 import 具體實作，無抽象介面
2. asyncio.Queue 是 in-process 的，多 Worker 進程無法共享
3. SQLite 是單檔案資料庫，多進程寫入會產生 SQLITE_BUSY
4. 無法水平擴展 — 增加第二台機器時任務佇列不互通
```

**架構級解決方案：Backend Interface + Strategy Pattern**

```python
# === Pseudocode: Abstract TaskBackend Interface ===

from abc import ABC, abstractmethod
from typing import Protocol

class TaskBackend(Protocol):
    """任務佇列後端抽象介面
    
    Phase 1: SQLiteBackend (現狀)
    Phase 4: CeleryBackend / RedisBackend (叢集)
    遵循 OCP (開放封閉原則) — 擴展新後端不需修改現有程式碼
    """

    async def enqueue(self, task_id: str, task_type: str, payload: dict) -> None:
        """將任務放入佇列"""
        ...

    async def dequeue(self) -> tuple[str, str, dict] | None:
        """從佇列取出任務 (blocking with timeout)"""
        ...

    async def update_status(self, task_id: str, status: str, **kwargs) -> None:
        """更新任務狀態"""
        ...

    async def get_task(self, task_id: str) -> dict | None:
        """查詢任務"""
        ...

    async def list_tasks(self, limit: int = 50) -> list[dict]:
        """列出任務"""
        ...


class SQLiteTaskBackend:
    """Phase 1: 現有的 SQLite 實作 (單機)"""
    # ... 將目前 TaskQueue 的 SQLite 邏輯移入此類


class CeleryTaskBackend:
    """Phase 4: Celery + Redis 實作 (叢集)"""

    def __init__(self, broker_url: str):
        from celery import Celery
        self.celery_app = Celery('bruv', broker=broker_url)

    async def enqueue(self, task_id: str, task_type: str, payload: dict):
        self.celery_app.send_task(
            f'bruv.tasks.{task_type}',
            args=[task_id, payload],
            task_id=task_id
        )
    # ...


class TaskQueue:
    """門面 (Facade) — 根據配置選擇後端"""

    def __init__(self, backend: TaskBackend | None = None):
        if backend is None:
            # 根據環境變數決定後端
            backend_type = os.getenv("TASK_BACKEND", "sqlite")
            if backend_type == "celery":
                self._backend = CeleryTaskBackend(os.getenv("CELERY_BROKER_URL"))
            else:
                self._backend = SQLiteTaskBackend()
        else:
            self._backend = backend

    async def create_and_enqueue(self, task_type, **kwargs):
        task_id = str(uuid.uuid4())
        await self._backend.enqueue(task_id, task_type, kwargs)
        return task_id
```

**遷移路徑**：

```
Phase 1 (現在):  TASK_BACKEND=sqlite   → SQLiteTaskBackend
Phase 4 (叢集):  TASK_BACKEND=celery   → CeleryTaskBackend
                 CELERY_BROKER_URL=redis://redis:6379/2

只需修改 .env 環境變數，零程式碼修改即可切換。
```

**額外建議**：

- 為 `AgentService` 也引入同樣的 Backend Pattern — 目前 `httpx.AsyncClient` 在每個方法中都 `async with` 新建 Client，應改用 `app.state.http_client` 共享連線池
- 引入 **Circuit Breaker** (斷路器) — 當 RAGFlow 或 Dify 服務掛掉時，避免排隊的請求持續等待超時：

```python
# Circuit Breaker 狀態機
CLOSED (正常) → 連續 5 次失敗 → OPEN (拒絕所有請求，直覺返回 503)
OPEN → 30 秒後 → HALF-OPEN (放行 1 個探測請求)
HALF-OPEN → 成功 → CLOSED | 失敗 → OPEN
```

---

#### 18.2.4 可觀測性與除錯 (Observability)

**現狀問題**

```python
# app_anytype.py 第 53-56 行
logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s - %(name)s - %(levelname)s - %(message)s'
)
```

在 9 個 Docker 容器 + 2 個原生進程的架構中：

| 問題 | 說明 |
|------|------|
| 無 Correlation ID | 一個使用者請求穿過 Nginx → FastAPI → Dify → RAGFlow，日誌散落在 4 個不同的 stdout，無法串聯 |
| 非結構化日誌 | 純文字格式無法被日誌系統解析、查詢、聚合 |
| 無 Metrics | 沒有 API 回應時間、錯誤率、佇列深度等即時指標 |
| 日誌散落 | 每個 Docker 容器的日誌獨立，需要逐一 `docker logs` 查看 |

**架構級解決方案：輕量級可觀測性堆疊 (適合地端單機)**

```
┌──────────────────────────────────────────────────────────┐
│               可觀測性三根柱子 (Three Pillars)              │
│                                                          │
│  1. Structured Logging  → Loki (輕量日誌聚合)             │
│  2. Metrics             → Prometheus + Grafana            │
│  3. Distributed Tracing → OpenTelemetry (最小化實作)       │
└──────────────────────────────────────────────────────────┘
```

**Step 1: 結構化日誌 + Correlation ID**

```python
# === Pseudocode: Structured Logging Middleware ===

import uuid
import json
import logging
from contextvars import ContextVar

# 每個請求的唯一追蹤 ID
request_id_var: ContextVar[str] = ContextVar('request_id', default='-')

class StructuredLogFormatter(logging.Formatter):
    """JSON 結構化日誌格式器"""
    def format(self, record):
        return json.dumps({
            "timestamp": self.formatTime(record),
            "level": record.levelname,
            "logger": record.name,
            "message": record.getMessage(),
            "request_id": request_id_var.get('-'),
            "module": record.module,
            "line": record.lineno,
            # 自動附加 exception traceback
            "exception": self.formatException(record.exc_info) if record.exc_info else None
        }, ensure_ascii=False)


class RequestTracingMiddleware:
    """為每個 HTTP 請求注入 Correlation ID"""

    async def __call__(self, request, call_next):
        # 從 Header 中取得或生成 Request ID
        req_id = request.headers.get("X-Request-ID", str(uuid.uuid4())[:8])
        request_id_var.set(req_id)

        # 將 Request ID 傳播到 downstream 呼叫
        response = await call_next(request)
        response.headers["X-Request-ID"] = req_id

        # 轉發到 Dify/RAGFlow 時也附加此 Header
        # httpx 呼叫時: headers["X-Request-ID"] = request_id_var.get()
        return response
```

**Step 2: 地端日誌聚合方案 (不需要雲端)**

```yaml
# 新增到 docker-compose.yml 的輕量級可觀測性容器
# 總共只增加 ~300MB RAM

loki:
  image: grafana/loki:2.9
  ports:
    - "127.0.0.1:3100:3100"
  volumes:
    - loki_data:/loki
  # 資源極低：~50MB RAM

promtail:
  image: grafana/promtail:2.9
  volumes:
    - /var/run/docker.sock:/var/run/docker.sock:ro  # 自動採集所有容器日誌
  # 自動採集 9 個容器 + FastAPI 的日誌並推送到 Loki

grafana:
  image: grafana/grafana:10
  ports:
    - "127.0.0.1:3000:3000"
  # 統一儀表板：日誌查詢 + Metrics 圖表
```

**Step 3: 最小化 OpenTelemetry 實作**

```python
# === app_anytype.py lifespan 中加入 ===

from opentelemetry import trace
from opentelemetry.sdk.trace import TracerProvider
from opentelemetry.sdk.trace.export import SimpleSpanProcessor, ConsoleSpanExporter
from opentelemetry.instrumentation.fastapi import FastAPIInstrumentor
from opentelemetry.instrumentation.httpx import HTTPXClientInstrumentor

# 最小化配置 — 先用 Console 輸出，未來可切換為 OTLP Exporter
provider = TracerProvider()
provider.add_span_processor(SimpleSpanProcessor(ConsoleSpanExporter()))
trace.set_tracer_provider(provider)

# 自動為 FastAPI 路由加入 Span
FastAPIInstrumentor.instrument_app(app)

# 自動為 httpx 呼叫加入 Span (追蹤 Dify/RAGFlow 請求)
HTTPXClientInstrumentor().instrument()
```

這樣一個請求的完整追蹤鏈就自動建立：

```
[Span] FastAPI: POST /api/dify/chat  (req_id=abc123)
  └── [Span] httpx: POST http://localhost:5001/v1/chat  (req_id=abc123)
       └── [Dify Internal Spans...]
```

---

### 18.3 程式碼級建議

#### 18.3.1 watcher.py `_process_file()` — 引入 Saga + 重試

改進前 (現狀)：
```python
def _process_file(self, file_path):
    upload_result = self.rag_client.upload_file(...)  # A: 可能成功
    self._add_to_graph(file_path, upload_result)      # B: 可能失敗 → 不一致！
```

改進後：
```python
def _process_file(self, file_path: Path) -> None:
    saga = SagaLog(file_path)
    ragflow_doc_id = None

    try:
        # Step A: RAGFlow Upload (with retry)
        for attempt in range(3):  # 最多重試 3 次
            try:
                upload_result = self.rag_client.upload_file(
                    dataset_id=self.dataset_id,
                    file_path=str(file_path)
                )
                ragflow_doc_id = extract_doc_id(upload_result)
                saga.mark_step("ragflow_upload", "COMPLETED", doc_id=ragflow_doc_id)
                break
            except (httpx.TimeoutException, httpx.ConnectError) as e:
                if attempt < 2:
                    time.sleep(2 ** attempt)  # Exponential backoff: 1s, 2s, 4s
                    continue
                saga.mark_step("ragflow_upload", "FAILED", error=str(e))
                raise

        # Step B: KuzuDB Write
        entity_id = self._add_to_graph(file_path, upload_result, graph_id)
        if entity_id:
            saga.mark_step("kuzu_write", "COMPLETED", entity_id=entity_id)
        else:
            saga.mark_step("kuzu_write", "FAILED")
            # 補償: 刪除已上傳的 RAGFlow 文件
            if ragflow_doc_id:
                self.rag_client.delete_document(ragflow_doc_id)
                logger.warning(f"補償完成: 已撤銷 RAGFlow 上傳 {ragflow_doc_id}")
            return

        # Step C: Excel Parse (optional, 失敗不補償，只記錄)
        if file_path.suffix.lower() == '.xlsx' and entity_id:
            self._parse_excel_and_link(file_path, entity_id, graph_id)

    except Exception as e:
        logger.error(f"Saga 失敗: {file_path.name} - {e}", exc_info=True)
        # 寫入 Dead Letter Queue
        self._record_dlq(file_path, saga, str(e))
```

#### 18.3.2 KuzuDBManager — 加入 asyncio.Lock 的最小改動

不需要完整重寫，只需在現有 `KuzuDBManager` 上包裝一層：

```python
# === backend/core/kuzu_manager.py — 最小改動 ===

import asyncio
from concurrent.futures import ThreadPoolExecutor

class AsyncKuzuWrapper:
    """為現有 KuzuDBManager 加入 async 安全層
    
    使用方式：
        wrapper = AsyncKuzuWrapper(kuzu_manager)
        result = await wrapper.safe_write("MERGE ...", params)
        result = await wrapper.safe_read("MATCH ...", params)
    """

    def __init__(self, manager: KuzuDBManager):
        self._manager = manager
        self._write_lock = asyncio.Lock()
        self._executor = ThreadPoolExecutor(max_workers=4, thread_name_prefix="kuzu")

    async def safe_write(self, cypher: str, parameters: dict = None) -> bool:
        """所有寫入操作在 Lock 保護下序列化執行"""
        async with self._write_lock:
            loop = asyncio.get_event_loop()
            return await loop.run_in_executor(
                self._executor,
                lambda: self._manager.conn.execute(cypher, parameters=parameters or {})
            )

    async def safe_read(self, cypher: str, parameters: dict = None) -> list:
        """讀取操作不需要 Lock，但需要避免阻塞事件迴圈"""
        loop = asyncio.get_event_loop()
        return await loop.run_in_executor(
            self._executor,
            lambda: self._manager.query(cypher, parameters)
        )
```

#### 18.3.3 TaskQueue — 為未來遷移預留介面

最小改動，不影響現有行為：

```python
# === backend/services/task_queue.py — 在檔案頂部加入 ===

from typing import Protocol, runtime_checkable

@runtime_checkable
class TaskBackend(Protocol):
    """任務後端抽象介面 — 未來遷移到 Celery 時只需實作此介面"""
    def create_task(self, task_type: str, **kwargs) -> str: ...
    def get_task(self, task_id: str) -> dict | None: ...
    def update_status(self, task_id: str, status: str, **kwargs) -> None: ...
    def list_tasks(self) -> list[dict]: ...

# 現有的 TaskQueue 類別自動 "實作" 此介面 (Duck Typing)
# 未來新增 CeleryTaskQueue 時，只需實作同一介面
```

---

### 18.4 優先級行動計劃

| 優先級 | 項目 | 預估工時 | 風險降低 |
|--------|------|---------|---------|
| **P0** | KuzuDB asyncio.Lock + run_in_executor | 2 小時 | 消除併發寫入毀損風險 |
| **P0** | watcher.py 加入補償機制 (基礎版) | 3 小時 | 消除幽靈文件問題 |
| **P1** | 結構化日誌 + Request ID Middleware | 2 小時 | 大幅降低 MTTR |
| **P1** | TaskBackend Protocol 抽象介面 | 1 小時 | 為 Phase 4 預留擴展點 |
| **P2** | Loki + Grafana Docker 容器 | 1 小時 | 集中式日誌查詢 |
| **P2** | CircuitBreaker for Dify/RAGFlow | 3 小時 | 避免級聯故障 |
| **P3** | 完整 Saga Orchestrator + DLQ | 8 小時 | 企業級資料一致性 |
| **P3** | OpenTelemetry 分散式追蹤 | 4 小時 | 跨服務請求追蹤 |

---

## 19. 變更紀錄

| 日期 | 版本 | 變更內容 |
|------|------|---------|
| 2026-02-07 | v3.0 | 初始架構文件 (Anytype Edition) |
| 2026-02-10 | v3.1 | 整合為單一規劃主文件，新增四層架構概述、安全縱深防禦五層模型、硬體規格建議、未來擴展路線圖、變更紀錄 |
| 2026-02-10 | v3.2 | 架構深度審查 — 新增紅隊測試報告 (§18)：資料一致性 Saga Pattern、KuzuDB 併發控制、TaskBackend 抽象介面、輕量級可觀測性方案、程式碼級 Pseudocode、優先級行動計劃 |
| 2026-02-11 | v3.3 | **§18.4 優先級行動計劃實作完成 — 整合測試 15/15 通過**。詳見 `docs/SAGA_TEST_FINAL_REPORT.md` |

### v3.3 變更明細

**測試結果 (15/15 Pass)**

| 測試組 | 項目數 | 結果 |
|--------|-------|------|
| Backend 可用性 | 2 | ✅ |
| CircuitBreaker 狀態 | 6 | ✅ |
| DLQ 端點 | 2 | ✅ |
| Saga 補償機制 | 2 | ✅ |
| 結構化日誌 + X-Request-ID | 2 | ✅ |
| OpenTelemetry 狀態 | 1 | ✅ |

**修復的 5 個 Bug**

1. **RAGFlow URL 轉換錯誤** — `app_anytype.py`、`system.py` 中 `/api/v1` 被錯誤轉為 `/v1`，導致 API 呼叫失敗。已移除轉換邏輯，直接使用 config URL。
2. **rag_client 未檢查回應 body** — RAGFlow 以 HTTP 200 回傳業務層錯誤 (`code=401`)，`raise_for_status()` 無法偵測。已新增 `_check_response()` 與 `RAGFlowAPIError`。
3. **`delete_document()` 簽章不匹配** — 缺少 `dataset_id` 參數且 API 路徑格式錯誤。已更新為 v1 格式 `/datasets/{id}/documents`。
4. **httpx DELETE 不支援 `json=`** — `httpx.Client.delete()` 無法傳遞 JSON body。改用 `client.request("DELETE", ..., content=body)`。
5. **`.env` API Key 遮罩值** — `RAGFLOW_API_KEY` 存放的是遮罩字串而非真實金鑰。已修正。

**已知問題**: RAGFlow MySQL schema 拼字錯誤 (`process_duation` → `process_duration`)，導致檔案上傳失敗，需由 RAGFlow 端修復。
