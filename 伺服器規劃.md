# BruV Enterprise Server — 企業級地端化伺服器規劃

> **版本**：v5.1 Anytype Edition  
> **最後更新**：2026-02-17  
> **定位**：企業級、完全地端部署的 AI 知識管理伺服器  
> **本文件為唯一規劃主文件，所有架構討論的變動皆在此更新。**

---

## 目錄

1. [系統總覽](#1-系統總覽)
2. [四層架構概述](#2-四層架構概述)
3. [核心引擎整合](#3-核心引擎整合)
4. [前端架構](#4-前端架構)
5. [後端架構](#5-後端架構)
6. [API 端點一覽](#6-api-端點一覽)
7. [資料庫與儲存](#7-資料庫與儲存)
8. [Docker 容器服務](#8-docker-容器服務)
9. [安全縱深防禦](#9-安全縱深防禦)
10. [配置管理](#10-配置管理)
11. [任務佇列與持久化](#11-任務佇列與持久化)
12. [檔案監控與自動匯入](#12-檔案監控與自動匯入)
13. [Nginx 反向代理](#13-nginx-反向代理)
14. [依賴清單](#14-依賴清單)
15. [部署與啟動方式](#15-部署與啟動方式)
16. [硬體建議規格](#16-硬體建議規格)
17. [未來擴展路線圖](#17-未來擴展路線圖)
18. [架構深度審查 — 紅隊測試報告](#18-架構深度審查--紅隊測試報告-2026-02-10)
19. [變更紀錄](#19-變更紀錄)

---

## 1. 系統總覽

BruV Enterprise Server 是一套企業級、完全地端部署的 AI 知識管理平台。  
它整合了三大核心引擎：

| # | 引擎 | 用途 |
|---|------|------|
| 1 | **Dify** | 大語言模型 (LLM) 對話平台 — AI 聊天、自動化工作流 |
| 2 | **RAGFlow** | 檢索增強生成 (RAG) 知識檢索引擎 — 文件解析與語義搜尋 |
| 3 | **KuzuDB** | 圖資料庫 — 知識圖譜的節點與關係管理 |

前端提供 **2D (AntV G6)** 與 **3D (Three.js + 3D-Force-Graph)** 雙模式的知識圖譜視覺化介面，支援拖放操作、跨圖譜關聯、智能推薦連結、**圖譜刪除管理**、**Tag 標籤篩選與編輯**等功能。

**v5.1 新增**：連線管理系統 (Connection Manager) — 取代舊的 flat config，支援多連線 CRUD、即時測試、自動偵測可用服務；Tag 標籤系統全鏈路支援 (LLM 自動生成 → KuzuDB 儲存 → 前端過濾/編輯/色點指示器)；3D 圖譜平行連線曲率、連線互動、方向箭頭；Settings 頁面全面重寫。

**v5.0 新增**：Excel 批量智能匯入引擎大幅升級 — 欄位智能提取 (免 LLM)、LLM 結果快取 (MD5 去重)、自適應大批次、RAGFlow 合併上傳 (按類型分組)、3000 筆大規模匯入支援、記憶體管理最佳化。

**v3.4 新增**：節點自動互連引擎 — 基於 Link Domain 歸類與關鍵字共現分析，將 RAGFlow 解析後的資源節點從星狀拓撲升級為網狀知識圖譜。

**v3.5 新增**：前端抓取邏輯統一 — 所有 API 呼叫收斂至 `apiClient` 高層函式 + `graphStore` 統一管理，消除各頁面重複抓取與硬編碼路徑。

**v3.6 新增**：RAGFlow Hybrid Search + Rerank — 檢索端點升級為混合檢索（向量 + 關鍵字權重可調），支援 Rerank 模型重排序，擴大 top_k 初篩範圍以提升召回率。

**v3.7 新增**：Ollama 本地 LLM 引擎 — 以 Docker 容器部署 Ollama，預載 llama3 (4.7 GB) 與 nomic-embed-text (274 MB) 模型，支援 GPU 直通加速，RAGFlow / Dify 可透過 Docker 內網 `http://ollama:11434` 呼叫，實現完全離線推理。

**所有資料與模型完全執行在本地環境，不依賴任何外部雲端服務，滿足企業對資料隱私與合規性的嚴格要求。**

### 主要技術棧

| 分類 | 技術 |
|------|------|
| 前端 | Vue 3 + Vite 6 + Pinia + Element Plus + Tailwind CSS + 企業級深色主題 |
| 後端 | Python FastAPI + Uvicorn (ASGI) |
| 圖資料庫 | KuzuDB |
| AI 引擎 | Dify (LLM) + RAGFlow (RAG) |
| 容器化 | Docker Compose (15 個微服務) |
| 本地 LLM | Ollama (llama3 + qwen2.5:14b + bge-m3 + nomic-embed-text) |
| 反向代理 | Nginx (SSL/TLS + 安全標頭 + 速率限制) |
| 物件儲存 | MinIO (S3 相容) |
| 搜尋引擎 | Elasticsearch 8.11 |
| 關聯式資料庫 | PostgreSQL 15 (Dify) / MySQL 8.0 (RAGFlow) |
| 快取 | Redis 7 (兩組獨立實例) |

---

## 2. 四層架構概述

| 層級 | 技術組件 | 職責 |
|------|---------|------|
| **展示層** | Vue 3 + Vite 6 + Element Plus + AntV G6 / Three.js | 知識圖譜 2D/3D 視覺化、AI 對話、系統管理 UI (Enterprise Navy 深色主題) |
| **接入層** | Nginx (SSL/TLS + 速率限制 + 安全標頭) | HTTPS 終端、反向代理、WAF 防護 |
| **業務層** | FastAPI + Uvicorn (ASGI) | API 路由、認證、意圖路由、任務佇列、檔案監控 |
| **資料層** | KuzuDB + PostgreSQL + MySQL + ES + Redis×2 + MinIO + SQLite | 圖資料庫、全文搜尋、快取、物件儲存、任務持久化 |

### 系統完整運作圖 (v4.0)

> 以下為 BruV Enterprise Server 全功能完整運作圖，涵蓋所有 15 個 Docker 容器、7 條 API 路由、  
> 4 個背景服務、11 個資料儲存、3 組可觀測性堆疊，以及前端 15 個頁面路由。

```
╔══════════════════════════════════════════════════════════════════════════════════════════════════════════════╗
║                                   BruV Enterprise Server v5.0 — 完整運作圖                                  ║
╠══════════════════════════════════════════════════════════════════════════════════════════════════════════════╣
║                                                                                                            ║
║   ┌─────────────────────────────────────────────────────────────────────────────┐                           ║
║   │                         使用者瀏覽器 (Enterprise Navy 深色主題)                │                           ║
║   │                                                                             │                           ║
║   │  ┌─ 知識圖譜 ──────────────┐  ┌─ AI 對話 ──────────┐  ┌─ 系統管理 ────────┐  │                           ║
║   │  │ /nexus     知識中樞主頁  │  │ /chat   Dify AI 聊天│  │ /settings 系統設定│  │                           ║
║   │  │ /graph-page 2D 圖譜操作 │  │ AgentService 意圖路由│  │ /monitor  系統監控│  │                           ║
║   │  │ /graph-3d   3D 圖譜渲染 │  │  ├ RAG → 知識檢索   │  │ /login    認證登入│  │                           ║
║   │  │ /cross-graph 跨圖譜關聯 │  │  ├ CHAT → LLM 對話  │  │ 使用者管理 (CRUD) │  │                           ║
║   │  │ /import     資料匯入    │  │  └ AUTO → 自動化    │  │ 連線測試 / DLQ    │  │                           ║
║   │  │ /file-import 檔案匯入  │  └───────────────────┘  │ CircuitBreaker 狀態│ │                           ║
║   │  │ /create     建立節點    │                          └──────────────────┘  │                           ║
║   │  │ /batch-repair 批量修復 │  ┌─ 其他 ─────────────┐                         │                           ║
║   │  │ /timeline   時間線     │  │ /graph  舊版 2D 圖譜 │  ┌─ 核心元件 ────────┐  │                           ║
║   │  └─────────────────────┘  │ /*       404 NotFound│  │ Sidebar 側邊導航   │  │                           ║
║   │                            └──────────────────────┘  │ TopBar 頂部列     │  │                           ║
║   │  ┌─ 前端技術棧 ──────────────────────────────────┐     │ Pinia graphStore  │  │                           ║
║   │  │ Vue 3 + Vite 6 │ Pinia │ Element Plus        │     │ GraphDataManager  │  │                           ║
║   │  │ AntV G6 (2D)   │ Three.js + 3D-Force-Graph  │     │ apiClient 統一呼叫│  │                           ║
║   │  │ Tailwind CSS    │ markdown-it │ xlsx          │     │ authFetch Token   │  │                           ║
║   │  └───────────────────────────────────────────────┘     └──────────────────┘  │                           ║
║   └──────────────────────────────┬──────────────────────────────────────────────┘                           ║
║                                  │ HTTP / HTTPS                                                             ║
║   ═══════════════════════════════╪══════════════════════════════════════════════════════════ 接入層 ══════    ║
║                                  ▼                                                                          ║
║   ┌──────────────────────────────────────────────────────────────────────────────────────────┐              ║
║   │                           Nginx 反向代理 (HTTPS :443 / HTTP :80)                          │              ║
║   │                                                                                          │              ║
║   │  SSL/TLS 1.2-1.3 終端 │ HSTS 1年 │ WAF 安全標頭 (CSP / X-Frame / Permissions-Policy)    │              ║
║   │  速率限制: API 30r/s (burst 50) │ Upload 5r/s (burst 10) │ Gzip Level 6                 │              ║
║   │  路徑封鎖: .env / .git / .sql / .log │ 靜態資源快取 30天 │ 隱藏版本 (server_tokens off) │              ║
║   └──────────────────────────────┬───────────────────────────────────────────────────────────┘              ║
║                                  │                                                                          ║
║   ═══════════════════════════════╪══════════════════════════════════════════════════════════ 業務層 ══════    ║
║                                  ▼                                                                          ║
║   ┌──────────────────────────────────────────────────────────────────────────────────────────────────────┐  ║
║   │                           FastAPI 後端 (Port 8000 · Uvicorn ASGI)                                    │  ║
║   │                                                                                                      │  ║
║   │  ╔═ 中間件鏈 (由外到內) ═══════════════════════════════════════════════════════════════════════╗      │  ║
║   │  ║ ① CORSMiddleware (白名單 Origin) → ② RequestTracing (X-Request-ID) → ③ Auth (Bearer Token) ║      │  ║
║   │  ╚═════════════════════════════════════════════════════════════════════════════════════════════╝      │  ║
║   │                                                                                                      │  ║
║   │  ┌─ API 路由 (7 組 Router) ────────────────────────────────────────────────────────────────────┐      │  ║
║   │  │                                                                                             │      │  ║
║   │  │  /api/auth/*     認證登入·狀態查詢                                                          │      │  ║
║   │  │  /api/graph/*    知識圖譜 CRUD·Cypher 查詢·元資料管理·圖譜刪除(級聯)·節點互連觸發           │      │  ║
║   │  │  /api/graph/*    Excel/CSV 智能匯入·LLM Prompt v2.0 自動標題/描述/關係推薦                  │      │  ║
║   │  │  /api/dify/*     Dify LLM 對話代理·動態 per-user API Key·AgentService 意圖路由              │      │  ║
║   │  │  /api/ragflow/*  RAGFlow 混合檢索 (Hybrid Search + Rerank)·文件上傳·解析狀態               │      │  ║
║   │  │  /api/system/*   系統配置讀寫·連線測試·通用上傳·CircuitBreaker 狀態·Saga DLQ·深度健康檢查   │      │  ║
║   │  │  /api/media/*    媒體庫 CRUD·MinIO 物件儲存 (本地 fallback)·標籤分類·OCR                    │      │  ║
║   │  │  /api/tasks/*    任務狀態查詢 (列表/單一)                                                    │      │  ║
║   │  └─────────────────────────────────────────────────────────────────────────────────────────────┘      │  ║
║   │                                                                                                      │  ║
║   │  ┌─ 核心模組 (backend/core/) ─────────────────────────────────────────────────────────────────┐      │  ║
║   │  │  config.py        Pydantic Settings · config.json > .env > 預設值 · 原子寫入 · LRU 快取    │      │  ║
║   │  │  auth.py          Bearer Token + SHA-256 雜湊 · 白名單免認證 · 自動生成 Token             │      │  ║
║   │  │  kuzu_manager.py  KuzuDB CRUD · AsyncKuzuWrapper (asyncio.Lock 序列化 + ThreadPool)       │      │  ║
║   │  │  circuit_breaker  CLOSED→OPEN→HALF_OPEN 斷路器 · dify_breaker + ragflow_breaker           │      │  ║
║   │  │  logging.py       JSON 結構化日誌 · X-Request-ID (ContextVar) · 生產/開發雙模式            │      │  ║
║   │  │  telemetry.py     OpenTelemetry 分散式追蹤 (可選) · FastAPI + httpx 自動儀器化             │      │  ║
║   │  └────────────────────────────────────────────────────────────────────────────────────────────┘      │  ║
║   │                                                                                                      │  ║
║   │  ┌─ 服務層 (backend/services/) ───────────────────────────────────────────────────────────────┐      │  ║
║   │  │  agent_service    意圖路由器 (RAG / CHAT / AUTOMATION) · 中文關鍵字匹配                    │      │  ║
║   │  │  task_queue       asyncio 背景 Worker · SQLite 持久化 · 進度追蹤 · 上限 500 條            │      │  ║
║   │  │  saga.py          Saga Orchestrator · 補償操作 · SagaLog SQLite · FileImportSaga          │      │  ║
║   │  │  watcher.py       watchdog 檔案監控 · Saga 補償 · 指數退避重試 ×3 · DLQ                   │      │  ║
║   │  │                   節點互連引擎: Link Domain 歸類 + 關鍵字共現 (Step D)                     │      │  ║
║   │  └────────────────────────────────────────────────────────────────────────────────────────────┘      │  ║
║   │                                                                                                      │  ║
║   │  ┌─ Lifespan 背景服務 (啟動時初始化 · 關閉時清理) ────────────────────────────────────────────┐      │  ║
║   │  │  ① 結構化日誌初始化  ② TaskQueue Worker (asyncio)  ③ httpx 連線池 (max 50)               │      │  ║
║   │  │  ④ KuzuDBManager + AsyncKuzuWrapper  ⑤ WatcherService (Saga + 重試 + DLQ)               │      │  ║
║   │  │  ⑥ OpenTelemetry (可選)  ⑦ 全部掛載至 app.state                                         │      │  ║
║   │  └────────────────────────────────────────────────────────────────────────────────────────────┘      │  ║
║   │                                                                                                      │  ║
║   │  ┌─ 安全層 ──────────────────────────────────────────────────────────────────────────────────┐      │  ║
║   │  │  Cypher 雙重驗證 (前端 regex + 後端黑名單) · 查詢限制 2000 字元 · 上傳限制 100MB           │      │  ║
║   │  │  config.json 原子寫入 + threading.Lock · 密碼/金鑰 .env 注入 · Docker ${VAR:?} 強制必填   │      │  ║
║   │  └────────────────────────────────────────────────────────────────────────────────────────────┘      │  ║
║   └──────┬──────────────┬───────────────┬───────────────┬───────────────┬─────────────────────────────────┘  ║
║          │              │               │               │               │                                    ║
║   ═══════╪══════════════╪═══════════════╪═══════════════╪═══════════════╪═══════════════════════ 資料層 ═══   ║
║          │              │               │               │               │                                    ║
║          ▼              ▼               ▼               ▼               ▼                                    ║
║   ┌─────────────┐ ┌──────────┐  ┌─────────────┐ ┌─────────────┐ ┌──────────────────────┐                   ║
║   │  Dify 堆疊   │ │  Ollama  │  │ RAGFlow 堆疊 │ │ 可觀測性堆疊 │ │   本地儲存            │                   ║
║   │  (4 容器)    │ │  (GPU)   │  │  (5 容器)    │ │  (3 容器)   │ │   ~/BruV_Data/       │                   ║
║   │             │ │          │  │             │ │             │ │                      │                   ║
║   │ ┌─────────┐ │ │ ┌──────┐ │  │ ┌─────────┐ │ │ ┌─────────┐ │ │ ┌──────────────────┐ │                   ║
║   │ │Dify Web │ │ │ │Ollama│ │  │ │RAGFlow  │ │ │ │  Loki   │ │ │ │ kuzu_db/         │ │                   ║
║   │ │ :82     │ │ │ │:11434│ │  │ │:81/:9380│ │ │ │  :3100  │ │ │ │ (KuzuDB 圖資料庫) │ │                   ║
║   │ └─────────┘ │ │ │      │ │  │ │ :9381   │ │ │ └─────────┘ │ │ └──────────────────┘ │                   ║
║   │ ┌─────────┐ │ │ │llama3│ │  │ └─────────┘ │ │ ┌─────────┐ │ │ ┌──────────────────┐ │                   ║
║   │ │Dify API │ │ │ │bge-m3│ │  │ ┌─────────┐ │ │ │Promtail │ │ │ │ Auto_Import/     │ │                   ║
║   │ │ :5001   │ │ │ │nomic │ │  │ │  ES     │ │ │ │ (採集)  │ │ │ │ (watchdog 監控)  │ │                   ║
║   │ └─────────┘ │ │ └──────┘ │  │ │  :9200  │ │ │ └─────────┘ │ │ └──────────────────┘ │                   ║
║   │ ┌─────────┐ │ │  GPU 直通 │  │ └─────────┘ │ │ ┌─────────┐ │ │ ┌──────────────────┐ │                   ║
║   │ │PostgreSQL│ │ │  nvidia  │  │ ┌─────────┐ │ │ │ Grafana │ │ │ │ media_library/   │ │                   ║
║   │ │  :5432  │ │ └──────────┘  │ │ MySQL   │ │ │ │  :3000  │ │ │ │ (媒體庫 / MinIO) │ │                   ║
║   │ └─────────┘ │      ▲        │ │  8.0    │ │ │ └─────────┘ │ │ └──────────────────┘ │                   ║
║   │ ┌─────────┐ │      │        │ └─────────┘ │ └─────────────┘ │ ┌──────────────────┐ │                   ║
║   │ │ Redis   │ │      │        │ ┌─────────┐ │                 │ │ auth_token.json   │ │                   ║
║   │ │  :6379  │ │      │        │ │ MinIO   │ │                 │ │ (SHA-256 雜湊)    │ │                   ║
║   │ └─────────┘ │      │        │ │:9000/01 │ │                 │ └──────────────────┘ │                   ║
║   └──────┬──────┘      │        │ └─────────┘ │                 │ ┌──────────────────┐ │                   ║
║          │             │        │ ┌─────────┐ │                 │ │ task_queue.db     │ │                   ║
║          └─────────────┘        │ │ Redis   │ │                 │ │ (SQLite 任務持久化)│ │                   ║
║          Dify ←→ Ollama         │ │  :6379  │ │                 │ └──────────────────┘ │                   ║
║          (Docker 內網)          │ └─────────┘ │                 │ ┌──────────────────┐ │                   ║
║                                 └──────┬──────┘                 │ │ saga_log.db       │ │                   ║
║                                        │                        │ │ (Saga 步驟追蹤)   │ │                   ║
║                                        └────────────────────┐   │ └──────────────────┘ │                   ║
║                                        RAGFlow ←→ Ollama    │   │ ┌──────────────────┐ │                   ║
║                                        (Docker 內網)        │   │ │ saga_dlq.db       │ │                   ║
║                                                             │   │ │ (Dead Letter Queue)│ │                   ║
║                                                             │   │ └──────────────────┘ │                   ║
║                                                             │   │ ┌──────────────────┐ │                   ║
║                                                             │   │ │ config.json       │ │                   ║
║                                                             │   │ │ (系統配置)        │ │                   ║
║                                                             │   │ └──────────────────┘ │                   ║
║                                                             │   └──────────────────────┘                   ║
║                                                             │                                               ║
║                                                             ▼                                               ║
║                                                     ┌──────────────┐                                       ║
║                                                     │   Ollama     │                                       ║
║                                                     │   :11434     │          bruv_network (bridge)         ║
║                                                     │  GPU 直通    │          所有 15 容器互聯               ║
║                                                     └──────────────┘                                       ║
╚══════════════════════════════════════════════════════════════════════════════════════════════════════════════╝
```

### 核心資料流

```
┌─────────────────────────────────────────────────────────────────────────────────────────────┐
│                                   六條主要資料流路徑                                          │
├─────────────────────────────────────────────────────────────────────────────────────────────┤
│                                                                                             │
│  ❶ AI 對話流 (使用者提問 → 智能回應)                                                        │
│  ─────────────────────────────────────                                                      │
│  瀏覽器 → Nginx → FastAPI Auth → AgentService 意圖路由                                     │
│                                    ├─ RAG 意圖 → RAGFlow Hybrid Search → Dify LLM 生成     │
│                                    ├─ CHAT 意圖 → Dify LLM 直接對話 (per-user API Key)      │
│                                    └─ AUTO 意圖 → 系統自動化 API                            │
│                                                                         → JSON → 瀏覽器    │
│                                                                                             │
│  ❷ 圖譜操作流 (知識圖譜視覺化與 CRUD)                                                       │
│  ──────────────────────────────────────                                                      │
│  瀏覽器 (G6 2D / Three.js 3D) → apiClient → FastAPI → KuzuDB (AsyncKuzuWrapper)            │
│  Cypher 查詢: 前端 regex 攔截 → 後端黑名單驗證 → KuzuDB 唯讀執行                           │
│  圖譜刪除: 確認對話框 → DELETE /metadata/{id}?cascade=true → 級聯刪除 → 切換主腦圖譜       │
│                                                                                             │
│  ❸ 檔案匯入流 (自動監控 + Saga 補償)                                                        │
│  ──────────────────────────────────────                                                      │
│  使用者放入檔案 → ~/Auto_Import/ → watchdog 偵測                                            │
│  → Saga Step A: 上傳至 RAGFlow (指數退避重試 ×3)                                            │
│  → Saga Step B: 同步元資料至 KuzuDB                                                        │
│  → Saga Step C: Excel 深度解析 + LLM Prompt v2.0 自動推薦                                  │
│  → Saga Step D: 節點互連引擎 (Link Domain + 關鍵字共現)                                     │
│  失敗: Step B 失敗 → 補償刪除 RAGFlow 文件 → 補償失敗 → DLQ → 管理員手動處理               │
│                                                                                             │
│  ❹ RAGFlow 知識檢索流                                                                       │
│  ────────────────────                                                                        │
│  /api/ragflow/query → RAGFlowClient.retrieve() → POST /retrieval                            │
│  參數: similarity_threshold · vector_similarity_weight · top_k (1024) · rerank_id           │
│  RAGFlow 內部: MinIO (檔案) → ES (語義索引) → MySQL (元資料) → Rerank → 排序結果            │
│                                                                                             │
│  ❺ 媒體庫操作流                                                                              │
│  ──────────────                                                                              │
│  瀏覽器上傳 → /api/media/upload → MinIO S3 物件儲存 (或本地 fallback ~/media_library/)      │
│  → 標籤分類 + OCR 文字辨識 → KuzuDB 關聯知識節點                                            │
│                                                                                             │
│  ❻ 可觀測性流 (日誌 + 監控)                                                                  │
│  ────────────────────────                                                                    │
│  所有 15 容器 → Docker stdout → Promtail (自動採集) → Loki (聚合) → Grafana (儀表板 :3000)  │
│  FastAPI 結構化 JSON 日誌 → X-Request-ID 關聯 → OpenTelemetry (可選 OTLP Export)            │
│  CircuitBreaker 狀態 (Dify/RAGFlow) → /api/system/circuit-breakers → 前端系統監控           │
│                                                                                             │
└─────────────────────────────────────────────────────────────────────────────────────────────┘
```

### Docker 容器清單 (14 個 · bruv_network)

```
┌──────────────────────────────────────────────────────────────────────────────────────────┐
│                      bruv_network (Docker Bridge)                                        │
│                                                                                          │
│  ┌─ Dify 堆疊 ─────────┐  ┌─ RAGFlow 堆疊 ─────────┐  ┌─ 可觀測性 ──────────────────┐ │
│  │ ① dify-web     :82  │  │ ⑤ ragflow  :81/:9380/81│  │ ⑪ loki       :3100         │ │
│  │ ② dify-api    :5001 │  │ ⑥ es01          :9200  │  │ ⑫ promtail   (採集器)      │ │
│  │ ③ dify-db   (PG 15) │  │ ⑦ ragflow-mysql (8.0)  │  │ ⑬ grafana    :3000         │ │
│  │ ④ dify-redis  (R7)  │  │ ⑧ ragflow-minio :9000  │  └──────────────────────────────┘ │
│  └──────────────────────┘  │ ⑨ ragflow-redis  (R7)  │                                   │
│                            └────────────────────────┘  ┌─ LLM 引擎 ─────────────────┐  │
│                                                        │ ⑭ ollama     :11434        │  │
│  Port 綁定: 全部 127.0.0.1 (僅本地)                     │    GPU 直通 (nvidia)        │  │
│  Docker 內網: http://ollama:11434                       │    llama3 + bge-m3 + nomic │  │
│  Volumes: 10 個持久化卷                                  └──────────────────────────────┘  │
└──────────────────────────────────────────────────────────────────────────────────────────┘
```

---

## 3. 核心引擎整合

```
┌────────────────────────────────────────────────────────────────────────────────────────────┐
│                              FastAPI 後端閘道 (Port 8000)                                   │
│                                                                                            │
│   ┌──────────────────┐   ┌────────────────────┐   ┌──────────────────┐   ┌──────────────┐ │
│   │    Dify           │   │    RAGFlow          │   │    KuzuDB        │   │   Ollama     │ │
│   │    LLM 對話平台    │   │    RAG 知識檢索      │   │    知識圖譜       │   │   本地 LLM   │ │
│   │    :5001 / :82    │   │    :9380 / :81      │   │    嵌入式         │   │   :11434     │ │
│   │    Per-user Key   │   │    Hybrid + Rerank  │   │    AsyncWrapper  │   │   GPU 直通   │ │
│   └────────┬─────────┘   └──────────┬─────────┘   └────────┬─────────┘   └──────┬───────┘ │
│            │                        │                       │                    │         │
│            │           ┌────────────┘                       │              ┌─────┘         │
│            ▼           ▼                                    ▼              ▼               │
│   ┌─────────────────────────────────────────────────────────────────────────────────────┐  │
│   │                       AgentService 意圖路由器                                        │  │
│   │                                                                                     │  │
│   │   使用者提問 ──► 中文關鍵字匹配 ──┬─► RAG 意圖   → RAGFlow 檢索 → Dify LLM 生成回應  │  │
│   │                                  ├─► CHAT 意圖  → Dify LLM 直接對話                 │  │
│   │                                  └─► AUTO 意圖  → 系統自動化 API 執行               │  │
│   │                                                                                     │  │
│   │   Dify/RAGFlow 內部皆透過 Docker 內網呼叫 Ollama (:11434) 進行本地推理              │  │
│   └─────────────────────────────────────────────────────────────────────────────────────┘  │
│                                                                                            │
│   ┌─ 檔案匯入 Saga 編排器 ────────────────────────────────────────────────────────────────┐ │
│   │                                                                                       │ │
│   │  ~/Auto_Import/ → watchdog → Step A: RAGFlow Upload (重試×3)                         │ │
│   │                             → Step B: KuzuDB 元資料同步 (失敗→補償刪除 RAGFlow 文件)  │ │
│   │                             → Step C: Excel 深度解析 + LLM Prompt v2.0               │ │
│   │                             → Step D: 節點互連引擎 (Domain + 關鍵字)                  │ │
│   │                             → 失敗: DLQ → /api/system/saga-dlq → 管理員處理          │ │
│   └───────────────────────────────────────────────────────────────────────────────────────┘ │
└────────────────────────────────────────────────────────────────────────────────────────────┘
```

---

## 4. 前端架構

### 4.1 技術選型

| 分類 | 技術 | 版本 |
|------|------|------|
| 框架 | Vue 3 (Composition API + `<script setup>`) | 3.4.15+ |
| 建構工具 | Vite | 5.4.21 |
| 狀態管理 | Pinia (defineStore Composition 風格) | 3.x |
| UI 組件庫 | Element Plus | 2.5 |
| CSS 框架 | Tailwind CSS | 3.4 |
| 2D 圖譜渲染 | AntV G6 | 5.0 |
| 3D 圖譜渲染 | 3D-Force-Graph + Three.js | 1.79 / 0.182 |
| HTTP 客戶端 | 統一 apiClient (authFetch + apiGet/apiPost/apiPut/apiDelete/apiPostForm) | — |
| 路由 | Vue Router (History Mode) | 4.2 |
| 其他 | markdown-it · xlsx · splitpanes · vuedraggable | — |

### 4.2 路由表 (全部 Lazy Loading)

| 路徑 | 名稱 | 組件 | 說明 |
|------|------|------|------|
| `/` | — | redirect → /nexus | 首頁重定向 |
| `/nexus` | Nexus | NexusPage | 知識中樞主頁面 |
| `/graph-page` | GraphPage | GraphPage | 知識圖譜頁面 |
| `/graph` | Graph | GraphView | 舊版 2D 圖譜 |
| `/graph-3d` | Graph3D | Graph3D | 3D 圖譜視覺化 |
| `/cross-graph` | CrossGraph | CrossGraphPage | 跨圖譜關聯 |
| `/import` | Import | ImportPage | 資料匯入 |
| `/file-import` | FileImport | FileImport | 檔案匯入 |
| `/batch-repair` | BatchRepair | BatchRepair | 批量修復 |
| `/create` | Create | KnowledgeForm | 建立知識節點 |
| `/settings` | Settings | Settings | 系統設定 |
| `/monitor` | SystemMonitor | SystemMonitorPage | 系統監控 |
| `/timeline` | Timeline | TimelinePage | 時間線 |
| `/chat` | Chat | ChatPage | AI 聊天 (Dify) |
| `/login` | Login | LoginPage | 公開登入頁面 |

**認證守衛** (router.beforeEach)：
- 首次載入時呼叫 `/api/auth/status` 檢查認證是否啟用
- 未帶 Token 時重定向至 `/login`
- 標記 `meta.public: true` 的路由免認證

### 4.3 狀態管理 (Pinia Stores)

**graphStore.js** (1566 行)：
- 管理知識圖譜的所有狀態：nodes、links、選中節點、2D/3D 模式切換、跨圖譜 AI Link
- `executeCypherQuery()` — 含前端安全驗證 (CYPHER_BLOCKED regex)，使用 `apiPost()` *(v3.5 簡化)*
- `deleteGraph(graphId, cascade)` — 刪除圖譜（含級聯刪除所有節點與關係） *(v3.4 新增)*
- `updateEntity(nodeId, updates)` — 更新實體節點 (API + Store 同步) *(v3.5 新增)*
- `deleteEntity(nodeId)` — 刪除實體節點 (API + Store 同步) *(v3.5 新增)*
- `fetchRAGFlowDatasets()` — 集中抓取 RAGFlow 知識庫列表，`ragflowDatasets` 狀態供全頁面共用 *(v3.5 新增)*
- **Tag 標籤系統** *(v5.1 新增)*：`allTags` 全域統計 (名稱+數量排序)、`nodesByTag` 按 Tag 分群、`filteredNodes` 疊加 Tag 過濾、`addTagToNode()`/`removeTagFromNode()`/`setTagFilter()` 操作、`activeTagFilter`/`tagFilterMode` ('any'|'all') 狀態
- 呼叫 GraphDataManager 取得資料；所有 API 呼叫統一使用 apiClient 高層函式

### 4.4 核心服務層

**GraphDataManager.js** (392 行)：
- 設計模式：單例 (Singleton)
- LRU 快取 (Map, 上限 10 個圖譜, TTL 5 分鐘)
- 請求去重 (pendingRequests Map) — 同一 graphId 的並發請求只發送一次
- `deleteGraph(graphId, cascade=true)` — 呼叫 `DELETE /api/graph/metadata/{id}?cascade=true` *(v3.4 新增)*
- 使用 authFetch 自動附加認證 Token

**apiClient.js** (154 行) — *v3.5 強化*：
- **底層**：`authFetch(url, options)` — 封裝原生 fetch，自動附加 Token、超時 30s、401 重定向
- **高層便捷函式** *(v3.5 新增)*：
  - `apiGet(url)` — GET + 自動 JSON 解析 + 錯誤提取
  - `apiPost(url, data)` — POST JSON + 自動解析
  - `apiPut(url, data)` — PUT JSON + 自動解析
  - `apiDelete(url)` — DELETE + 自動解析
  - `apiPostForm(url, formData)` — FormData 上傳（不設 Content-Type，瀏覽器自動處理 boundary）
- `_extractErrorMessage(response)` — 從非 2xx 回應統一提取 `detail` / `message` 錯誤訊息 *(v3.5 新增)*
- Token 存於 `localStorage('bruv_api_token')`

### 4.5 前端安全措施

- Cypher 查詢雙重防護：前端 regex 攔截 + 後端白/黑名單驗證
- 查詢長度限制：2000 字元
- 黑名單關鍵字：`CREATE, DELETE, DETACH, SET, REMOVE, MERGE, DROP, ALTER, CALL, COPY, LOAD`

### 4.6 建構配置 (vite.config.js)

- Dev Server：Port 5173
- API Proxy：`/api` → `http://127.0.0.1:8000`
- 手動分塊策略：vue-vendor、element-plus、g6、xlsx、markdown
- 路徑別名：`@` → `./src`
- Terser 壓縮、sourcemap 關閉、chunk 上限 1500KB

---

## 5. 後端架構

### 5.1 主程式進入點 (app_anytype.py, 617 行)

- **框架**：FastAPI + Uvicorn (ASGI)
- **應用模式**：Lifespan Context Manager (取代已棄用的 on_event)

**初始化流程 (lifespan)**：

| 階段 | 啟動時 | 關閉時 |
|------|--------|--------|
| 0 | 結構化日誌初始化 (`setup_structured_logging`) | — |
| 1 | 啟動 TaskQueue 背景 Worker (asyncio) | 停止 TaskQueue Worker |
| 2 | 建立共享 httpx.AsyncClient 連線池 (max=50) | 關閉 httpx 連線池 |
| 3 | 初始化 KuzuDBManager + **AsyncKuzuWrapper** (併發安全層) | 關閉 KuzuDB 連線 |
| 4 | 初始化 WatcherService (含 Saga 補償 + 重試 + DLQ) | 停止 WatcherService |
| 5 | 初始化 OpenTelemetry (可選，`OTEL_ENABLED=true`) | — |
| 6 | 將所有服務存於 app.state | — |

**中間件** (由外到內)：

| 順序 | 中間件 | 功能 |
|------|--------|------|
| 1 | CORSMiddleware | 白名單式 origin 控制 |
| 2 | **RequestTracingMiddleware** | 為每個請求注入 X-Request-ID，記錄請求摘要日誌 |
| 3 | APIAuthMiddleware | Bearer Token 認證 |

**掛載的 Router**：

| 路徑前綴 | Router | 模組 |
|---------|--------|------|
| `/api/tasks` | tasks_router | 任務管理 |
| `/api/dify` | dify_router | Dify LLM 代理 |
| `/api/ragflow` | ragflow_router | RAGFlow 知識檢索代理 |
| `/api/graph` | graph_router | 知識圖譜 CRUD |
| `/api/graph` | graph_import_router | Excel/CSV 匯入 |
| `/api/system` | system_router | 系統配置與上傳 |
| `/api/media` | media_library_router | 媒體庫管理 |

### 5.2 核心模組 (backend/core/)

**config.py** (205 行)：
- `Settings` 類別 (Pydantic BaseSettings)
- 配置優先級：`config.json` > 環境變數 (`.env`) > 程式碼預設值
- 執行緒安全：`threading.Lock` 保護 config.json 讀寫
- 原子寫入：先寫 `.tmp` 再 `rename`
- API Key 快取：`@lru_cache(maxsize=1)`，save 時自動清除
- **連線管理** *(v5.1 新增)*：`load_connections()` / `save_connections()` — `connections` 陣列格式，首次使用時自動從舊 flat key 格式遷移，儲存時同步維護舊格式確保向後相容

**auth.py** (330 行)：
- Bearer Token 認證 — Token 首次啟動時自動生成 (`secrets.token_urlsafe(32)`)
- Token 以 **SHA-256 雜湊**存於 `auth_token.json` (不存明文)
- 資料目錄透過 `BRUV_DATA_DIR` 環境變數配置，與 config.py 一致
- 白名單免認證路徑：`/docs`, `/redoc`, `/openapi.json`, `/api/health`, `/api/auth/login`, `/api/auth/status`, `/`
- 白名單前綴：`/assets/`, `/favicon`

**kuzu_manager.py** (909 行)：
- KuzuDBManager — Schema 初始化、實體 CRUD、關係操作、Cypher 查詢
- **AsyncKuzuWrapper** — 併發安全層：`asyncio.Lock` 序列化寫入 + `ThreadPoolExecutor` 避免阻塞事件迴圈
- `safe_delete_graph_metadata(graph_id, cascade)` — 級聯刪除圖譜及其所有節點與關係 *(v3.4 新增)*
- 路徑處理：非 ASCII 路徑 fallback 到 `C:/BruV_Data/kuzu_db`
- MockKuzuManager 用於開發/測試環境 fallback

**circuit_breaker.py** (196 行) — *v3.3 新增*：
- CircuitBreaker 斷路器模式 — 防止級聯故障
- 狀態機：`CLOSED → OPEN (連續 N 次失敗) → HALF_OPEN (探測) → CLOSED`
- 預建實例：`dify_breaker`、`ragflow_breaker` (threshold=5, timeout=30s)
- 支援 async context manager 與 decorator 兩種使用方式
- `CircuitBreakerOpenError` 自動返回 503

**logging.py** (149 行) — *v3.3 新增*：
- `StructuredLogFormatter` — JSON 結構化日誌，含 timestamp/level/request_id/module
- `RequestTracingMiddleware` — 為每個 HTTP 請求注入 X-Request-ID (ContextVar 跨 async 安全)
- `setup_structured_logging()` — 一鍵配置全域日誌 (JSON 生產模式 / 人類可讀開發模式)

**telemetry.py** (151 行) — *v3.3 新增*：
- OpenTelemetry 分散式追蹤最小化實作
- 可選啟用 (`OTEL_ENABLED=true`)，不影響核心功能
- 自動儀器化：FastAPI 路由 + httpx 出站請求
- 支援 Console / OTLP 兩種 Exporter
- NoOp Tracer fallback (未安裝 OTel 時)

### 5.3 API 路由模組 (backend/api/)

| 模組 | 行數 | 功能描述 |
|------|------|---------|
| **graph.py** | 540 | 知識圖譜核心 API — 實體建立、關係管理、鄰居查詢、Cypher 安全驗證、圖譜元資料 CRUD、**圖譜刪除 (級聯)**、**手動節點互連觸發**、實體 tags 更新 *(v5.1)* |
| **graph_import.py** | 1205 | Excel/CSV 智能解析匯入、LLM Prompt v2.0 自動標題/描述/關係/tags 推薦、欄位智能提取、LLM 快取、合併上傳、多語言+領域特化、支援 3000 筆 |
| **dify.py** | 208 | Dify LLM 平台代理、動態 API Key、整合 agent_service 意圖路由 |
| **ragflow.py** | 242 | RAGFlow 混合檢索代理 (Hybrid Search + Rerank)、支援 `similarity_threshold, vector_similarity_weight, top_k, rerank_id` 參數 *(v3.6 升級)* |
| **system.py** | 977 | 系統配置讀寫、**連線管理 CRUD (6 端點)**、自動偵測服務、連線測試、通用檔案上傳、CircuitBreaker 狀態、Saga DLQ 管理 *(v5.1 大幅擴展)* |
| **media_library.py** | 438 | 媒體檔案 CRUD、MinIO 物件儲存 (本地 fallback)、標籤分類、OCR |
| **tasks.py** | 64 | 任務狀態查詢 (列表/單一)、封裝 TaskQueue |

### 5.4 服務層 (backend/services/)

**agent_service.py** (338 行)：
- 智能代理核心 — 意圖路由 (Intent Router)
- 意圖類型：`RAG` (知識檢索) / `AUTOMATION` (系統自動化) / `CHAT` (閒聊)
- 中文關鍵字匹配進行意圖識別
- httpx 非同步呼叫，超時由 `settings.REQUEST_TIMEOUT` 控制

**task_queue.py** (443 行)：
- asyncio 背景 Worker + SQLite 持久化 (`~/BruV_Data/task_queue.db`)
- 任務狀態：`PENDING → PROCESSING → COMPLETED | FAILED`
- 追蹤：進度百分比、total/processed/failed items、current stage
- 最大歷史 500 條，自動清理過期任務

**watcher.py** (978 行) — *v3.4 大幅強化*：
- watchdog 庫 (Observer + FileSystemEventHandler)
- 監控 AUTO_IMPORT_DIR，支援 `.pdf, .txt, .md, .docx, .xlsx`
- **Saga 補償機制**：RAGFlow 上傳成功但 KuzuDB 寫入失敗時，自動反向刪除 RAGFlow 文件
- **重試策略**：指數退避重試 (最多 3 次，1s → 2s → 4s)
- **Dead Letter Queue (DLQ)**：補償也失敗的操作記入 SQLite DLQ，供管理員手動處理
- **節點互連引擎** `_build_inter_node_links()` *(v3.4 新增)*：
  - Layer 1 — **Link Domain 歸類**：提取 URL 網域，同域資源自動建立 `same_domain` 關係 (每域上限 20 條)
  - Layer 2 — **關鍵字共現**：從標題/描述提取關鍵字 (CJK ≥2 字元, EN ≥3 字元, 含停用詞過濾)，≥2 共同關鍵字建立 `keyword_overlap` 關係 (上限 100 條)
  - 防重複：查詢已有關係避免重複建立
  - 自動更新圖譜統計資訊
- **Saga Step D** *(v3.4 新增)*：Excel 解析後自動執行節點互連 (Step A→B→C→**D**)
- 整合 TaskQueue 追蹤進度，背景執行緒不阻塞 asyncio

**saga.py** (384 行) — *v3.3 新增*：
- Saga Orchestrator — 跨系統事務編排器
- `SagaLog` — 步驟狀態持久化到 SQLite (`saga_log.db`)，崩潰後可恢復補償
- `FileImportSaga` — 協調 RAGFlow Upload + KuzuDB Write 的跨系統事務
- 每個步驟都有對應的補償操作 (Compensating Transaction)
- 查詢工具：`list_recent_sagas()`、`get_saga_by_id()`

### 5.5 RAG 客戶端 (backend/rag_client.py, 236 行) — *v3.6 擴展*

- **同步 + 非同步** HTTP 客戶端 (httpx.Client / AsyncClient) — 同步供 WatcherService 背景執行緒，非同步供 FastAPI 路由使用
- 連接 RAGFlow v1 API (`http://localhost:9380/api/v1`)
- `upload_file(dataset_id, file_path)` — 上傳文件到指定知識庫
- `delete_document(dataset_id, document_id)` — 刪除文件 (Saga 補償用)
- `get_chunks(dataset_id, document_id)` — 取回文件解析分塊 *(v3.4 新增)*
- `async_get_chunks(dataset_id, document_id)` — 非同步版取回分塊 *(v3.4 新增)*
- `get_document_status(dataset_id, document_id)` — 查詢文件解析狀態 *(v3.4 新增)*
- `async_get_document_status(dataset_id, document_id)` — 非同步版查詢狀態 *(v3.4 新增)*
- `retrieve(question, dataset_ids, ...)` — 混合檢索 (Hybrid Search + Rerank) *(v3.6 新增)*
  - 參數：`similarity_threshold`, `vector_similarity_weight`, `top_k`, `rerank_id`
  - POST 至 `{base_url}/retrieval`，過濾 None 值後透傳
- `_check_response()` — 檢查 RAGFlow 回應 body 中的業務層錯誤 (HTTP 200 但 code≠0)
- `RAGFlowAPIError` — 自訂例外類別，區分 HTTP 錯誤與業務錯誤

---

## 6. API 端點一覽

### 認證 API

| 方法 | 路徑 | 說明 |
|------|------|------|
| POST | `/api/auth/login` | Token 驗證登入 |
| GET | `/api/auth/status` | 認證狀態查詢 (是否啟用) |

### 系統 API

| 方法 | 路徑 | 說明 |
|------|------|------|
| GET | `/api/health` | 健康檢查 |
| GET | `/api/system/config` | 讀取目前配置 |
| POST | `/api/system/config` | 更新配置 (寫入 config.json) |
| GET | `/api/system/env-file` | 讀取 .env 檔案 |
| POST | `/api/system/test-connection` | 測試 Dify/RAGFlow 連線 |
| POST | `/api/system/upload` | 通用檔案上傳 |
| GET | `/api/system/circuit-breakers` | CircuitBreaker 狀態 (Dify/RAGFlow) |
| GET | `/api/system/saga-dlq` | Dead Letter Queue 列表 |
| POST | `/api/system/saga-dlq/{id}/resolve` | 手動 Resolve DLQ 項目 |
| GET | `/api/system/health-check` | 深度健康檢查 (含下游服務連線狀態) |
| GET | `/api/system/connections` | 列出所有連線配置 *(v5.1 新增)* |
| POST | `/api/system/connections` | 新增連線 *(v5.1 新增)* |
| PUT | `/api/system/connections/{conn_id}` | 更新連線 *(v5.1 新增)* |
| DELETE | `/api/system/connections/{conn_id}` | 刪除連線 *(v5.1 新增)* |
| POST | `/api/system/connections/{conn_id}/test` | 測試指定連線 *(v5.1 新增)* |
| POST | `/api/system/test-connection-inline` | Dialog 內即時測試 (不儲存) *(v5.1 新增)* |
| POST | `/api/system/detect-services` | 自動偵測可用服務 (掃描 Dify/RAGFlow/Ollama 等常見端口) *(v5.1 新增)* |

### 知識圖譜 API

| 方法 | 路徑 | 說明 |
|------|------|------|
| POST | `/api/graph/entities` | 建立實體節點 |
| POST | `/api/graph/relations` | 建立關係邊 |
| GET | `/api/graph/entities/{id}` | 取得單一實體 |
| GET | `/api/graph/entities` | 搜尋/列出實體 |
| GET | `/api/graph/entities/{id}/neighbors` | 取得鄰居節點 |
| GET | `/api/graph/list` | 列出圖譜 |
| POST | `/api/graph/query` | 執行 Cypher 查詢 (僅讀取) |
| POST | `/api/graph/metadata` | 建立圖譜元資料 |
| GET | `/api/graph/metadata` | 列出所有圖譜元資料 |
| GET | `/api/graph/metadata/{id}` | 取得單一圖譜元資料 |
| PUT | `/api/graph/metadata/{id}` | 更新圖譜元資料 |
| PUT | `/api/graph/entities/{id}` | 更新實體節點 (含 tags) *(v5.1 擴展)* |
| DELETE | `/api/graph/metadata/{id}` | 刪除圖譜元資料 |
| POST | `/api/graph/import` | Excel/CSV 智能匯入 |
| POST | `/api/graph/interlink/{graph_id}` | 手動觸發節點互連分析 *(v3.4 新增)* |

### AI 代理 API

| 方法 | 路徑 | 說明 |
|------|------|------|
| POST | `/api/dify/chat` | Dify LLM 對話 |
| POST | `/api/ragflow/query` | RAGFlow 知識檢索 |

### 媒體庫 API

| 方法 | 路徑 | 說明 |
|------|------|------|
| POST | `/api/media/upload` | 上傳媒體檔案 |
| GET | `/api/media/list` | 列出媒體庫 |
| GET | `/api/media/files/{path}` | 取得檔案 |
| DELETE | `/api/media/{file_id}` | 刪除檔案 |
| GET | `/api/media/stats` | 媒體庫統計 |

### 任務 API

| 方法 | 路徑 | 說明 |
|------|------|------|
| GET | `/api/tasks` | 取得所有任務列表 |
| GET | `/api/tasks/{task_id}` | 取得單一任務狀態 |

---

## 7. 資料庫與儲存

| # | 引擎 | 用途 | 位置/Port | 備份策略 |
|---|------|------|-----------|---------|
| 1 | **KuzuDB** | 知識圖譜 (節點+關係) | `~/BruV_Data/kuzu_db` | 目錄快照 |
| 2 | **PostgreSQL 15** | Dify 平台資料 | 容器 `dify-db` (無外部 Port) | Docker Volume `dify_db_data` |
| 3 | **MySQL 8.0** | RAGFlow 平台資料 | 容器 `ragflow-mysql` (無外部) | Docker Volume `ragflow_mysql_data` |
| 4 | **Elasticsearch 8.11.3** | 全文搜尋與語義索引 | `127.0.0.1:9200` | Docker Volume `es01_data` |
| 5 | **Redis 7 (Dify)** | Dify 快取與佇列 | 容器 `dify-redis` (無外部) | Docker Volume (可重建) |
| 6 | **Redis 7 (RAGFlow)** | RAGFlow 快取 | 容器 `ragflow-redis` (無外部) | Docker Volume (可重建) |
| 7 | **MinIO** | S3 相容物件儲存 | `127.0.0.1:9000` (API) / `:9001` (Console) | Docker Volume `ragflow_minio_data` |
| 8 | **SQLite** | 任務佇列持久化 | `~/BruV_Data/task_queue.db` | 500 條上限，自動清理 |
| 9 | **SQLite** | Saga 日誌持久化 | `~/BruV_Data/saga_log.db` | Saga 步驟追蹤 |
| 10 | **SQLite** | Dead Letter Queue | `~/BruV_Data/saga_dlq.db` | 補償失敗項目紀錄 |
| 11 | **本地檔案系統** | config/token/媒體/自動匯入 | `~/BruV_Data/` | 整目錄備份 |

---

## 8. Docker 容器服務

使用 Docker Compose 編排 **15 個微服務**，所有服務在 `bruv_network` (bridge) 網路中通訊。

| 服務名稱 | 映像 | 外部 Port (bind 127.0.0.1) | 資源限制 |
|---------|------|---------------------------|--------|
| dify-nginx | nginx:latest | 82 → 80 | — |
| dify-web | langgenius/dify-web:0.6.16 | (無外部) | 2 CPU + 4GB |
| dify-api | langgenius/dify-api:0.6.16 | 5001 → 5001 | 2 CPU + 4GB |
| dify-worker | langgenius/dify-api:0.6.16 | (無外部) | 2 CPU + 4GB |
| dify-db | postgres:15-alpine | (無外部) | — |
| dify-redis | redis:7-alpine | (無外部) | — |
| ragflow | infiniflow/ragflow:v0.16.0 | 81→80, 9380, 9381 | — |
| es01 | elasticsearch:8.11.3 | 9200 → 9200 | — |
| ragflow-mysql | mysql:8.0 | (無外部) | — |
| ragflow-minio | minio/minio:latest | 9000, 9001 | — |
| ragflow-redis | redis:7-alpine | (無外部) | — |
| **ollama** | **ollama/ollama:latest** | **11434 → 11434** | **GPU 直通 (nvidia)** |
| **loki** | **grafana/loki:2.9.0** | **3100 → 3100** | **0.5 CPU + 256M** |
| **promtail** | **grafana/promtail:2.9.0** | **(無外部)** | **0.25 CPU + 128M** |
| **grafana** | **grafana/grafana:10.2.0** | **3000 → 3000** | **0.5 CPU + 256M** |

**Docker Volumes (13 個)**：  
`dify_db_data`, `dify_redis_data`, `dify_storage`, `ragflow_data`, `ragflow_logs`, `ragflow_mysql_data`, `ragflow_minio_data`, `ragflow_redis_data`, `es01_data`, `ollama_data`, `loki_data`, `grafana_data`

---

## 9. 安全縱深防禦

### 五層防護架構

```
第1層 ─ 網路邊界
│  ├── Port 綁定 127.0.0.1 (僅本地存取)
│  ├── SSL/TLS 1.2-1.3 (HTTPS 加密)
│  └── HSTS 1 年 (強制 HTTPS)
│
第2層 ─ Nginx WAF
│  ├── 速率限制 (API 30r/s burst 50 · Upload 5r/s burst 10)
│  ├── 安全標頭 (CSP · X-Frame-Options · HSTS · Permissions-Policy)
│  ├── 隱藏 Nginx 版本 (server_tokens off)
│  └── 路徑封鎖 (.env · .git · .sql · .log · 隱藏檔)
│
第3層 ─ 應用認證
│  ├── Bearer Token + SHA-256 雜湊儲存 (不存明文)
│  ├── CORS 白名單式 Origin 控制
│  ├── 免認證白名單 (/docs · /health · /login)
│  └── 401 自動清除 Token + 重定向
│
第4層 ─ 業務邏輯
│  ├── Cypher 前後端雙重驗證 (前端 regex + 後端黑名單)
│  ├── 查詢長度限制 2000 字元
│  ├── 上傳大小限制 100MB + Nginx 128M
│  └── config.json 原子寫入 + threading.Lock 防競爭
│
第5層 ─ 資料隔離
   ├── 完全地端部署 (零外部雲端依賴)
   ├── 密碼/金鑰透過 .env 注入 (不寫死在程式碼)
   ├── Docker Compose 使用 ${VAR:?message} 強制必填
   └── 進程優雅停止 (先 terminate → 5秒超時 → force kill)
```

---

## 10. 配置管理

### 10.1 配置優先級（高 → 低）

1. `config.json` (使用者透過 UI 設定頁面修改)
2. 環境變數 (`.env` 檔案)
3. 程式碼預設值 (`Settings` 類別)

### 10.2 Settings 類別欄位

| 欄位名稱 | 預設值 | 說明 |
|---------|--------|------|
| HOST | 127.0.0.1 | 伺服器監聽位址 |
| PORT | 8765 | 伺服器監聽埠號 |
| ENVIRONMENT | development | 執行環境 |
| DIFY_API_URL | http://localhost:80/v1 | Dify API 位址 |
| RAGFLOW_API_URL | http://localhost:81/api/v1 | RAGFlow API 位址 |
| KUZU_DB_PATH | ~/BruV_Data/kuzu_db | 圖資料庫路徑 |
| AUTO_IMPORT_DIR | ~/BruV_Data/Auto_Import | 自動匯入監控目錄 |
| MEDIA_LIBRARY_PATH | ~/BruV_Data/media_library | 媒體庫路徑 |
| MINIO_ENDPOINT | localhost:9000 | MinIO 端點 |
| MINIO_ROOT_USER | minioadmin | MinIO 使用者 |
| MINIO_ROOT_PASSWORD | (空) | MinIO 密碼 |
| REQUEST_TIMEOUT | 30 | HTTP 請求超時 (秒) |
| BRUV_AUTH_ENABLED | true | 啟用 API 認證 |
| BRUV_API_TOKEN | (空) | 自訂 Token |
| MAX_UPLOAD_SIZE | 104857600 | 上傳大小限制 (100MB) |

### 10.3 環境變數 (.env.example)

```
DIFY_API_URL, DIFY_API_KEY, DIFY_SECRET_KEY,
RAGFLOW_API_URL, RAGFLOW_API_KEY,
KUZU_DB_PATH, DEBUG, LOG_LEVEL,
BRUV_AUTH_ENABLED, BRUV_API_TOKEN,
DIFY_DB_PASSWORD, RAGFLOW_MYSQL_PASSWORD,
MINIO_ROOT_USER, MINIO_ROOT_PASSWORD,
RAGFLOW_REDIS_PASSWORD, ELASTIC_PASSWORD
```

---

## 11. 任務佇列與持久化

TaskQueue 是基於 asyncio 的背景任務系統，搭配 SQLite 持久化。

**任務生命週期**：`PENDING → PROCESSING → COMPLETED | FAILED`

**任務類型**：
- `file_upload` — 檔案上傳至 RAGFlow
- `excel_parse` — Excel 智能解析匯入

**每個任務追蹤**：
- 進度百分比 (0-100%)
- 總項目數 / 已處理 / 失敗項目數
- 當前階段描述
- 結果 (JSON) 或錯誤訊息
- 建立/開始/完成時間

**持久化機制**：
- 儲存路徑：`~/BruV_Data/task_queue.db` (SQLite)
- 每次 create/update 即時寫入
- 啟動時自動載入未完成的任務
- 歷史記錄上限 500 條，自動清理

---

## 12. 檔案監控與自動匯入

WatcherService 使用 watchdog 庫監控 AUTO_IMPORT_DIR 目錄。

**監控流程 (v3.3 含 Saga 補償)**：

```
1. 使用者將檔案放入 ~/BruV_Data/Auto_Import/
2. WatcherService 偵測到新檔案事件
3. 檢查副檔名 (.pdf, .txt, .md, .docx, .xlsx)
4. 建立 TaskQueue 任務，開始追蹤進度
5. Step A: 上傳檔案至 RAGFlow (含指數退避重試 ×3)
6. Step B: 同步文件元資料至 KuzuDB 知識圖譜
7. Step C: Excel 深度解析 (可選，失敗不補償)
8. Step D: 節點互連分析 (v3.4 新增) — 基於 domain 歸類 + 關鍵字共現

失敗處理：
  • Step A 失敗 → 重試 3 次 → 記入 DLQ
  • Step B 失敗 → 反向補償 (刪除 RAGFlow 文件) → 記入 DLQ
  • Step D 失敗 → 只記錄警告，不影響主流程 (可稍後手動觸發)
  • 補償失敗 → 記入 Dead Letter Queue，等待管理員處理
```

> watchdog callback 在獨立的背景執行緒中執行，不會阻塞 FastAPI 的 asyncio 事件迴圈。
> 管理員可透過 `/api/system/saga-dlq` 查看/resolve 失敗項目。

---

## 13. Nginx 反向代理

配置檔案：`nginx/ragflow.conf` (200 行)

| 功能 | 配置 |
|------|------|
| SSL/TLS 終端 | TLS 1.2 + TLS 1.3 |
| 上游代理 | 127.0.0.1:9380 (RAGFlow API) |
| WebSocket | `/ws` 路徑 (read_timeout 86400) |
| Gzip 壓縮 | Level 6 |
| 靜態資源快取 | 30 天 (immutable) |
| HTTP → HTTPS | 301 重定向 |
| API 速率限制 | 30r/s (burst 50, nodelay) |
| 上傳速率限制 | 5r/s (burst 10, nodelay) |
| 上傳超時 | 600 秒 |

---

## 14. 依賴清單

### 14.1 Python 後端 (requirements.txt) — 全部版本鎖定

| 套件 | 版本 | 用途 |
|------|------|------|
| fastapi | 0.104.1 | Web 框架 |
| uvicorn[standard] | 0.24.0 | ASGI 伺服器 |
| pydantic | 2.5.0 | 資料驗證 |
| pydantic-settings | 2.1.0 | 設定管理 |
| httpx | 0.25.1 | 非同步 HTTP 客戶端 |
| requests | 2.32.5 | 同步 HTTP 客戶端 |
| kuzu | 0.1.0 | 圖資料庫 |
| python-multipart | 0.0.6 | 檔案上傳 |
| pandas | 3.0.0 | 資料處理 |
| openpyxl | 3.1.5 | Excel 讀寫 |
| python-dotenv | 1.0.0 | 環境變數載入 |
| watchdog | 6.0.0 | 檔案系統監控 |
| minio | 7.2.20 | MinIO 物件儲存客戶端 |
| opentelemetry-api | ≥1.20.0 | OTel 追蹤 API (可選) |
| opentelemetry-sdk | ≥1.20.0 | OTel 追蹤 SDK (可選) |
| opentelemetry-instrumentation-fastapi | ≥0.41b0 | FastAPI 自動儀器化 (可選) |
| opentelemetry-instrumentation-httpx | ≥0.41b0 | httpx 自動儀器化 (可選) |

### 14.2 GUI 啟動器 (requirements-gui.txt)

| 套件 | 版本 | 用途 |
|------|------|------|
| PySide6 | 6.6.1 | Qt GUI 框架 (僅啟動器) |

### 14.3 前端依賴 (package.json 摘要)

| 套件 | 版本 | 用途 |
|------|------|------|
| vue | ^3.4.15 | UI 框架 |
| vue-router | ^4.2.5 | 路由 |
| pinia | ^3.0.4 | 狀態管理 |
| element-plus | ^2.5.4 | UI 組件庫 |
| @antv/g6 | ^5.0.0 | 2D 圖譜渲染 |
| 3d-force-graph | ^1.79 | 3D 圖譜渲染 |
| three | ^0.182 | 3D 引擎 |
| axios | ^1.13.4 | HTTP 客戶端 |
| markdown-it | ^14.0.0 | Markdown 渲染 |
| xlsx | ^0.18.5 | Excel 解析 |
| splitpanes | ^4.0.4 | 面板分割 |
| vuedraggable | ^4.1.0 | 拖放功能 |
| vite | ^5.0 | 建構工具 |
| tailwindcss | ^3.4 | CSS 框架 |

---

## 15. 部署與啟動方式

### 15.1 開發環境啟動

| 步驟 | 指令 | 說明 |
|------|------|------|
| 1 | `docker-compose up -d` | 啟動 Docker 容器群組 |
| 2 | `.\start_backend.ps1` 或 `uvicorn app_anytype:app --host 127.0.0.1 --port 8765` | 啟動 FastAPI 後端 |
| 3 | `cd frontend && npm run dev` | 啟動前端開發伺服器 |
| 4 (選用) | `python launcher_gui.py` | 啟動 GUI 啟動器 |

### 15.2 一鍵啟動

- `START.bat` — Windows 批次檔
- `START.ps1` — PowerShell 腳本
- `start_gui_launcher.bat` — GUI 啟動器

### 15.3 GUI 啟動器 (launcher_gui.py, 1454 行)

PySide6 桌面應用程式，功能包括：
- 一鍵啟動/停止所有服務
- 即時日誌輸出
- 服務健康狀態指示燈 (後端/前端/Dify/RAGFlow)
- 快速連結 (開啟 BruV AI / Dify / RAGFlow)
- 多語言支援 (繁體中文/英文)
- 系統設定頁面 (API 配置/認證管理)
- 優雅停止機制 (先 terminate → 5 秒超時 → force kill)

### 15.4 資料目錄

```
~/BruV_Data/    (可透過 BRUV_DATA_DIR 環境變數覆蓋)
├── kuzu_db/          KuzuDB 圖資料庫
├── Auto_Import/      自動匯入監控目錄
├── media_library/    本地媒體儲存
├── auth_token.json   認證 Token 雜湊
├── task_queue.db     SQLite 任務持久化
├── saga_log.db       Saga 步驟追蹤日誌
└── saga_dlq.db       Dead Letter Queue (補償失敗紀錄)
```

---

## 16. 硬體建議規格

| 等級 | CPU | RAM | 儲存 | GPU | 適用場景 |
|------|-----|-----|------|-----|---------|
| **入門** | 4C/8T | 16 GB | 256 GB SSD | — | 個人/小團隊，使用外部 LLM API |
| **標準** | 8C/16T | 32 GB | 512 GB NVMe | — | 中型團隊，Dify + RAGFlow 完整運行 |
| **進階** | 16C/32T | 64 GB | 1 TB NVMe | RTX 4060+ | 本地 LLM (Ollama)，大規模知識庫 |
| **企業** | 32C+ | 128 GB+ | 2 TB+ NVMe RAID | A4000+ | 多人同時推論，TB 級文件庫 |

---

## 17. 未來擴展路線圖

| 階段 | 目標 | 具體做法 |
|------|------|---------|
| **Phase 1** (現階段) | 單機地端部署 | Port 127.0.0.1 綁定，GUI 啟動器管理 |
| **Phase 2** | 區網多人存取 | Nginx HTTPS :443 開放區網 IP，多使用者 Token |
| **Phase 3** ✅ | 本地 LLM 整合 | Ollama (llama3 + nomic-embed-text) 容器部署，GPU 直通，完全離線。已部署 (v3.7) + RAGFlow 橋接驗證 (v3.8) |
| **Phase 4** | 高可用部署 | Docker Swarm / K3s，PostgreSQL 主從複製 |
| **Phase 5** | 多節點聯邦 | 多台主機跨圖譜同步，分散式知識圖譜 |

---

## 18. 架構深度審查 — 紅隊測試報告 (2026-02-10)

### 18.1 執行摘要

**整體評分：7.2 / 10 → v3.3 後提升至 8.5 / 10** ✅

作為一套地端化單機部署的 AI 知識管理平台，BruV v3.0 在功能完整度與安全縱深防禦上已達到相當成熟的水準。前端雙模式圖譜視覺化、後端三引擎整合、五層安全模型——這些都是扎實的架構決策。v3.3 已完成所有 P0-P3 行動項目，三個 P0 級風險全部消除。

> **v3.3 修復狀態**：P0-1 ✅ Saga 補償 | P0-2 ✅ AsyncKuzuWrapper | P0-3 ✅ 結構化日誌 + X-Request-ID

原始審查發現的 **三個 P0 級架構風險** (已修復)：

| 風險排名 | 維度 | 問題 | 影響 |
|---------|------|------|------|
| **P0-1** | 資料一致性 | RAGFlow ↔ KuzuDB 跨系統寫入無補償機制 | 「幽靈文件」── 檔案存在 RAGFlow 但知識圖譜無對應節點，導致搜得到但圖譜看不到 |
| **P0-2** | 併發安全 | KuzuDB 單一 `Connection` 物件在 async 環境中無任何鎖保護 | 高併發寫入時可能觸發 Segfault 或資料庫檔案毀損 |
| **P0-3** | 可觀測性 | 10 個 Docker 容器 + 2 個原生進程，無 Correlation ID，無集中式日誌 | 跨服務除錯如同大海撈針，MTTR (平均恢復時間) 極高 |

---

### 18.2 深度分析

#### 18.2.1 資料一致性與分散式事務 (Data Consistency)

**現狀問題**

檢視 [watcher.py](backend/services/watcher.py) 的 `_process_file()` 方法，目前的寫入流程是：

```
動作 A: self.rag_client.upload_file()    → 寫入 RAGFlow (MySQL + ES + MinIO)
動作 B: self._add_to_graph()            → 寫入 KuzuDB
動作 C: self._parse_excel_and_link()     → 寫入 KuzuDB (Excel 深度解析)
```

**失敗情境分析**：

| 情境 | A (RAGFlow) | B (KuzuDB) | 結果 | 目前處理方式 |
|------|-------------|------------|------|-------------|
| 正常 | ✅ | ✅ | 一致 | — |
| 情境 1 | ✅ | ❌ | **不一致** — 幽靈文件 | `except` 印 Log，無補償 |
| 情境 2 | ❌ | — | 一致 (都未寫入) | 正確中斷 |
| 情境 3 | ✅ | ✅ (節點) | ❌ (關係) — **不一致** — 孤立節點 | 部分成功無回滾 |

**架構級解決方案：Saga Pattern (Orchestration 模式)**

引入 **Saga Orchestrator** 搭配 **補償操作 (Compensating Transaction)**：

```python
# === Pseudocode: SagaOrchestrator for File Import ===

class FileImportSaga:
    """
    Saga 編排器：協調 RAGFlow 上傳 + KuzuDB 寫入的跨系統事務。
    每個步驟都有對應的補償操作，確保最終一致性。
    """

    def __init__(self, rag_client, kuzu_manager, task_queue):
        self.rag_client = rag_client
        self.kuzu_manager = kuzu_manager
        self.task_queue = task_queue

    async def execute(self, file_path: Path, graph_id: str, dataset_id: str):
        saga_log = SagaLog()  # 持久化到 SQLite，記錄每一步的執行狀態
        ragflow_doc_id = None
        kuzu_entity_id = None

        try:
            # ── Step 1: 上傳至 RAGFlow ──
            saga_log.record_step("ragflow_upload", status="STARTED")
            upload_result = await self.rag_client.async_upload_file(dataset_id, str(file_path))
            ragflow_doc_id = extract_doc_id(upload_result)
            saga_log.record_step("ragflow_upload", status="COMPLETED", doc_id=ragflow_doc_id)

            # ── Step 2: 寫入 KuzuDB ──
            saga_log.record_step("kuzu_write", status="STARTED")
            kuzu_entity_id = generate_entity_id(file_path, upload_result)
            success = self.kuzu_manager.add_entity(
                entity_id=kuzu_entity_id,
                name=file_path.name,
                entity_type='document',
                graph_id=graph_id
            )
            if not success:
                raise KuzuWriteError(f"KuzuDB 寫入失敗: {kuzu_entity_id}")
            saga_log.record_step("kuzu_write", status="COMPLETED", entity_id=kuzu_entity_id)

            # ── Step 3: Excel 深度解析 (可選) ──
            if file_path.suffix.lower() == '.xlsx':
                saga_log.record_step("excel_parse", status="STARTED")
                parse_excel_and_link(file_path, kuzu_entity_id, graph_id)
                saga_log.record_step("excel_parse", status="COMPLETED")

            saga_log.mark_saga_completed()

        except Exception as e:
            # ── 補償流程 (Compensation) ──
            logger.error(f"Saga 失敗，啟動補償: {e}")
            await self._compensate(saga_log, ragflow_doc_id, kuzu_entity_id)
            saga_log.mark_saga_failed(str(e))
            raise

    async def _compensate(self, saga_log, ragflow_doc_id, kuzu_entity_id):
        """反向補償：按照 saga_log 反向撤銷已完成的步驟"""
        completed_steps = saga_log.get_completed_steps()

        if "kuzu_write" in completed_steps and kuzu_entity_id:
            try:
                self.kuzu_manager.delete_entity(kuzu_entity_id)
                logger.info(f"補償完成: 已刪除 KuzuDB 實體 {kuzu_entity_id}")
            except Exception as comp_err:
                logger.error(f"補償失敗 (KuzuDB): {comp_err}")
                # 寫入 Dead Letter Queue，等待人工介入

        if "ragflow_upload" in completed_steps and ragflow_doc_id:
            try:
                await self.rag_client.async_delete_document(ragflow_doc_id)
                logger.info(f"補償完成: 已刪除 RAGFlow 文件 {ragflow_doc_id}")
            except Exception as comp_err:
                logger.error(f"補償失敗 (RAGFlow): {comp_err}")
                # 寫入 Dead Letter Queue
```

**額外建議**：

- **Dead Letter Queue (DLQ)**：補償也失敗的操作寫入 `saga_dlq` SQLite 表，提供 `/api/system/saga-dlq` 端點讓管理員手動重試或確認
- **冪等性設計 (Idempotency)**：KuzuDB 的 `add_entity()` 已使用 `MERGE` (upsert) ✅，RAGFlow 上傳需增加基於檔案雜湊的去重檢查
- **定時調和任務 (Reconciliation Job)**：每小時比對 RAGFlow 文件清單與 KuzuDB Entity 清單，自動修復不一致

---

#### 18.2.2 KuzuDB 的併發處理 (Concurrency in Embedded DB)

**現狀問題**

檢視 [kuzu_manager.py](backend/core/kuzu_manager.py)：

```python
# 第 49-50 行 — 整個生命週期只建立一個 Connection
self.db = kuzu.Database(db_path_str)
self.conn = kuzu.Connection(self.db)
```

**風險鏈**：

```
FastAPI (async) → 多個並發 API Handler
                  ├── Handler A: self.conn.execute("MERGE ...")  ← 寫入
                  ├── Handler B: self.conn.execute("MATCH ...")  ← 讀取
                  └── Handler C: self.conn.execute("CREATE ...")  ← 寫入
                  
問題：kuzu.Connection 不是 thread-safe 的。
      在 async 環境中，雖然 GIL 提供了一定保護，
      但 KuzuDB 的 C++ 底層操作可能在 GIL 釋放期間並發執行。
```

此外，`conn.execute()` 是 **同步阻塞呼叫**，會阻塞整個事件迴圈，在高併發時造成所有 API 回應延遲。

**架構級解決方案：Write Serialization Queue + Read Connection Pool**

```python
# === Pseudocode: KuzuDBManager v2 with Concurrency Control ===

import asyncio
import threading
from contextlib import contextmanager

class KuzuDBManagerV2:
    """
    併發安全的 KuzuDB 管理器
    
    設計原則：
    1. 寫入操作序列化 — 所有寫入排進 asyncio.Queue，由單一 Writer 執行
    2. 讀取操作並行  — 使用 Connection Pool (讀取鎖不衝突)
    3. 同步呼叫隔離  — 使用 run_in_executor 避免阻塞事件迴圈
    """

    def __init__(self, db_path: str, read_pool_size: int = 3):
        self.db = kuzu.Database(db_path)
        
        # 寫入專用連線 (單一，序列化)
        self._write_conn = kuzu.Connection(self.db)
        self._write_lock = asyncio.Lock()
        
        # 讀取連線池
        self._read_pool = [kuzu.Connection(self.db) for _ in range(read_pool_size)]
        self._read_semaphore = asyncio.Semaphore(read_pool_size)
        self._read_index = 0
        
        # 後台執行緒池 (避免阻塞 asyncio 事件迴圈)
        self._executor = ThreadPoolExecutor(max_workers=read_pool_size + 1, 
                                             thread_name_prefix="kuzu")

    async def write(self, cypher: str, parameters: dict = None) -> bool:
        """序列化寫入 — 所有寫入操作排隊等待"""
        async with self._write_lock:  # ← 確保同一時間只有一個寫入
            loop = asyncio.get_event_loop()
            return await loop.run_in_executor(
                self._executor,
                self._sync_execute,      # 同步呼叫
                self._write_conn, 
                cypher, 
                parameters
            )

    async def read(self, cypher: str, parameters: dict = None) -> list:
        """並行讀取 — 從連線池取得連線"""
        async with self._read_semaphore:  # ← 限制並發讀取數
            conn = self._get_read_conn()
            loop = asyncio.get_event_loop()
            return await loop.run_in_executor(
                self._executor,
                self._sync_query,
                conn,
                cypher,
                parameters
            )

    def _sync_execute(self, conn, cypher, parameters):
        """在執行緒池中執行的同步寫入"""
        conn.execute(cypher, parameters=parameters or {})
        return True

    def _sync_query(self, conn, cypher, parameters):
        """在執行緒池中執行的同步查詢"""
        result = conn.execute(cypher, parameters=parameters or {})
        return [dict(row) for row in result.get_as_df().to_dict('records')]

    def _get_read_conn(self):
        """輪詢 (Round-Robin) 取得讀取連線"""
        conn = self._read_pool[self._read_index % len(self._read_pool)]
        self._read_index += 1
        return conn
```

**關鍵改進點**：

| 改進 | 說明 |
|------|------|
| `asyncio.Lock` 寫入序列化 | 避免並發寫入導致的資料毀損 |
| `run_in_executor` | 將同步阻塞呼叫移至 ThreadPoolExecutor，不阻塞事件迴圈 |
| Read Connection Pool | KuzuDB 支援多讀取連線並行，提升查詢吞吐量 |
| Write-Ahead 考量 | 未來可在寫入前先記錄 WAL (Write-Ahead Log) 到 SQLite，崩潰時可重播 |

---

#### 18.2.3 系統擴展性與解耦 (Scalability & Decoupling)

**現狀問題**

檢視 [task_queue.py](backend/services/task_queue.py)：

```python
# 模組層級全域單例 — 硬綁定到 asyncio + SQLite
task_queue = TaskQueue()
```

耦合鏈分析：

```
watcher.py  ──import──► task_queue (module-level singleton)
app_anytype.py ──import──► task_queue
tasks.py    ──import──► task_queue

問題：
1. 所有模組直接 import 具體實作，無抽象介面
2. asyncio.Queue 是 in-process 的，多 Worker 進程無法共享
3. SQLite 是單檔案資料庫，多進程寫入會產生 SQLITE_BUSY
4. 無法水平擴展 — 增加第二台機器時任務佇列不互通
```

**架構級解決方案：Backend Interface + Strategy Pattern**

```python
# === Pseudocode: Abstract TaskBackend Interface ===

from abc import ABC, abstractmethod
from typing import Protocol

class TaskBackend(Protocol):
    """任務佇列後端抽象介面
    
    Phase 1: SQLiteBackend (現狀)
    Phase 4: CeleryBackend / RedisBackend (叢集)
    遵循 OCP (開放封閉原則) — 擴展新後端不需修改現有程式碼
    """

    async def enqueue(self, task_id: str, task_type: str, payload: dict) -> None:
        """將任務放入佇列"""
        ...

    async def dequeue(self) -> tuple[str, str, dict] | None:
        """從佇列取出任務 (blocking with timeout)"""
        ...

    async def update_status(self, task_id: str, status: str, **kwargs) -> None:
        """更新任務狀態"""
        ...

    async def get_task(self, task_id: str) -> dict | None:
        """查詢任務"""
        ...

    async def list_tasks(self, limit: int = 50) -> list[dict]:
        """列出任務"""
        ...


class SQLiteTaskBackend:
    """Phase 1: 現有的 SQLite 實作 (單機)"""
    # ... 將目前 TaskQueue 的 SQLite 邏輯移入此類


class CeleryTaskBackend:
    """Phase 4: Celery + Redis 實作 (叢集)"""

    def __init__(self, broker_url: str):
        from celery import Celery
        self.celery_app = Celery('bruv', broker=broker_url)

    async def enqueue(self, task_id: str, task_type: str, payload: dict):
        self.celery_app.send_task(
            f'bruv.tasks.{task_type}',
            args=[task_id, payload],
            task_id=task_id
        )
    # ...


class TaskQueue:
    """門面 (Facade) — 根據配置選擇後端"""

    def __init__(self, backend: TaskBackend | None = None):
        if backend is None:
            # 根據環境變數決定後端
            backend_type = os.getenv("TASK_BACKEND", "sqlite")
            if backend_type == "celery":
                self._backend = CeleryTaskBackend(os.getenv("CELERY_BROKER_URL"))
            else:
                self._backend = SQLiteTaskBackend()
        else:
            self._backend = backend

    async def create_and_enqueue(self, task_type, **kwargs):
        task_id = str(uuid.uuid4())
        await self._backend.enqueue(task_id, task_type, kwargs)
        return task_id
```

**遷移路徑**：

```
Phase 1 (現在):  TASK_BACKEND=sqlite   → SQLiteTaskBackend
Phase 4 (叢集):  TASK_BACKEND=celery   → CeleryTaskBackend
                 CELERY_BROKER_URL=redis://redis:6379/2

只需修改 .env 環境變數，零程式碼修改即可切換。
```

**額外建議**：

- 為 `AgentService` 也引入同樣的 Backend Pattern — 目前 `httpx.AsyncClient` 在每個方法中都 `async with` 新建 Client，應改用 `app.state.http_client` 共享連線池
- 引入 **Circuit Breaker** (斷路器) — 當 RAGFlow 或 Dify 服務掛掉時，避免排隊的請求持續等待超時：

```python
# Circuit Breaker 狀態機
CLOSED (正常) → 連續 5 次失敗 → OPEN (拒絕所有請求，直覺返回 503)
OPEN → 30 秒後 → HALF-OPEN (放行 1 個探測請求)
HALF-OPEN → 成功 → CLOSED | 失敗 → OPEN
```

---

#### 18.2.4 可觀測性與除錯 (Observability)

**現狀問題**

```python
# app_anytype.py 第 53-56 行
logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s - %(name)s - %(levelname)s - %(message)s'
)
```

在 10 個 Docker 容器 + 2 個原生進程的架構中：

| 問題 | 說明 |
|------|------|
| 無 Correlation ID | 一個使用者請求穿過 Nginx → FastAPI → Dify → RAGFlow，日誌散落在 4 個不同的 stdout，無法串聯 |
| 非結構化日誌 | 純文字格式無法被日誌系統解析、查詢、聚合 |
| 無 Metrics | 沒有 API 回應時間、錯誤率、佇列深度等即時指標 |
| 日誌散落 | 每個 Docker 容器的日誌獨立，需要逐一 `docker logs` 查看 |

**架構級解決方案：輕量級可觀測性堆疊 (適合地端單機)**

```
┌──────────────────────────────────────────────────────────┐
│               可觀測性三根柱子 (Three Pillars)              │
│                                                          │
│  1. Structured Logging  → Loki (輕量日誌聚合)             │
│  2. Metrics             → Prometheus + Grafana            │
│  3. Distributed Tracing → OpenTelemetry (最小化實作)       │
└──────────────────────────────────────────────────────────┘
```

**Step 1: 結構化日誌 + Correlation ID**

```python
# === Pseudocode: Structured Logging Middleware ===

import uuid
import json
import logging
from contextvars import ContextVar

# 每個請求的唯一追蹤 ID
request_id_var: ContextVar[str] = ContextVar('request_id', default='-')

class StructuredLogFormatter(logging.Formatter):
    """JSON 結構化日誌格式器"""
    def format(self, record):
        return json.dumps({
            "timestamp": self.formatTime(record),
            "level": record.levelname,
            "logger": record.name,
            "message": record.getMessage(),
            "request_id": request_id_var.get('-'),
            "module": record.module,
            "line": record.lineno,
            # 自動附加 exception traceback
            "exception": self.formatException(record.exc_info) if record.exc_info else None
        }, ensure_ascii=False)


class RequestTracingMiddleware:
    """為每個 HTTP 請求注入 Correlation ID"""

    async def __call__(self, request, call_next):
        # 從 Header 中取得或生成 Request ID
        req_id = request.headers.get("X-Request-ID", str(uuid.uuid4())[:8])
        request_id_var.set(req_id)

        # 將 Request ID 傳播到 downstream 呼叫
        response = await call_next(request)
        response.headers["X-Request-ID"] = req_id

        # 轉發到 Dify/RAGFlow 時也附加此 Header
        # httpx 呼叫時: headers["X-Request-ID"] = request_id_var.get()
        return response
```

**Step 2: 地端日誌聚合方案 (不需要雲端)**

```yaml
# 新增到 docker-compose.yml 的輕量級可觀測性容器
# 總共只增加 ~300MB RAM

loki:
  image: grafana/loki:2.9
  ports:
    - "127.0.0.1:3100:3100"
  volumes:
    - loki_data:/loki
  # 資源極低：~50MB RAM

promtail:
  image: grafana/promtail:2.9
  volumes:
    - /var/run/docker.sock:/var/run/docker.sock:ro  # 自動採集所有容器日誌
  # 自動採集 10 個容器 + FastAPI 的日誌並推送到 Loki

grafana:
  image: grafana/grafana:10
  ports:
    - "127.0.0.1:3000:3000"
  # 統一儀表板：日誌查詢 + Metrics 圖表
```

**Step 3: 最小化 OpenTelemetry 實作**

```python
# === app_anytype.py lifespan 中加入 ===

from opentelemetry import trace
from opentelemetry.sdk.trace import TracerProvider
from opentelemetry.sdk.trace.export import SimpleSpanProcessor, ConsoleSpanExporter
from opentelemetry.instrumentation.fastapi import FastAPIInstrumentor
from opentelemetry.instrumentation.httpx import HTTPXClientInstrumentor

# 最小化配置 — 先用 Console 輸出，未來可切換為 OTLP Exporter
provider = TracerProvider()
provider.add_span_processor(SimpleSpanProcessor(ConsoleSpanExporter()))
trace.set_tracer_provider(provider)

# 自動為 FastAPI 路由加入 Span
FastAPIInstrumentor.instrument_app(app)

# 自動為 httpx 呼叫加入 Span (追蹤 Dify/RAGFlow 請求)
HTTPXClientInstrumentor().instrument()
```

這樣一個請求的完整追蹤鏈就自動建立：

```
[Span] FastAPI: POST /api/dify/chat  (req_id=abc123)
  └── [Span] httpx: POST http://localhost:5001/v1/chat  (req_id=abc123)
       └── [Dify Internal Spans...]
```

---

### 18.3 程式碼級建議

#### 18.3.1 watcher.py `_process_file()` — 引入 Saga + 重試

改進前 (現狀)：
```python
def _process_file(self, file_path):
    upload_result = self.rag_client.upload_file(...)  # A: 可能成功
    self._add_to_graph(file_path, upload_result)      # B: 可能失敗 → 不一致！
```

改進後：
```python
def _process_file(self, file_path: Path) -> None:
    saga = SagaLog(file_path)
    ragflow_doc_id = None

    try:
        # Step A: RAGFlow Upload (with retry)
        for attempt in range(3):  # 最多重試 3 次
            try:
                upload_result = self.rag_client.upload_file(
                    dataset_id=self.dataset_id,
                    file_path=str(file_path)
                )
                ragflow_doc_id = extract_doc_id(upload_result)
                saga.mark_step("ragflow_upload", "COMPLETED", doc_id=ragflow_doc_id)
                break
            except (httpx.TimeoutException, httpx.ConnectError) as e:
                if attempt < 2:
                    time.sleep(2 ** attempt)  # Exponential backoff: 1s, 2s, 4s
                    continue
                saga.mark_step("ragflow_upload", "FAILED", error=str(e))
                raise

        # Step B: KuzuDB Write
        entity_id = self._add_to_graph(file_path, upload_result, graph_id)
        if entity_id:
            saga.mark_step("kuzu_write", "COMPLETED", entity_id=entity_id)
        else:
            saga.mark_step("kuzu_write", "FAILED")
            # 補償: 刪除已上傳的 RAGFlow 文件
            if ragflow_doc_id:
                self.rag_client.delete_document(ragflow_doc_id)
                logger.warning(f"補償完成: 已撤銷 RAGFlow 上傳 {ragflow_doc_id}")
            return

        # Step C: Excel Parse (optional, 失敗不補償，只記錄)
        if file_path.suffix.lower() == '.xlsx' and entity_id:
            self._parse_excel_and_link(file_path, entity_id, graph_id)

    except Exception as e:
        logger.error(f"Saga 失敗: {file_path.name} - {e}", exc_info=True)
        # 寫入 Dead Letter Queue
        self._record_dlq(file_path, saga, str(e))
```

#### 18.3.2 KuzuDBManager — 加入 asyncio.Lock 的最小改動

不需要完整重寫，只需在現有 `KuzuDBManager` 上包裝一層：

```python
# === backend/core/kuzu_manager.py — 最小改動 ===

import asyncio
from concurrent.futures import ThreadPoolExecutor

class AsyncKuzuWrapper:
    """為現有 KuzuDBManager 加入 async 安全層
    
    使用方式：
        wrapper = AsyncKuzuWrapper(kuzu_manager)
        result = await wrapper.safe_write("MERGE ...", params)
        result = await wrapper.safe_read("MATCH ...", params)
    """

    def __init__(self, manager: KuzuDBManager):
        self._manager = manager
        self._write_lock = asyncio.Lock()
        self._executor = ThreadPoolExecutor(max_workers=4, thread_name_prefix="kuzu")

    async def safe_write(self, cypher: str, parameters: dict = None) -> bool:
        """所有寫入操作在 Lock 保護下序列化執行"""
        async with self._write_lock:
            loop = asyncio.get_event_loop()
            return await loop.run_in_executor(
                self._executor,
                lambda: self._manager.conn.execute(cypher, parameters=parameters or {})
            )

    async def safe_read(self, cypher: str, parameters: dict = None) -> list:
        """讀取操作不需要 Lock，但需要避免阻塞事件迴圈"""
        loop = asyncio.get_event_loop()
        return await loop.run_in_executor(
            self._executor,
            lambda: self._manager.query(cypher, parameters)
        )
```

#### 18.3.3 TaskQueue — 為未來遷移預留介面

最小改動，不影響現有行為：

```python
# === backend/services/task_queue.py — 在檔案頂部加入 ===

from typing import Protocol, runtime_checkable

@runtime_checkable
class TaskBackend(Protocol):
    """任務後端抽象介面 — 未來遷移到 Celery 時只需實作此介面"""
    def create_task(self, task_type: str, **kwargs) -> str: ...
    def get_task(self, task_id: str) -> dict | None: ...
    def update_status(self, task_id: str, status: str, **kwargs) -> None: ...
    def list_tasks(self) -> list[dict]: ...

# 現有的 TaskQueue 類別自動 "實作" 此介面 (Duck Typing)
# 未來新增 CeleryTaskQueue 時，只需實作同一介面
```

---

### 18.4 優先級行動計劃 — 全部完成 ✅ (2026-02-11)

| 優先級 | 項目 | 狀態 | 實作檔案 |
|--------|------|------|----------|
| **P0** | KuzuDB asyncio.Lock + run_in_executor | ✅ 已完成 | `backend/core/kuzu_manager.py` (AsyncKuzuWrapper) |
| **P0** | watcher.py 加入補償機制 | ✅ 已完成 | `backend/services/watcher.py` (Saga + 重試 + DLQ) |
| **P1** | 結構化日誌 + Request ID Middleware | ✅ 已完成 | `backend/core/logging.py` |
| **P1** | TaskBackend Protocol 抽象介面 | ✅ 已完成 | `backend/services/task_queue.py` |
| **P2** | Loki + Grafana Docker 配置 | ✅ 已完成 | `observability/*.yml` |
| **P2** | CircuitBreaker for Dify/RAGFlow | ✅ 已完成 | `backend/core/circuit_breaker.py` |
| **P3** | 完整 Saga Orchestrator + DLQ | ✅ 已完成 | `backend/services/saga.py` + `backend/api/system.py` |
| **P3** | OpenTelemetry 分散式追蹤 | ✅ 已完成 | `backend/core/telemetry.py` |

> 整合測試 **15/15 全部通過**。詳見 `docs/SAGA_TEST_FINAL_REPORT.md`。

---

## 19. 變更紀錄

| 日期 | 版本 | 變更內容 |
|------|------|---------|
| 2026-02-07 | v3.0 | 初始架構文件 (Anytype Edition) |
| 2026-02-10 | v3.1 | 整合為單一規劃主文件，新增四層架構概述、安全縱深防禦五層模型、硬體規格建議、未來擴展路線圖、變更紀錄 |
| 2026-02-10 | v3.2 | 架構深度審查 — 新增紅隊測試報告 (§18)：資料一致性 Saga Pattern、KuzuDB 併發控制、TaskBackend 抽象介面、輕量級可觀測性方案、程式碼級 Pseudocode、優先級行動計劃 |
| 2026-02-11 | v3.3 | **§18.4 優先級行動計劃實作完成 — 整合測試 15/15 通過**。詳見 `docs/SAGA_TEST_FINAL_REPORT.md` |
| 2026-02-11 | v3.4 | **節點互連引擎 + 圖譜刪除功能**。詳見下方 v3.4 變更明細 |
| 2026-02-11 | v3.5 | **前端抓取邏輯整理 — 統一 API 呼叫架構**。詳見下方 v3.5 變更明細 |
| 2026-02-11 | v3.6 | **RAGFlow Hybrid Search + Rerank 檢索升級**。詳見下方 v3.6 變更明細 |
| 2026-02-12 | v3.7 | **Ollama 本地 LLM 引擎部署 (Phase 3)**。詳見下方 v3.7 變更明細 |
| 2026-02-12 | v3.8 | **RAGFlow ↔ Ollama 橋接驗證**。新增 `scripts/check_ollama_bridge.ps1` 容器互通性檢查腳本，確認 Docker bridge 連線狀態、模型可見性、推薦 Base URL |
| 2026-02-12 | v3.9 | **3D 圖譜渲染引擎升級 + 工專清理**。詳見下方 v3.9 變更明細 |
| 2026-02-13 | v4.0 | **企業級 UI 主題全面改造 — Enterprise Navy 設計系統**。詳見下方 v4.0 變更明細 |
| 2026-02-14 | v5.0 | **Excel 批量智能匯入引擎大幅升級 + 架構審計修復**。詳見下方 v5.0 變更明細 |
| 2026-02-17 | v5.1 | **連線管理系統 + Tag 標籤系統 + Settings 重寫 + 3D 圖譜增強**。詳見下方 v5.1 變更明細 |

### v5.1 變更明細

**核心目標：連線管理系統 (Connection Manager) + Tag 標籤系統全鏈路支援 + Settings 頁面全面重寫 + 3D 圖譜互動增強**

#### 一、連線管理系統 — 後端 (backend/api/system.py · backend/core/config.py)

取代舊的 flat config (dify_api_key/url + ragflow_api_key/url 四個獨立欄位)，升級為結構化 `connections` 陣列，支援多連線 CRUD。

**新增 8 個 API 端點**：

| 端點 | 說明 |
|------|------|
| `GET /api/system/connections` | 列出所有連線配置 |
| `POST /api/system/connections` | 新增連線 |
| `PUT /api/system/connections/{conn_id}` | 更新連線 |
| `DELETE /api/system/connections/{conn_id}` | 刪除連線 |
| `POST /api/system/connections/{conn_id}/test` | 測試指定連線 |
| `POST /api/system/test-connection-inline` | Dialog 內即時測試 (不儲存) |
| `POST /api/system/detect-services` | 自動偵測可用服務 (掃描 Dify/RAGFlow/Ollama 等常見端口) |

**連線類型**：`dify` / `ragflow` / `ollama` / `openai` / `custom` (通用 HTTP 探測)

**config.py 擴展**：
- `generate_connection_id()` — 產生唯一連線 ID (`conn_xxxxxxxxxxxx`)
- `load_connections()` — 載入連線，首次使用時**自動從舊格式遷移**
- `save_connections()` — 儲存連線，**同步維護舊格式 flat keys** 確保向後相容

| 修改檔案 | 行數變化 | 變更說明 |
|---------|---------|---------|
| `backend/api/system.py` | 599 → 977 | 新增 8 個連線管理端點 + `_probe_service()` 通用探測器 + `ConnectionModel` / `InlineTestRequest` 資料模型 |
| `backend/core/config.py` | 134 → 205 | 新增連線 CRUD 函式 + 舊格式自動遷移 + 向後相容同步 |
| `config.json.example` | +40 行 | 新增 `connections` 陣列範例 (Dify/RAGFlow/Ollama 三個預設連線) |

#### 二、Tag 標籤系統 — 全鏈路支援

**後端**：
- `graph_import.py`：`_COLUMN_ALIASES` 新增 `tags` 欄位 (支援 `標籤`/`tags`/`標記`/`tag`/`分類標籤` 欄名)；LLM Prompt 新增 tags 規則 (3-5 個分類標籤)；`_validate_node()` 新增 tags 驗證與別名轉換
- `graph.py`：`EntityUpdate` 模型新增 `tags: Optional[List[str]]`，`update_entity()` 支援 tags 更新
- `app_anytype.py`：`get_graph_data()` 回傳節點時新增 `tags` 欄位，支援 JSON 字串 / 逗號分隔 / 已解析列表三種格式

**前端 Store** (`graphStore.js` 1445 → 1566 行)：
- 新 State：`activeTagFilter`、`tagFilterMode` ('any' | 'all')
- 新 Computed：`allTags` (全域唯一 Tag 統計，按數量排序)、`nodesByTag` (按 Tag 分群)、`filteredNodes` 疊加 Tag 過濾
- 新 Actions：`addTagToNode()` / `removeTagFromNode()` / `getAllTagNames()` / `setTagFilter()`
- `_addNodeRaw()` 新增 tags 陣列初始化

**前端 UI**：
- `GraphPage.vue`：節點檢視面板新增 **Tags 編輯區塊** — Tag 膠囊 (藍色圓角 pill) + 刪除按鈕 + 輸入框 (Enter 新增) + 常用 Tag 快速選擇 (前 8 個高頻 Tag + 使用次數)
- `NexusPanel.vue`：側邊節點列表新增 **Tag 篩選列** (全部 + 前 10 個 Tag 按鈕)；節點項顯示 Tag 膠囊 (最多 2 個 + 溢出計數)
- `Graph2D.vue`：節點底部 Canvas 繪製 **Tag 色點指示器** (最多 4 個，縮放 ≥0.6 時顯示)
- `Graph3D.vue`：節點底部顯示 **Tag 色環指示器** (最多 4 個，6 色循環)

#### 三、Settings 頁面全面重寫 (Settings.vue 927 → 1125 行)

- **Tab 分頁架構**：`connections` (連線管理)、`users` (帳號管理)
- **連線卡片列表**：每個連線顯示名稱、類型標章 (D/R/O/A/C)、啟用狀態、測試狀態指示燈
- **新增/編輯 Dialog**：類型切換、URL 智慧建議 (結合偵測結果 + 預設值)、API Key 記住選項、即時測試
- **自動偵測服務面板**：一鍵掃描本地常見端口，顯示可用服務列表，可直接一鍵添加
- **API Key 安全機制**：`remember_key` 選項，不記住時使用 `localStorage` 暫存

#### 四、3D 圖譜互動增強 (Graph3D.vue 948 → 1026 行)

| 功能 | 說明 |
|------|------|
| 平行連線曲率 | `_rebuildParallelLinkCache()` 避免同一對節點間多條連線重疊 |
| 連線互動 | `handleLinkClick()` 點擊顯示 ElMessage (AI/普通標示 + 信心值)；`handleLinkHover()` 游標指針切換 |
| 連線標籤 tooltip | hover 時顯示 HTML 富文本 (AI 連線：黃色 + 原因 + 信心值) |
| 方向箭頭 | 所有連線顯示箭頭 (AI 連線箭頭更大)，支援 focusFade 淡化 |
| Bug 修復 | `clampScalar` 改用手動 `Math.min/max` 避免相容性問題；`initGraph()` await 後重新檢查 `graphContainer.value` 防止組件已卸載 |

#### 五、新增文件

| 檔案 | 說明 |
|------|------|
| `docs/UPLOAD_LOGIC.md` (542 行) | 完整上傳管線技術參考 — 架構總覽、前端 ImportPage 流程、後端處理細節、RAGFlow 整合、Watcher Saga、TaskQueue、錯誤處理與診斷 |
| `.github/copilot-instructions.md` | Copilot 技能包指令 — 自動讀取機制 + 專案架構快速參考 |

#### 六、基礎設施

| 修改 | 說明 |
|------|------|
| `docker-compose.yml` | Ollama `latest` tag 定期 pull 提醒 + 舊版 bge-m3 NaN embedding 已知問題警告 |

#### 本版修改檔案總覽

| 檔案 | 行數 | 主要變更 |
|------|------|---------|
| `backend/api/system.py` | 977 | 連線管理 CRUD + 自動偵測 + 即時測試 |
| `backend/core/config.py` | 205 | connections 陣列 + 舊格式遷移 + 向後相容 |
| `backend/api/graph_import.py` | 1205 | tags 欄位匯入 + LLM Prompt tags 規則 |
| `backend/api/graph.py` | 540 | EntityUpdate 新增 tags |
| `app_anytype.py` | 617 | get_graph_data 新增 tags 欄位解析 |
| `frontend/src/views/Settings.vue` | 1125 | Tab + 連線卡片 + Dialog + 偵測面板 全面重寫 |
| `frontend/src/stores/graphStore.js` | 1566 | Tag 過濾/統計/操作 + activeTagFilter |
| `frontend/src/views/GraphPage.vue` | 2530 | Tags 編輯區塊 (膠囊 + 輸入 + 快速選擇) |
| `frontend/src/components/NexusPanel.vue` | +37 行 | Tag 篩選列 + 節點 Tag 膠囊 |
| `frontend/src/views/Graph3D.vue` | 1026 | 平行連線 + 互動 + 箭頭 + Tag 色環 |
| `frontend/src/components/Graph2D.vue` | 877 | Tag 色點指示器 |
| `config.json.example` | +40 行 | connections 陣列範例 |
| `docs/UPLOAD_LOGIC.md` | 542 | 上傳邏輯技能包 (新增) |
| `.github/copilot-instructions.md` | — | Copilot 指令 (新增) |

### v5.0 變更明細

**核心目標：將 Excel/CSV 批量匯入能力從數十筆提升至 3000 筆，並套用架構審計修正項目**

本版包含 7 個 Git 提交 (`64ab503` ~ `ad1d68a`)，涵蓋 6 大改進主題：

#### 一、config.json BOM 修復 (`64ab503`)

**問題**：`config.json` 含有 UTF-8 BOM 字元 → `json.load()` 解析失敗 → 回退使用 `.env` 的佔位 API Key → Dify 401 → 全部 65 個節點「LLM 分析失敗」。

| 修改檔案 | 變更說明 |
|---------|---------|
| `backend/core/config.py` | `open()` 改用 `encoding='utf-8-sig'` 自動處理 BOM |

#### 二、GPU 併發最佳化 (`662e8f6`)

**問題**：`MAX_CONCURRENCY=8` 超載單 GPU (RTX 4070 Super 12GB) → 大量 timeout → 節點內容「未提供」。

| 參數 | 舊值 | 新值 | 說明 |
|------|------|------|------|
| `MAX_CONCURRENCY` | 8 | 2 | 本地 Ollama GPU 專用 |
| `LLM_TIMEOUT` | 120s | 300s | qwen2.5:14b 長上下文需要更多時間 |
| `TARGET_BATCH_TOKENS` | 4000 | 2000 | 降低每批 token 量確保品質 |
| `BATCH_DELAY` | 0.5s | 1.0s | GPU 冷卻時間 |

另外強化 `_validate_node()` 支援別名 (`title`/`name`/`標題`/`名稱`)，減少「未提供」情況。

#### 三、RAGFlow 合併上傳 (`ce3f270`)

**問題**：每行資料分別上傳一個文件至 RAGFlow → 65 筆產生 65 個文件，知識庫膨脹。

**改進**：按節點類型分組合併 → 生成 5-10 個結構化 `.md` 文件 → 超過 200KB 自動分割。

| 修改檔案 | 變更說明 |
|---------|---------|
| `backend/api/graph_import.py` | `_upload_to_ragflow()` 重寫：按類型分組 + `.md` 結構化輸出 + `MAX_RAGFLOW_FILE_BYTES=200_000` 分割 |

#### 四、3000 筆大規模匯入支援 (`b268304`)

修復 7 項瓶頸以支撐 3000 筆資料匯入：

| 層級 | 修復項目 | 說明 |
|------|---------|------|
| 後端 | 記憶體釋放 | KuzuDB 寫入完成後 `del nodes` 釋放記憶體 |
| 後端 | Status API 瘦身 | 不再回傳完整 `nodes` 陣列，改回傳 `node_count` |
| 後端 | RAGFlow 文件分割 | 超過 200KB 自動切割 |
| 後端 | 任務過期延長 | `_TASK_EXPIRY_SECONDS` 3600→7200 (2 小時) |
| 前端 | 輪詢超時 | ImportPage 輪詢超時 30min→2h (2400 × 3s) |
| 前端 | Set 去重 | `addBatchNodes` 用 `Set` O(1) 取代 `.some()` O(N×M) |
| 前端 | fetchGraphData | `pollImportStatus` 完成後用 `fetchGraphData()` 取代直接塞入 `data.nodes` |

#### 五、LLM 瓶頸突破 — 三大策略 (`8ff0e6c`)

| 策略 | 說明 | 效果 |
|------|------|------|
| **欄位智能提取** | `_try_extract_from_columns()` — 匹配 Excel 欄名別名 (`標題`→label, `類型`→type, `描述`→description, `關鍵詞`→keywords)，直接跳過 LLM | 有對應欄位的行 100% 免 LLM |
| **LLM 結果快取** | MD5 雜湊去重 (`_llm_result_cache`)，相同內容跨批次只呼叫一次 LLM，上限 10K 筆 | Fast mode 下啟用 |
| **自適應大批次** | `TARGET_BATCH_TOKENS_FAST=6000` (一般模式 2000)，搭配 qwen2.5:14b 128K 上下文窗口，每批可處理 ~30 行 | ~3x 吞吐量提升 |

**修改檔案**：`backend/api/graph_import.py` — `_run_import()` 大幅重寫整合三大策略、`row_results[]` 合併陣列、`_COLUMN_ALIASES` 字典。

#### 六、架構審計修復 (`ad1d68a`)

根據 walkthrough.md 審計結果，修正 2 項有效問題：

| 修改檔案 | 變更說明 |
|---------|---------|
| `backend/core/auth.py` | 移除硬編碼 `Path("C:/BruV_Data/auth_token.json")` → 使用 `BRUV_DATA_DIR` 環境變數，與 config.py 一致 |
| `docker-compose.yml` | 移除已棄用 `version: '3.8'` 欄位 (Docker Compose V2 會產生警告) |

#### 本版修改檔案總覽

| 檔案 | 行數 | 主要變更 |
|------|------|---------|
| `backend/api/graph_import.py` | 1284 | GPU 參數、合併上傳、3000 筆支援、3 大 LLM 策略 |
| `backend/core/config.py` | 134 | `utf-8-sig` 編碼處理 BOM |
| `backend/core/auth.py` | 330 | `BRUV_DATA_DIR` 環境變數取代硬編碼路徑 |
| `docker-compose.yml` | 318 | 移除 `version: '3.8'` |
| `frontend/src/views/ImportPage.vue` | 1249 | 輪詢超時 2h、`extracted_count` 顯示 |
| `frontend/src/stores/graphStore.js` | 1445 | `fetchGraphData` 取代 `data.nodes`、Set 去重 |

### v3.3 變更明細

**測試結果 (15/15 Pass)**

| 測試組 | 項目數 | 結果 |
|--------|-------|------|
| Backend 可用性 | 2 | ✅ |
| CircuitBreaker 狀態 | 6 | ✅ |
| DLQ 端點 | 2 | ✅ |
| Saga 補償機制 | 2 | ✅ |
| 結構化日誌 + X-Request-ID | 2 | ✅ |
| OpenTelemetry 狀態 | 1 | ✅ |

**修復的 5 個 Bug**

1. **RAGFlow URL 轉換錯誤** — `app_anytype.py`、`system.py` 中 `/api/v1` 被錯誤轉為 `/v1`，導致 API 呼叫失敗。已移除轉換邏輯，直接使用 config URL。
2. **rag_client 未檢查回應 body** — RAGFlow 以 HTTP 200 回傳業務層錯誤 (`code=401`)，`raise_for_status()` 無法偵測。已新增 `_check_response()` 與 `RAGFlowAPIError`。
3. **`delete_document()` 簽章不匹配** — 缺少 `dataset_id` 參數且 API 路徑格式錯誤。已更新為 v1 格式 `/datasets/{id}/documents`。
4. **httpx DELETE 不支援 `json=`** — `httpx.Client.delete()` 無法傳遞 JSON body。改用 `client.request("DELETE", ..., content=body)`。
5. **`.env` API Key 遮罩值** — `RAGFLOW_API_KEY` 存放的是遮罩字串而非真實金鑰。已修正。

**已知問題**: RAGFlow MySQL schema 拼字錯誤 (`process_duation` → `process_duration`)，導致檔案上傳失敗，需由 RAGFlow 端修復。

### v3.4 變更明細

**核心功能：節點互連引擎 (Inter-Node Linking Engine)**

解決問題：RAGFlow 解析 Excel 後，圖譜中的資料節點僅以星狀拓撲 (`contains` 關係) 連接到文件節點，節點之間沒有任何互連，導致知識圖譜無法呈現資料間的關聯性。

| 連線類型 | 演算法 | 上限 |
|---------|--------|------|
| `same_domain` | 提取 URL 的網域名稱，同域資源自動互連 | 每域 20 條 |
| `keyword_overlap` | 從標題/描述提取關鍵字 (CJK ≥2 字元, EN ≥3 字元, 含停用詞過濾)，≥2 共同關鍵字即建立連線 | 總計 100 條 |

**實測結果** (graph_c8e84245d755, 68 節點)：

| 連線類型 | 數量 |
|---------|------|
| `contains` (原有) | 195 |
| `same_domain` (新增) | 29 |
| `keyword_overlap` (新增) | 101 |
| **總計** | **325** |

**觸發方式**：
1. **自動**：Saga Step D — 每次 Excel 上傳解析後自動執行 (Step A→B→C→**D**)
2. **手動**：`POST /api/graph/interlink/{graph_id}` — 管理員可隨時重新分析

**修改的檔案 (6 個)**：

| 檔案 | 變更類型 | 說明 |
|------|---------|------|
| `backend/services/watcher.py` | 新增 ~200 行 | `_build_inter_node_links()` 互連引擎 + Saga Step D 整合 |
| `backend/rag_client.py` | 新增 ~60 行 | `get_chunks()`, `async_get_chunks()`, `get_document_status()`, `async_get_document_status()` 四個新方法 |
| `backend/api/graph.py` | 新增 ~35 行 | `POST /interlink/{graph_id}` 手動觸發端點 + Delete 回應增強 |
| `backend/core/kuzu_manager.py` | 新增 ~40 行 | `safe_delete_graph_metadata(graph_id, cascade)` 級聯刪除 |
| `frontend/src/stores/graphStore.js` | 新增 ~30 行 | `deleteGraph(graphId, cascade)` action |
| `frontend/src/views/GraphPage.vue` | 修改 ~40 行 | `handleDeleteGraph()` 完整確認對話框 + 主腦保護邏輯 |

### v3.5 變更明細

**核心目標：前端抓取邏輯整理 — 統一 API 呼叫架構**

整理前的問題：

| # | 問題 | 影響 |
|---|------|------|
| 1 | 各 View 直接呼叫 `authFetch()` + 手動 `response.ok` / `.json()` 處理 | 大量重複的樣板程式碼 |
| 2 | `apiClient.js` 已有 `apiGet/apiPost` 等高層函式，但無人使用 | 工具函式閒置 |
| 3 | Settings.vue 使用 `http://localhost:8000` 絕對路徑 | 生產環境不一致、潛在 CORS 問題 |
| 4 | GraphPage.vue 直接呼叫 API 更新/刪除節點 | 繞過 Store，抓取邏輯分散在 View 層 |
| 5 | RAGFlow 知識庫列表在 ImportPage 和 NexusPage 各自抓取 | 重複邏輯、重複網路請求 |
| 6 | ImportPage 有 12 行 `[DEBUG]` console.log | 主控台汙染 |

**整理後的架構層級**：

```
Views (頁面元件)
  │
  ├── 圖譜操作 → graphStore (Pinia)
  │                ├── 透過 GraphDataManager (快取/去重層)
  │                │     └── authFetch (底層)
  │                └── 直接呼叫 apiGet/apiPost/apiPut/apiDelete/apiPostForm (高層)
  │
  └── 系統操作 → apiGet/apiPost (Settings 等頁面直接使用高層函式)
```

**修改的檔案 (6 個)**：

| 檔案 | 行數變化 | 變更說明 |
|------|---------|---------|
| `frontend/src/services/apiClient.js` | 102 → 154 | 強化錯誤提取 `_extractErrorMessage()`；新增 `apiPostForm()` 支援 FormData 上傳；所有高層函式統一錯誤格式 |
| `frontend/src/stores/graphStore.js` | 1333 → 1315 | 7 個方法改用 `apiGet/apiPost/apiPostForm` 消除樣板；新增 `updateEntity()`、`deleteEntity()`、`fetchRAGFlowDatasets()` + `ragflowDatasets` 共用狀態 |
| `frontend/src/views/Settings.vue` | 985 → 927 | 移除 `API_BASE_URL` 絕對路徑；`loadConfig/saveConfig/testConnection` 三方法改用 `apiGet/apiPost` |
| `frontend/src/views/GraphPage.vue` | 2556 → 2532 | 移除 `authFetch` import；`saveChanges()` 改用 `graphStore.updateEntity()`；刪除節點改用 `graphStore.deleteEntity()` |
| `frontend/src/views/ImportPage.vue` | 1186 → 1143 | 刪除 55 行本地 `loadRAGFlowDatasets()`（含 12 行 DEBUG 日誌）；改用 `graphStore.fetchRAGFlowDatasets()` + `computed` |
| `frontend/src/views/NexusPage.vue` | 677 → 663 | 移除 `authFetch` import 和本地 `fetchRAGFlowDatasets()`；改用 `graphStore` 集中管理 |

**新增的 Store 方法**：

| 方法 | 說明 |
|------|------|
| `updateEntity(nodeId, updates)` | 呼叫 `PUT /api/graph/entities/{id}` + 同步 Store |
| `deleteEntity(nodeId)` | 呼叫 `DELETE /api/graph/entities/{id}` + 同步 Store |
| `fetchRAGFlowDatasets()` | 呼叫 `GET /api/ragflow/datasets`，結果存入 `ragflowDatasets` ref 供全頁面共用 |

**新增的 apiClient 方法**：

| 方法 | 說明 |
|------|------|
| `apiPostForm(url, formData)` | FormData 上傳，不設 Content-Type（瀏覽器自動處理 multipart boundary） |
| `_extractErrorMessage(response)` | 從非 2xx 回應統一提取 `detail` / `message` 錯誤訊息 |

**效果**：
- 消除 3 份重複的 RAGFlow 資料集抓取邏輯 → 1 處集中管理
- 消除 Settings.vue 的 `http://localhost:8000` 硬編碼
- GraphPage 的實體 CRUD 從 View 層搬進 Store 層，實現「View 不直接發 API」原則
- 所有修改檔案通過 `get_errors` 驗證：**零錯誤**

**核心功能：圖譜刪除 (Graph Delete with Cascade)**

- 後端：`DELETE /api/graph/metadata/{graph_id}?cascade=true` — 級聯刪除圖譜及其下所有節點與關係
- 前端：`GraphPage.vue` 確認對話框顯示節點/連線數量，禁止刪除主腦圖譜 (ID=1)
- 刪除後自動切換至主腦圖譜

### v3.7 變更明細

**核心目標：Phase 3 — 部署 Ollama 本地 LLM 引擎，實現完全離線推理**

解決問題：系統依賴外部 LLM API (OpenAI / 雲端模型) 進行推理，敏感資料需傳送至外部伺服器，不符合企業資料隱私要求。

**部署架構**：

```
主機 / Docker 內網 (bruv_network)
│
├── bruv_ollama (ollama/ollama:latest)
│   ├── Port: 11434 (對外 + 對內)
│   ├── GPU: NVIDIA 全 GPU 直通 (deploy.resources.reservations.devices)
│   ├── Volume: ollama_data:/root/.ollama (模型持久化)
│   └── 預載模型:
│       ├── llama3 (4.7 GB) — 通用 LLM 推理
│       └── nomic-embed-text (274 MB) — 文本嵌入
│
├── RAGFlow → http://ollama:11434 (Docker 內網直連)
├── Dify    → http://ollama:11434 (Docker 內網直連)
└── 主機    → http://localhost:11434 (本地存取)
```

**修改 / 新增的檔案 (2 個)**：

| 檔案 | 行數變化 | 變更說明 |
|------|---------|--------|
| `docker-compose.yml` | 277 → 297 | 新增 `ollama` 服務 (GPU 直通 + volume + network) + `ollama_data` volume + RAGFlow `OLLAMA_HOST` 註解更新為 Docker 內網位址 |
| `scripts/init_ollama.ps1` | 新增 ~95 行 | 初始化腳本：健康檢查等待 → 模型存在性檢測 → `docker exec` 拉取模型 → 推理測試 → 端點清單輸出 |

**初始化腳本功能** (`scripts/init_ollama.ps1`)：

| 步驟 | 說明 |
|------|------|
| 1. 健康檢查 | 輪詢 `http://localhost:11434` 最多 120 秒 |
| 2. 模型拉取 | `docker exec bruv_ollama ollama pull llama3` + `nomic-embed-text`，已存在則跳過 |
| 3. 模型清單 | `docker exec bruv_ollama ollama list` 列出已安裝模型 |
| 4. 推理測試 | POST `/api/generate` 測試 llama3 回應 |
| 5. 端點輸出 | 顯示 Docker 內網 / 主機存取端點 |

**驗證結果**：
- `bruv_ollama` 容器狀態：Running ✅
- `http://localhost:11434` → "Ollama is running" ✅
- llama3 推理測試 → 回應 "Hello!" (32.15s) ✅
- nomic-embed-text 載入完成 ✅
- Docker 容器總數：9 → 10 (+ Ollama)
- Docker Volumes：9 → 10 (+ `ollama_data`)

**RAGFlow / Dify 整合方式**：
取消 `docker-compose.yml` 中 RAGFlow 段落的 `OLLAMA_HOST` 註解即可使用本地模型：
```yaml
# ragflow 服務 environment 區段取消以下註解：
- OLLAMA_HOST=http://ollama:11434
```

---

### v3.6 變更明細

**核心目標：RAGFlow 檢索升級 — Hybrid Search + Rerank 機制**

整理前的問題：

| # | 問題 | 影響 |
|---|------|------|
| 1 | `query_ragflow` 端點僅傳遞 `question, dataset_ids, top_k` 三個參數 | 無法控制混合檢索權重與相似度門檻 |
| 2 | `ragflow.py` 直接使用 `httpx.AsyncClient` 手動建構 request | 繞過 `RAGFlowClient`，邏輯分散 |
| 3 | 缺少 `rerank_id` 參數 | 無法啟用 Rerank 模型進行結果重排序 |
| 4 | `top_k` 預設值為 5 | 初篩範圍過小，召回率不足 |
| 5 | `RAGFlowAPIError` 未被端點 catch | 業務錯誤 (code≠0) 落入全域 500 handler |

**修改的檔案 (2 個)**：

| 檔案 | 行數變化 | 變更說明 |
|------|---------|---------|
| `backend/rag_client.py` | 194 → 236 | 新增 `retrieve()` 非同步方法 — Hybrid Search + Rerank |
| `backend/api/ragflow.py` | 148 → 242 | `RAGFlowQuery` 模型擴充 8 個參數；`query_ragflow` 改用 `RAGFlowClient.retrieve()` 透傳；新增 `RAGFlowAPIError` catch (422) |

**RAGFlowQuery 新增參數**：

| 參數 | 型別 | 預設值 | 說明 |
|------|------|--------|------|
| `page` | int | 1 | 分頁頁碼 |
| `page_size` | int | 10 | 每頁筆數 |
| `similarity_threshold` | float | 0.2 | 最低相似度門檻 |
| `vector_similarity_weight` | float | 0.3 | 向量 vs 關鍵字權重 (0~1) |
| `top_k` | int | 1024 | 初篩範圍 (原 5 → 1024) |
| `rerank_id` | Optional[str] | None | Rerank 模型 ID (None = 不啟用) |

**架構改善**：

```
Before (v3.5):
  ragflow.py → httpx.AsyncClient → POST /retrieval (手動建構 3 參數)

After (v3.6):
  ragflow.py → RAGFlowClient.retrieve() → POST /retrieval (8 參數透傳)
       ↓
  RAGFlowClient._check_response() → RAGFlowAPIError (422)
```

**驗證結果**：
- `POST /api/ragflow/query` 使用真實 dataset_id 測試 → `code: 0` ✅
- 空 `dataset_ids` 測試 → `RAGFlowAPIError` 正確回傳 422 ✅
- `GET /api/ragflow/documents/{id}` 上傳功能驗證 → 正常回傳 ✅
- 兩個修改檔案 `get_errors` 驗證：**零錯誤** ✅

---

### v3.9 變更明細

**核心目標：3D 圖譜渲染引擎升級 + 工專清理**

#### 一、Graph3D.vue 渲染引擎重構（對齊 2D 邏輯）

將 `Graph2D.vue` 的成熟渲染邏輯完整移植到 `Graph3D.vue`，確保 2D/3D 切換時行為一致。

| 移植項目 | 說明 |
|---|---|
| **防抖 + 更新鎖** | `updateGraphData` 150ms 防抖 + `isUpdating` 鎖，避免重複渲染 |
| **淺層 Watch** | 用 `nodeCount/linkCount/aiLinkCount/crossGraphMode/currentGraphId` 取代 `{ deep: true }`，大幅提升效能 |
| **nodeVersion 同步** | 節點名稱/顏色/類型等屬性變更時即時同步，不重載整個圖 |
| **Focus-fade 效果** | 選中節點後：鄰居 85% 透明度、無關節點 12%、選中節點放大 1.4x + 金色光暈 |
| **Focus-fade 連線** | 無關連線顏色降至 `0.06` 透明度、寬度降至 `0.3`，聚焦體驗一致 |
| **密度過濾** | `densityThreshold` prop 控制 `nodeVisibility` + `linkVisibility`，隱藏低連接度節點 |
| **3D 材質直改** | 選中節點時直接修改 `material.opacity` / `emissiveIntensity` / `scale`，不重建 Three.js 物件 |
| **縮放控制** | 新增 `zoomIn`/`zoomOut`/`zoomToFit`/`resetView`/`getZoom` 方法，暴露給父組件 |
| **防抖 Resize** | 頂層定義 `handleResize`（200ms 防抖），`onUnmounted` 統一清理 |

**Bug 修復**：
- `graph._destructor()` → `graphInstance._destructor()`（變數名稱錯誤）
- 移除重複的 theme watch
- 移除巢狀 `onUnmounted`（改為頂層統一清理）

**修改檔案**：

| 檔案 | 行數變化 | 變更說明 |
|------|---------|---------|
| `frontend/src/views/Graph3D.vue` | 776 → 948 | 完整移植 2D 渲染邏輯 + Focus-fade + 密度過濾 + 縮放控制 |

#### 二、工專清理

刪除臨時測試腳本和檔案，減少專案雜訊：

| 刪除項目 | 類型 | 說明 |
|----------|------|------|
| `test_e2e.py` | 根目錄測試腳本 | 已完成的整合測試 |
| `test_ragflow_connection.py` | 專案目錄測試腳本 | RAGFlow 連線測試（已驗證完畢） |
| `frontend/build_out.txt` | 建置日誌 | 臨時建置輸出 |
| `frontend/build_output.txt` | 建置日誌 | 臨時建置輸出 |
| `frontend/build_result.txt` | 建置日誌 | 臨時建置輸出 |
| `frontend/dist_test/` | 建置產出目錄 | 測試用建置結果（35 檔案） |
| `tests/` 目錄 (18 檔案) | 測試目錄 | 開發期間的測試腳本，已驗證完畢 |

**驗證結果**：
- `Graph3D.vue` 編譯零錯誤 ✅
- Vite build 3162 modules → 35 files ✅

---

### v4.0 變更明細

**核心目標：企業級 UI 主題全面改造 — 從「Nexus Universe」霓虹賽博風格升級為「Enterprise Navy」專業深色主題**

設計理念：採用深色海軍藍與炭灰色調，營造高信任感的專業氛圍。布局使用精細的「毛玻璃」卡片效果（`backdrop-filter: blur(24px) saturate(1.2)`），搭配細膩的半透明邊框與狀態指示燈（連線成功綠色脈衝環）。字體為現代無襯線體 Inter (300–800)，操作按鈕改為實色與線條組合，確保在維持科技感的同時符合專業後台管理系統的嚴謹性。

#### 一、設計系統變更

**色彩系統 — 舊 vs 新**：

| Token | 舊值 (Nexus Universe) | 新值 (Enterprise Navy) |
|-------|----------------------|------------------------|
| `--bg-main` | `#0c1029` (深太空藍) | `#0b1222` (深海軍藍) |
| `--bg-surface` | `#1a1d3a` | `#111a2e` |
| `--bg-elevated` | `#252847` | `#182136` |
| `--bg-card` | — | `rgba(17, 26, 46, 0.65)` (半透明毛玻璃) |
| `--bg-input` | — | `#0d1526` |
| `--border-color` | `#2d3154` (不透明) | `rgba(148, 163, 184, 0.12)` (半透明 slate) |
| `--text-primary` | `#e0e0ff` | `#e2e8f0` (Slate 200) |
| `--text-secondary` | `#9fa2c4` | `#94a3b8` (Slate 400) |
| `--text-tertiary` | `#6c6f93` | `#64748b` (Slate 500) |

**新增 CSS 變數**：

| 變數 | 值 | 用途 |
|------|------|------|
| `--bg-card` | `rgba(17, 26, 46, 0.65)` | 毛玻璃卡片背景 |
| `--bg-input` | `#0d1526` | 表單輸入框背景 |
| `--bg-hover` | `#1e2d47` | 懸停狀態背景 |
| `--shadow-glass` | `0 8px 32px rgba(0,0,0,0.25), inset 0 1px 0 rgba(255,255,255,0.03)` | 毛玻璃陰影 |
| `--border-glow` | `rgba(59, 130, 246, 0.25)` | 聚焦時的藍色邊框發光 |

**Tailwind 配置變更**：

| 項目 | 舊 | 新 |
|------|-----|-----|
| `neon` 色組 | blue/purple/cyan/pink/indigo 霓虹色 | **已移除** |
| `navy` 色階 | — | 新增 50–900 完整色階 |
| `boxShadow` | `neon-purple`, `neon-cyan` | `glass`, `enterprise`, `enterprise-lg`, `status-green` |
| `accent.orange` | `#ff8e3c` | `#f59e0b` |
| 新增 `accent.teal` | — | `#14b8a6` |

#### 二、元件級改造明細

**修改的檔案 (7 個)**：

| 檔案 | 變更說明 |
|------|----------|
| `frontend/src/style.css` | `:root` 全新色彩系統、`.glass`/`.glass-card` 真實毛玻璃效果、`.card`/`.panel-matte`/`.panel-elevated` 改為半透明 + blur、`.btn-primary`/`.btn-minimal` 去除漸層改為實色 + 線條、`.status-dot` 新增 `.warning` 狀態 + `::after` 脈衝環動畫、捲軸從霓虹紫漸層改為 slate 半透明、Element Plus 深色覆寫更新 |
| `frontend/tailwind.config.js` | 移除 `neon` 色組、新增 `navy` 色階、更新 `nexus`/`void`/`text`/`border` tokens、新增 `glass`/`enterprise` 陰影 |
| `frontend/src/App.vue` | `.top-bar` 改為 `rgba(11,18,34,0.85)` + `blur(20px) saturate(1.2)`、邊框改為 `rgba(148,163,184,0.08)` |
| `frontend/src/components/Sidebar.vue` | 容器改為半透明海軍藍 + 毛玻璃模糊、Logo 改為實色藍底、底部連線狀態新增綠色脈衝環動畫 `.status-indicator`、導航項目圓角收斂至 8px、活躍指示條精簡為 25%–75% 高度 |
| `frontend/src/views/Settings.vue` | `.settings-card` 改為 `var(--bg-card)` 毛玻璃效果、表單輸入統一 `var(--bg-input)`、按鈕去除漸層改為實色/透明 + 邊框、Toast 通知改為企業級毛玻璃、使用者管理表格全面更新配色 |
| `frontend/src/components/DifyChat.vue` | 主背景改用 `var(--bg-main)`、標頭/輸入區改為企業級毛玻璃、所有紫/霓虹色替換為藍色系、`.prose-chat` Markdown 樣式全面更新、建議按鈕從無效 inline hover 修正為 scoped class |
| `frontend/src/views/LoginPage.vue` | **全面重設計** — 新增環境光暈背景 `.login-ambient`、登入卡片毛玻璃效果 + `blur(24px)`、鎖形 SVG 圖示輸入框、錯誤訊息面板化（紅色背景 + 圖示）、提交按鈕載入旋轉動畫、品牌 Logo 改為 SVG 圖層圖示 |

#### 三、毛玻璃效果技術規格

```css
/* 卡片級毛玻璃 */
.glass-card {
  background: rgba(17, 26, 46, 0.65);
  backdrop-filter: blur(24px) saturate(1.2);
  -webkit-backdrop-filter: blur(24px) saturate(1.2);  /* Safari 支援 */
  border: 1px solid rgba(148, 163, 184, 0.1);
  box-shadow: 0 8px 32px rgba(0,0,0,0.25),
              inset 0 1px 0 rgba(255,255,255,0.03);
}

/* 頂部列 / 側邊欄級毛玻璃 */
.nav-glass {
  background: rgba(11, 18, 34, 0.85–0.92);
  backdrop-filter: blur(20–24px) saturate(1.2);
  border: 1px solid rgba(148, 163, 184, 0.06–0.08);
}
```

#### 四、狀態指示燈動畫

```css
@keyframes statusPulse {
  0%   { transform: scale(1); opacity: 0.6; }
  100% { transform: scale(2.5); opacity: 0; }
}

.status-dot.online::after {
  content: '';
  position: absolute;
  inset: 0;
  border-radius: 50%;
  border: 1.5px solid #22c55e;
  animation: statusPulse 2s ease-out infinite;
}
```

#### 五、修復的錯誤

| 檔案 | 問題 | 修復 |
|------|------|------|
| `Settings.vue` | 孤立 CSS 片段 — 重複的 `.status-badge.error` + `.toast.error` 缺少選擇器 | 移除孤立片段 |
| `DifyChat.vue` | 建議按鈕使用 inline `hover:background:` 偽類（HTML 不支援） | 改為 scoped `.suggestion-btn:hover` class |

**驗證結果**：
- 全部 7 個修改檔案 `get_errors` 驗證：**零編譯錯誤** ✅
- `@tailwind` 警告為 VS Code CSS 驗證器已知誤報，不影響 Vite 編譯 ✅
