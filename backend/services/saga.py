"""
Saga Orchestrator â€” è·¨ç³»çµ±äº‹å‹™ç·¨æŽ’å™¨ + Dead Letter Queue

è¨­è¨ˆåŽŸå‰‡ï¼š
1. Saga Pattern (Orchestration æ¨¡å¼) â€” å”èª¿ RAGFlow + KuzuDB çš„è·¨ç³»çµ±å¯«å…¥
2. æ¯å€‹æ­¥é©Ÿéƒ½æœ‰å°æ‡‰çš„è£œå„Ÿæ“ä½œ (Compensating Transaction)
3. Saga æ—¥èªŒæŒä¹…åŒ–åˆ° SQLiteï¼Œç¢ºä¿å´©æ½°å¾Œå¯é‡æ’­/è£œå„Ÿ
4. è£œå„Ÿå¤±æ•—çš„æ“ä½œå¯«å…¥ DLQï¼Œä¾›ç®¡ç†å“¡æ‰‹å‹•è™•ç†

Saga æµç¨‹ï¼š
  Step 1: RAGFlow Upload â†’ è£œå„Ÿ: RAGFlow Delete
  Step 2: KuzuDB Write   â†’ è£œå„Ÿ: KuzuDB Delete
  Step 3: Excel Parse     â†’ ç„¡è£œå„Ÿ (å¯é‡è©¦)

ä½¿ç”¨æ–¹å¼ï¼š
    saga = FileImportSaga(rag_client, kuzu_manager, dataset_id)
    result = await saga.execute(file_path, graph_id)
"""
import asyncio
import json
import logging
import sqlite3
import uuid
from datetime import datetime
from enum import Enum
from pathlib import Path
from typing import Optional, Dict, Any, List

from backend.core.telemetry import get_tracer

logger = logging.getLogger(__name__)
_tracer = get_tracer("bruv.saga")

# Saga æ—¥èªŒæŒä¹…åŒ–è·¯å¾‘
import os
_DATA_DIR = Path(os.environ.get("BRUV_DATA_DIR", str(Path.home() / "BruV_Data")))
_SAGA_DB_PATH = _DATA_DIR / "saga_log.db"


class SagaStepStatus(str, Enum):
    """Saga æ­¥é©Ÿç‹€æ…‹"""
    NOT_STARTED = "not_started"
    STARTED = "started"
    COMPLETED = "completed"
    FAILED = "failed"
    COMPENSATED = "compensated"
    COMPENSATION_FAILED = "compensation_failed"


class SagaStatus(str, Enum):
    """Saga æ•´é«”ç‹€æ…‹"""
    RUNNING = "running"
    COMPLETED = "completed"
    FAILED = "failed"
    COMPENSATING = "compensating"
    COMPENSATION_COMPLETE = "compensation_complete"
    COMPENSATION_FAILED = "compensation_failed"


class SagaLog:
    """
    Saga æ—¥èªŒ â€” è¨˜éŒ„æ¯å€‹æ­¥é©Ÿçš„åŸ·è¡Œç‹€æ…‹

    æŒä¹…åŒ–åˆ° SQLiteï¼Œç¢ºä¿å´©æ½°å¾Œå¯æ¢å¾©è£œå„Ÿæ“ä½œã€‚
    """

    def __init__(self, saga_id: str = None, file_path: str = None):
        self.saga_id = saga_id or str(uuid.uuid4())
        self.file_path = file_path
        self.steps: Dict[str, Dict[str, Any]] = {}
        self.status = SagaStatus.RUNNING
        self.error: Optional[str] = None
        self.created_at = datetime.now()

        # æŒä¹…åŒ–
        _SAGA_DB_PATH.parent.mkdir(parents=True, exist_ok=True)
        self._init_db()

    def _get_conn(self) -> sqlite3.Connection:
        conn = sqlite3.connect(str(_SAGA_DB_PATH), timeout=5)
        conn.row_factory = sqlite3.Row
        return conn

    def _init_db(self):
        with self._get_conn() as conn:
            conn.execute("""
                CREATE TABLE IF NOT EXISTS saga_logs (
                    saga_id TEXT PRIMARY KEY,
                    file_path TEXT,
                    status TEXT,
                    steps TEXT,
                    error TEXT,
                    created_at TEXT,
                    updated_at TEXT
                )
            """)

    def record_step(self, step_name: str, status: str, **kwargs):
        """è¨˜éŒ„æ­¥é©Ÿç‹€æ…‹"""
        self.steps[step_name] = {
            "status": status,
            "timestamp": datetime.now().isoformat(),
            **kwargs
        }
        self._persist()
        logger.debug(f"ðŸ“ Saga [{self.saga_id[:8]}] step={step_name} status={status}")

    def mark_saga_completed(self):
        self.status = SagaStatus.COMPLETED
        self._persist()
        logger.info(f"âœ… Saga [{self.saga_id[:8]}] å®Œæˆ")

    def mark_saga_failed(self, error: str):
        self.status = SagaStatus.FAILED
        self.error = error
        self._persist()
        logger.error(f"âŒ Saga [{self.saga_id[:8]}] å¤±æ•—: {error}")

    def mark_compensation_complete(self):
        self.status = SagaStatus.COMPENSATION_COMPLETE
        self._persist()

    def mark_compensation_failed(self, error: str):
        self.status = SagaStatus.COMPENSATION_FAILED
        self.error = error
        self._persist()

    def get_completed_steps(self) -> List[str]:
        """å–å¾—æ‰€æœ‰å·²å®Œæˆçš„æ­¥é©Ÿåç¨±"""
        return [
            name for name, step in self.steps.items()
            if step.get("status") == SagaStepStatus.COMPLETED.value
               or step.get("status") == "COMPLETED"
        ]

    def _persist(self):
        """æŒä¹…åŒ–åˆ° SQLite"""
        try:
            with self._get_conn() as conn:
                conn.execute("""
                    INSERT OR REPLACE INTO saga_logs
                    (saga_id, file_path, status, steps, error, created_at, updated_at)
                    VALUES (?, ?, ?, ?, ?, ?, ?)
                """, (
                    self.saga_id,
                    self.file_path,
                    self.status.value,
                    json.dumps(self.steps, ensure_ascii=False),
                    self.error,
                    self.created_at.isoformat(),
                    datetime.now().isoformat(),
                ))
        except Exception as e:
            logger.warning(f"Saga æ—¥èªŒæŒä¹…åŒ–å¤±æ•—: {e}")

    def to_dict(self) -> dict:
        return {
            "saga_id": self.saga_id,
            "file_path": self.file_path,
            "status": self.status.value,
            "steps": self.steps,
            "error": self.error,
            "created_at": self.created_at.isoformat(),
        }


class FileImportSaga:
    """
    Saga ç·¨æŽ’å™¨ï¼šå”èª¿ RAGFlow ä¸Šå‚³ + KuzuDB å¯«å…¥çš„è·¨ç³»çµ±äº‹å‹™

    æ ¸å¿ƒä¿è­‰ï¼š
    - æˆåŠŸï¼šRAGFlow å’Œ KuzuDB éƒ½å¯«å…¥æˆåŠŸ
    - å¤±æ•—ï¼šå·²å®Œæˆçš„æ­¥é©Ÿå…¨éƒ¨åå‘è£œå„Ÿï¼Œç¢ºä¿æœ€çµ‚ä¸€è‡´æ€§
    - è£œå„Ÿå¤±æ•—ï¼šå¯«å…¥ DLQï¼Œä¾›ç®¡ç†å“¡æ‰‹å‹•è™•ç†
    """

    def __init__(self, rag_client, kuzu_manager, dataset_id: str):
        self.rag_client = rag_client
        self.kuzu_manager = kuzu_manager
        self.dataset_id = dataset_id

    async def execute(
        self,
        file_path: Path,
        graph_id: str = "1",
        entity_id_generator=None,
        excel_parser=None,
    ) -> Dict[str, Any]:
        """
        åŸ·è¡Œ Saga â€” å®Œæ•´çš„æª”æ¡ˆåŒ¯å…¥äº‹å‹™

        Args:
            file_path: æª”æ¡ˆè·¯å¾‘
            graph_id: ç›®æ¨™åœ–è­œ ID
            entity_id_generator: è‡ªè¨‚ Entity ID ç”Ÿæˆå‡½å¼
            excel_parser: Excel è§£æžå›žå‘¼å‡½å¼

        Returns:
            Saga åŸ·è¡Œçµæžœå­—å…¸
        """
        saga_log = SagaLog(file_path=str(file_path))
        ragflow_doc_id = None
        kuzu_entity_id = None

        with _tracer.start_as_current_span("saga.file_import") as saga_span:
            saga_span.set_attribute("saga.id", saga_log.saga_id)
            saga_span.set_attribute("saga.file_path", str(file_path))
            saga_span.set_attribute("saga.file_name", file_path.name)
            saga_span.set_attribute("saga.graph_id", graph_id)
            saga_span.set_attribute("saga.dataset_id", self.dataset_id)

            try:
                # â”€â”€ Step 1: ä¸Šå‚³è‡³ RAGFlow â”€â”€
                with _tracer.start_as_current_span("saga.step.ragflow_upload") as step_span:
                    step_span.set_attribute("saga.id", saga_log.saga_id)
                    step_span.set_attribute("saga.file_name", file_path.name)
                    step_span.set_attribute("saga.step", "ragflow_upload")

                    saga_log.record_step("ragflow_upload", status="STARTED")

                    upload_result = await asyncio.get_event_loop().run_in_executor(
                        None,
                        lambda: self.rag_client.upload_file(
                            dataset_id=self.dataset_id,
                            file_path=str(file_path)
                        )
                    )
                    ragflow_doc_id = self._extract_doc_id(upload_result)
                    step_span.set_attribute("saga.ragflow_doc_id", ragflow_doc_id or "")
                    saga_log.record_step(
                        "ragflow_upload",
                        status="COMPLETED",
                        doc_id=ragflow_doc_id
                    )

                # â”€â”€ Step 2: å¯«å…¥ KuzuDB â”€â”€
                with _tracer.start_as_current_span("saga.step.kuzu_write") as step_span:
                    step_span.set_attribute("saga.id", saga_log.saga_id)
                    step_span.set_attribute("saga.file_name", file_path.name)
                    step_span.set_attribute("saga.step", "kuzu_write")

                    saga_log.record_step("kuzu_write", status="STARTED")

                    if entity_id_generator:
                        kuzu_entity_id = entity_id_generator(file_path, upload_result)
                    else:
                        import hashlib
                        file_hash = hashlib.md5(str(file_path.absolute()).encode()).hexdigest()
                        kuzu_entity_id = ragflow_doc_id or f"doc_{file_hash[:16]}"

                    step_span.set_attribute("saga.entity_id", kuzu_entity_id)

                    properties = {
                        'path': str(file_path.absolute()),
                        'size': file_path.stat().st_size,
                        'extension': file_path.suffix.lower(),
                        'dataset_id': self.dataset_id,
                        'document_id': ragflow_doc_id,
                    }

                    success = self.kuzu_manager.add_entity(
                        entity_id=kuzu_entity_id,
                        name=file_path.name,
                        entity_type='document',
                        properties=properties,
                        graph_id=graph_id
                    )
                    if not success:
                        raise RuntimeError(f"KuzuDB å¯«å…¥å¤±æ•—: {kuzu_entity_id}")

                    saga_log.record_step(
                        "kuzu_write",
                        status="COMPLETED",
                        entity_id=kuzu_entity_id
                    )

                # â”€â”€ Step 3: Excel æ·±åº¦è§£æž (å¯é¸) â”€â”€
                if file_path.suffix.lower() == '.xlsx' and excel_parser:
                    with _tracer.start_as_current_span("saga.step.excel_parse") as step_span:
                        step_span.set_attribute("saga.id", saga_log.saga_id)
                        step_span.set_attribute("saga.file_name", file_path.name)
                        step_span.set_attribute("saga.step", "excel_parse")

                        saga_log.record_step("excel_parse", status="STARTED")
                        try:
                            excel_parser(file_path, kuzu_entity_id, graph_id)
                            saga_log.record_step("excel_parse", status="COMPLETED")
                        except Exception as excel_err:
                            saga_log.record_step(
                                "excel_parse",
                                status="FAILED",
                                error=str(excel_err)
                            )
                            step_span.record_exception(excel_err)
                            logger.warning(f"Excel è§£æžå¤±æ•— (ä¸å½±éŸ¿ä¸»æµç¨‹): {excel_err}")

                saga_log.mark_saga_completed()
                saga_span.set_attribute("saga.status", "completed")

                return {
                    "success": True,
                    "saga_id": saga_log.saga_id,
                    "ragflow_doc_id": ragflow_doc_id,
                    "kuzu_entity_id": kuzu_entity_id,
                    "steps": saga_log.steps,
                }

            except Exception as e:
                logger.error(f"Saga å¤±æ•—ï¼Œå•Ÿå‹•è£œå„Ÿ: {e}")
                saga_span.record_exception(e)
                saga_span.set_attribute("saga.status", "compensating")
                saga_log.status = SagaStatus.COMPENSATING

                await self._compensate(saga_log, ragflow_doc_id, kuzu_entity_id)

                saga_log.mark_saga_failed(str(e))
                saga_span.set_attribute("saga.status", "failed")

                return {
                    "success": False,
                    "saga_id": saga_log.saga_id,
                    "error": str(e),
                    "steps": saga_log.steps,
                }

    async def _compensate(self, saga_log: SagaLog,
                          ragflow_doc_id: Optional[str],
                          kuzu_entity_id: Optional[str]):
        """åå‘è£œå„Ÿï¼šæŒ‰ saga_log åå‘æ’¤éŠ·å·²å®Œæˆçš„æ­¥é©Ÿ"""
        completed_steps = saga_log.get_completed_steps()
        all_compensated = True

        with _tracer.start_as_current_span("saga.compensate") as comp_span:
            comp_span.set_attribute("saga.id", saga_log.saga_id)
            comp_span.set_attribute("saga.file_path", saga_log.file_path)
            comp_span.set_attribute("saga.completed_steps", ",".join(completed_steps))

            # åå‘é †åºè£œå„Ÿ
            if "kuzu_write" in completed_steps and kuzu_entity_id:
                try:
                    self.kuzu_manager.delete_entity(kuzu_entity_id)
                    saga_log.record_step("comp_kuzu_delete", status="COMPLETED")
                    logger.info(f"ðŸ”„ è£œå„Ÿå®Œæˆ: å·²åˆªé™¤ KuzuDB å¯¦é«” {kuzu_entity_id}")
                except Exception as comp_err:
                    saga_log.record_step(
                        "comp_kuzu_delete",
                        status="FAILED",
                        error=str(comp_err)
                    )
                    comp_span.record_exception(comp_err)
                    logger.error(f"âŒ è£œå„Ÿå¤±æ•— (KuzuDB): {comp_err}")
                    all_compensated = False

            if "ragflow_upload" in completed_steps and ragflow_doc_id:
                try:
                    await asyncio.get_event_loop().run_in_executor(
                        None,
                        lambda: self.rag_client.delete_document(
                            dataset_id=self.dataset_id,
                            document_id=ragflow_doc_id
                        )
                    )
                    saga_log.record_step("comp_ragflow_delete", status="COMPLETED")
                    logger.info(f"ðŸ”„ è£œå„Ÿå®Œæˆ: å·²åˆªé™¤ RAGFlow æ–‡ä»¶ {ragflow_doc_id}")
                except Exception as comp_err:
                    saga_log.record_step(
                        "comp_ragflow_delete",
                        status="FAILED",
                        error=str(comp_err)
                    )
                    comp_span.record_exception(comp_err)
                    logger.error(f"âŒ è£œå„Ÿå¤±æ•— (RAGFlow): {comp_err}")
                    all_compensated = False

            if all_compensated:
                saga_log.mark_compensation_complete()
                comp_span.set_attribute("saga.compensation_result", "success")
            else:
                saga_log.mark_compensation_failed("éƒ¨åˆ†è£œå„Ÿæ“ä½œå¤±æ•—ï¼Œè«‹æŸ¥çœ‹ DLQ")
                comp_span.set_attribute("saga.compensation_result", "partial_failure")

    def _extract_doc_id(self, upload_result: dict) -> Optional[str]:
        """å¾ž RAGFlow ä¸Šå‚³çµæžœæå– document ID"""
        if not upload_result:
            return None
        data = upload_result.get('data')
        if isinstance(data, dict):
            return data.get('id')
        elif isinstance(data, list) and data:
            return data[0].get('id')
        return None


# ==================== Saga æŸ¥è©¢å·¥å…· ====================

def list_recent_sagas(limit: int = 50) -> List[dict]:
    """æŸ¥è©¢æœ€è¿‘çš„ Saga åŸ·è¡Œè¨˜éŒ„"""
    try:
        conn = sqlite3.connect(str(_SAGA_DB_PATH), timeout=5)
        conn.row_factory = sqlite3.Row
        rows = conn.execute(
            "SELECT * FROM saga_logs ORDER BY created_at DESC LIMIT ?",
            (limit,)
        ).fetchall()
        conn.close()
        return [dict(row) for row in rows]
    except Exception as e:
        logger.error(f"æŸ¥è©¢ Saga è¨˜éŒ„å¤±æ•—: {e}")
        return []


def get_saga_by_id(saga_id: str) -> Optional[dict]:
    """æ ¹æ“š ID æŸ¥è©¢ Saga è¨˜éŒ„"""
    try:
        conn = sqlite3.connect(str(_SAGA_DB_PATH), timeout=5)
        conn.row_factory = sqlite3.Row
        row = conn.execute(
            "SELECT * FROM saga_logs WHERE saga_id = ?",
            (saga_id,)
        ).fetchone()
        conn.close()
        return dict(row) if row else None
    except Exception as e:
        logger.error(f"æŸ¥è©¢ Saga å¤±æ•—: {e}")
        return None
