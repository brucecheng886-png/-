"""
ç³»çµ± API â€” è–„è·¯ç”±å±¤

æ ¸å¿ƒé‚è¼¯å·²æ‹†åˆ†è‡³:
  - system_config.py      (é…ç½®å·¥å…· & Pydantic æ¨¡å‹)
  - system_upload.py       (æª”æ¡ˆä¸Šå‚³ç®¡ç·š)
  - system_connections.py  (é€£ç·šç®¡ç† CRUD + åµæ¸¬)
"""
from fastapi import APIRouter, HTTPException
import os
import logging

from backend.core.config import (
    load_config_from_file, save_config_to_file, get_current_api_keys, settings
)
from backend.core.circuit_breaker import dify_breaker, ragflow_breaker

# ---- å¾æ‹†åˆ†æ¨¡çµ„åŒ¯å…¥ ----
from .system_config import (
    ConfigUpdateRequest,
    ConfigResponse,
    get_env_file_path,
    mask_api_key,
    is_masked_key,
    read_env_file,
    update_env_file,
    reload_env_to_os,
)
from . import system_upload
from . import system_connections

logger = logging.getLogger(__name__)
router = APIRouter()

# ---- åŒ…å«å­æ¨¡çµ„è·¯ç”± ----
router.include_router(system_upload.router)
router.include_router(system_connections.router)


# ===== é…ç½® API =====

@router.get("/config")
async def get_config():
    """ç²å–ç•¶å‰ç³»çµ±é…ç½®"""
    try:
        api_keys = get_current_api_keys()
        return ConfigResponse(
            success=True,
            message="é…ç½®ç²å–æˆåŠŸ",
            config={
                "dify_key": mask_api_key(api_keys['DIFY_API_KEY']),
                "ragflow_key": mask_api_key(api_keys['RAGFLOW_API_KEY']),
                "dify_api_url": api_keys['DIFY_API_URL'],
                "ragflow_api_url": api_keys['RAGFLOW_API_URL'],
                "config_source": "config.json (C:/BruV_Data/config.json)"
            }
        )
    except Exception as e:
        logger.error(f"ç²å–é…ç½®å¤±æ•—: {e}")
        raise HTTPException(status_code=500, detail=f"ç²å–é…ç½®å¤±æ•—: {str(e)}")


@router.post("/config")
async def update_config(request: ConfigUpdateRequest):
    """æ›´æ–°ç³»çµ±é…ç½®ï¼ˆä¿å­˜åˆ° config.jsonï¼‰"""
    try:
        config_updates = {}

        if request.dify_key:
            if is_masked_key(request.dify_key):
                logger.warning("å¿½ç•¥é®ç½©çš„ dify_api_keyï¼Œä¸æ›´æ–°")
            else:
                config_updates['dify_api_key'] = request.dify_key
                logger.info("æº–å‚™æ›´æ–° dify_api_key")

        if request.ragflow_key:
            if is_masked_key(request.ragflow_key):
                logger.warning("å¿½ç•¥é®ç½©çš„ ragflow_api_keyï¼Œä¸æ›´æ–°")
            else:
                config_updates['ragflow_api_key'] = request.ragflow_key
                logger.info("æº–å‚™æ›´æ–° ragflow_api_key")

        if request.dify_api_url:
            config_updates['dify_api_url'] = request.dify_api_url
            logger.info(f"æº–å‚™æ›´æ–° dify_api_url: {request.dify_api_url}")

        if request.ragflow_api_url:
            config_updates['ragflow_api_url'] = request.ragflow_api_url
            logger.info(f"æº–å‚™æ›´æ–° ragflow_api_url: {request.ragflow_api_url}")

        if not config_updates:
            raise HTTPException(status_code=400, detail="è‡³å°‘éœ€è¦æä¾›ä¸€å€‹è¨­å®šé …ç›®")

        success = save_config_to_file(config_updates)
        if not success:
            raise HTTPException(status_code=500, detail="æ›´æ–°é…ç½®æª”æ¡ˆå¤±æ•—")

        response_config = {}
        if request.dify_key:
            response_config['dify_key'] = request.dify_key
        if request.ragflow_key:
            response_config['ragflow_key'] = request.ragflow_key
        if request.dify_api_url:
            response_config['dify_api_url'] = request.dify_api_url
        if request.ragflow_api_url:
            response_config['ragflow_api_url'] = request.ragflow_api_url

        return ConfigResponse(
            success=True,
            message="âœ… é…ç½®å·²ä¿å­˜åˆ° config.jsonï¼ä¿®æ”¹å°‡ç«‹å³ç”Ÿæ•ˆ",
            config=response_config
        )

    except HTTPException:
        raise
    except Exception as e:
        logger.error(f"æ›´æ–°é…ç½®å¤±æ•—: {e}")
        raise HTTPException(status_code=500, detail=f"æ›´æ–°é…ç½®å¤±æ•—: {str(e)}")


@router.get("/env-file")
async def get_env_file_location():
    """ç²å– .env æª”æ¡ˆä½ç½®å’Œç‹€æ…‹"""
    try:
        env_path = get_env_file_path()
        exists = env_path.exists()
        writable = os.access(env_path.parent, os.W_OK)
        return {"success": True, "path": str(env_path), "exists": exists, "writable": writable}
    except Exception as e:
        logger.error(f"ç²å– .env æª”æ¡ˆè³‡è¨Šå¤±æ•—: {e}")
        raise HTTPException(status_code=500, detail=f"ç²å–æª”æ¡ˆè³‡è¨Šå¤±æ•—: {str(e)}")


# ===== èˆŠç‰ˆé€£ç·šæ¸¬è©¦ (å‘ä¸‹ç›¸å®¹) =====

@router.post("/test-connection")
async def test_connection():
    """æ¸¬è©¦ Dify å’Œ RAGFlow æœå‹™é€£æ¥ï¼ˆèˆŠç‰ˆï¼‰"""
    import httpx

    api_keys = get_current_api_keys()
    results = {
        "success": True,
        "dify": {
            "status": "unknown", "url": api_keys['DIFY_API_URL'],
            "message": "", "api_key_configured": bool(api_keys['DIFY_API_KEY'])
        },
        "ragflow": {
            "status": "unknown", "url": api_keys['RAGFLOW_API_URL'],
            "message": "", "api_key_configured": bool(api_keys['RAGFLOW_API_KEY'])
        }
    }

    # æ¸¬è©¦ Dify
    try:
        if not api_keys['DIFY_API_KEY']:
            results['dify']['status'] = 'warning'
            results['dify']['message'] = 'âŒ API Key æœªé…ç½®'
        else:
            async with httpx.AsyncClient(timeout=5.0) as client:
                response = await client.get(
                    api_keys['DIFY_API_URL'],
                    headers={"Authorization": f"Bearer {api_keys['DIFY_API_KEY']}"}
                )
                if response.status_code in [200, 401, 404, 422]:
                    results['dify']['status'] = 'ok'
                    results['dify']['message'] = 'âœ… é€£æ¥æˆåŠŸ'
                elif response.status_code == 403:
                    results['dify']['status'] = 'error'
                    results['dify']['message'] = 'âŒ API Key ç„¡æ¬Šé™'
                else:
                    results['dify']['status'] = 'error'
                    results['dify']['message'] = f'âŒ æœå‹™éŒ¯èª¤ ({response.status_code})'
    except httpx.ConnectError:
        results['dify']['status'] = 'error'
        results['dify']['message'] = f'âŒ ç„¡æ³•é€£æ¥åˆ° {api_keys["DIFY_API_URL"]} - è«‹ç¢ºèªæœå‹™å·²å•Ÿå‹•'
    except httpx.TimeoutException:
        results['dify']['status'] = 'error'
        results['dify']['message'] = 'âŒ é€£æ¥è¶…æ™‚'
    except Exception as e:
        results['dify']['status'] = 'error'
        results['dify']['message'] = f'âŒ {str(e)}'

    # æ¸¬è©¦ RAGFlow
    try:
        if not api_keys['RAGFLOW_API_KEY']:
            results['ragflow']['status'] = 'warning'
            results['ragflow']['message'] = 'âŒ API Key æœªé…ç½®'
        else:
            async with httpx.AsyncClient(timeout=5.0) as client:
                response = await client.get(
                    f"{api_keys['RAGFLOW_API_URL'].rstrip('/')}/datasets",
                    headers={"Authorization": f"Bearer {api_keys['RAGFLOW_API_KEY']}"}
                )
                if response.status_code == 200:
                    results['ragflow']['status'] = 'ok'
                    data = response.json()
                    datasets = data.get('data', [])
                    if isinstance(datasets, list):
                        dataset_count = len(datasets)
                        results['ragflow']['message'] = f'âœ… é€£æ¥æˆåŠŸï¼ˆæ‰¾åˆ° {dataset_count} å€‹çŸ¥è­˜åº«ï¼‰'
                    else:
                        results['ragflow']['message'] = 'âœ… é€£æ¥æˆåŠŸ'
                elif response.status_code == 401:
                    results['ragflow']['status'] = 'error'
                    results['ragflow']['message'] = 'âŒ API Key ç„¡æ•ˆæˆ–å·²éæœŸ'
                else:
                    results['ragflow']['status'] = 'error'
                    results['ragflow']['message'] = f'âŒ æœå‹™éŒ¯èª¤ ({response.status_code})'
    except httpx.ConnectError:
        results['ragflow']['status'] = 'error'
        results['ragflow']['message'] = f'âŒ ç„¡æ³•é€£æ¥åˆ° {api_keys["RAGFLOW_API_URL"]} - è«‹ç¢ºèªæœå‹™å·²å•Ÿå‹•'
    except httpx.TimeoutException:
        results['ragflow']['status'] = 'error'
        results['ragflow']['message'] = 'âŒ é€£æ¥è¶…æ™‚'
    except Exception as e:
        results['ragflow']['status'] = 'error'
        results['ragflow']['message'] = f'âŒ {str(e)}'

    if results['dify']['status'] == 'error' or results['ragflow']['status'] == 'error':
        results['success'] = False

    return results


# ===== æ–·è·¯å™¨ / DLQ / ç³»çµ±ç¶­è­· =====

@router.get("/circuit-breakers")
async def get_circuit_breaker_status():
    """å–å¾—æ‰€æœ‰æ–·è·¯å™¨ç‹€æ…‹"""
    return {
        "success": True,
        "data": {
            "dify": dify_breaker.get_status(),
            "ragflow": ragflow_breaker.get_status(),
        }
    }


@router.get("/saga-dlq")
async def get_saga_dlq():
    """å–å¾— Saga æ­»ä¿¡ä½‡åˆ—ä¸­çš„æœªè§£æ±ºé …ç›®"""
    try:
        from backend.services.watcher import dlq
        items = dlq.list_unresolved(limit=50)
        return {"success": True, "data": items, "total": len(items)}
    except Exception as e:
        logger.error(f"DLQ æŸ¥è©¢å¤±æ•—: {e}")
        raise HTTPException(status_code=500, detail=f"DLQ æŸ¥è©¢å¤±æ•—: {str(e)}")


@router.post("/saga-dlq/{dlq_id}/resolve")
async def resolve_dlq_item(dlq_id: str):
    """æ¨™è¨˜ DLQ é …ç›®ç‚ºå·²è§£æ±º"""
    try:
        from backend.services.watcher import dlq
        success = dlq.mark_resolved(dlq_id)
        if success:
            return {"success": True, "message": f"DLQ é …ç›® {dlq_id} å·²æ¨™è¨˜ç‚ºå·²è§£æ±º"}
        raise HTTPException(status_code=404, detail="DLQ é …ç›®ä¸å­˜åœ¨")
    except HTTPException:
        raise
    except Exception as e:
        logger.error(f"DLQ æ¨™è¨˜å¤±æ•—: {e}")
        raise HTTPException(status_code=500, detail=str(e))


@router.post("/maintenance/cleanup")
async def system_cleanup(retention_days: int = 7):
    """æ¸…ç†éæœŸçš„ SagaLog èˆ‡ TaskQueue è¨˜éŒ„"""
    import sqlite3
    from datetime import datetime, timedelta

    cutoff = (datetime.now() - timedelta(days=retention_days)).isoformat()
    results = {"saga_deleted": 0, "task_deleted": 0, "retention_days": retention_days, "cutoff": cutoff}

    try:
        from backend.services.saga import _SAGA_DB_PATH
        if _SAGA_DB_PATH.exists():
            conn = sqlite3.connect(str(_SAGA_DB_PATH), timeout=5)
            cursor = conn.execute(
                "DELETE FROM saga_logs WHERE status IN ('completed', 'compensation_complete') "
                "AND created_at < ?", (cutoff,)
            )
            results["saga_deleted"] = cursor.rowcount
            conn.commit()
            conn.close()
            logger.info(f"ğŸ§¹ å·²æ¸…ç† {results['saga_deleted']} ç­†éæœŸ SagaLog")
    except Exception as e:
        logger.error(f"SagaLog æ¸…ç†å¤±æ•—: {e}")
        results["saga_error"] = str(e)

    try:
        from backend.services.task_queue import _TASK_DB_PATH
        if _TASK_DB_PATH.exists():
            conn = sqlite3.connect(str(_TASK_DB_PATH), timeout=5)
            cursor = conn.execute(
                "DELETE FROM tasks WHERE status IN ('completed', 'failed') "
                "AND completed_at < ?", (cutoff,)
            )
            results["task_deleted"] = cursor.rowcount
            conn.commit()
            conn.close()
            logger.info(f"ğŸ§¹ å·²æ¸…ç† {results['task_deleted']} ç­†éæœŸ TaskQueue è¨˜éŒ„")
    except Exception as e:
        logger.error(f"TaskQueue æ¸…ç†å¤±æ•—: {e}")
        results["task_error"] = str(e)

    return {
        "success": True,
        "message": f"æ¸…ç†å®Œæˆ: SagaLog {results['saga_deleted']} ç­†, TaskQueue {results['task_deleted']} ç­† (DLQ ä¿ç•™ä¸å‹•)",
        "data": results
    }
